{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "colab_type": "code",
    "id": "K8VFcl1gBfU-",
    "outputId": "bb396c32-fbc4-490f-c8f4-78f1e1e69b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 4.8MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 52.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 43.4MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d03bde1420042337d0d099048404fc4dd6563726c019d6130b1db02be41ff3b8\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.0 transformers-2.5.0\n"
     ]
    }
   ],
   "source": [
    "#ALL INSTALLTIONS\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "T3MK2sszwvbe",
    "outputId": "8163f13e-478e-4406-b386-3a1baa058dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#all imports\n",
    "#BERT implemantation using Pytorch inspired by the tutorials of https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\n",
    "#and \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cEeA5Ys-R2r"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaSv6PB4w1JW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def initGpus1():\n",
    "  gpuname=tf.test.gpu_device_name()\n",
    "  if gpuname=='/device:GPU:0':\n",
    "    print('Found GPU at :{}'.format(gpuname))\n",
    "  else:\n",
    "    gpuname=\"\"\n",
    "  if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    n_gpu=torch.cuda.device_count()\n",
    "    print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "  else:\n",
    "    print(\"No GPU available using only CPU instead\")\n",
    "    device=torch.device(\"cpu\")\n",
    "  return gpuname,device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "iALw8AQY7LkW",
    "outputId": "7d20a5a4-f48f-49e2-9ec3-312e959ea41d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhCZIFPC7Yhs"
   },
   "outputs": [],
   "source": [
    "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/PredictFile.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RUoX4ag7a5W"
   },
   "outputs": [],
   "source": [
    "##Use blob\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['tweet','subtask_a']\n",
    "  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter=',',names=headers)\n",
    "  \n",
    "  data=greekdata[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  y=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  arrt=X[:,0]\n",
    "  #print(X)\n",
    "  #print(y)\n",
    "  preprocessedTweets=arrt\n",
    "  return preprocessedTweets,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfE9PV0Vu08q"
   },
   "outputs": [],
   "source": [
    "#preprocessedTweets,y=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "PuLzvJ4msRLX",
    "outputId": "60d20a13-de28-4899-9310-69fa15b22265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n##Use blob\\n#GET THE DATA FROM THE PANDAS FRAME\\ndef readData1():\\n  headers=[\\'tweet\\',\\'subtask_a\\']\\n  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter=\\'\\t\\',names=headers)\\n  data=greekdata[1:]\\n  #print(greekdata)\\n  dfnumpy=data.to_numpy();\\n  X=dfnumpy[:, 0].reshape(-1, 1)\\n\\n\\n  #REMOVE THE BELOW LINE\\n  greekdata1 = pd.read_csv(\"PredictFile.csv\", delimiter=\\',\\',names=headers)\\n\\n  data=greekdata[1:]\\n  dfnumpy=data.to_numpy();\\n  X=dfnumpy[:, 0].reshape(-1, 1)\\n  #print(X)\\n  \\n  data=greekdata1[1:]\\n  dfnumpy=data.to_numpy();\\n  y=dfnumpy[:, 1].reshape(-1, 1)\\n  \\n  arrt=X[:,0]\\n  #print(y)\\n  preprocessedTweets=arrt\\n\\n  return preprocessedTweets,y\\n  '"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##Use blob\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['tweet','subtask_a']\n",
    "  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter='\\t',names=headers)\n",
    "  data=greekdata[1:]\n",
    "  #print(greekdata)\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "\n",
    "\n",
    "  #REMOVE THE BELOW LINE\n",
    "  greekdata1 = pd.read_csv(\"PredictFile.csv\", delimiter=',',names=headers)\n",
    "\n",
    "  data=greekdata[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  #print(X)\n",
    "  \n",
    "  data=greekdata1[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  y=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  \n",
    "  arrt=X[:,0]\n",
    "  #print(y)\n",
    "  preprocessedTweets=arrt\n",
    "\n",
    "  return preprocessedTweets,y\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAPtgGcYVDjl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fF2D1hIsObn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_ZLONeR9I4Y"
   },
   "outputs": [],
   "source": [
    "def giveIds(sentence):\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "  ids_of_sentence=[]\n",
    "  ids_of_sentence_words=[]\n",
    "  attention_masks=[]\n",
    "  maxlength=0\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "  print(maxlength)\n",
    "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
    "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
    "  return ids_of_sentence_words,attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZsgnMAssDmy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYZP78bKr4Sa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eqN01x9LqjLa",
    "outputId": "800ad691-e69b-43f4-c7d6-293c3f30ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "xpredict,xpredictmask=giveIds(preprocessedTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X6_3fz3pruOD",
    "outputId": "ffcb6ea5-c6ab-4d5b-c5b9-6197f734bfc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_of_sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xv0Z1IwUyNGl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  #print(\"predictionArgmax\",predictionArgmax)\n",
    "  #print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3Gp5gPddxj"
   },
   "outputs": [],
   "source": [
    "def predictingData(pTweets,ypred):\n",
    "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  xpredict,xpredictmask=giveIds(pTweets)\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ypredict=le.fit_transform(ypred.flatten())\n",
    "\n",
    "  x_predict_pytorch=torch.tensor(xpredict)\n",
    "  y_predict_pytorch=torch.tensor(ypredict)\n",
    "  x_predict_mask_pytorch=torch.tensor(xpredictmask)\n",
    "\n",
    "  bsize = 32\n",
    "  predictdata=TensorDataset(x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch)\n",
    "  predictsampler=RandomSampler(predictdata)\n",
    "  predictdataloader=DataLoader(predictdata,sampler=predictsampler,batch_size=bsize)\n",
    "  \n",
    "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "  model.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  \n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "\n",
    "  for batch in predictdataloader: \n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      trueLabels.append(label_ids)\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      \n",
    "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "  return predictedLabels,trueLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Da99UbY7xlx_"
   },
   "outputs": [],
   "source": [
    "#device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "cBxBKJFVaFjr",
    "outputId": "6ebf28cb-94a4-45b0-b21a-c91fb5e55c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n",
      "The device name is Tesla P100-PCIE-16GB\n",
      "166\n",
      "  F1 score: 0.839\n",
      "  Accuracy score: 0.883\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  initGpus1()  \n",
    "  preprocessedTweets,y=readData1()\n",
    "  predictedLabels,trueLabels=predictingData(preprocessedTweets,y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey3iQErEVmuA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PredictionGreek.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
