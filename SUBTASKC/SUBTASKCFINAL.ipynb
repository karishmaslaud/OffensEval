{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "46ee4a6c-8ec3-453d-a179-016e1f61934e"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "46Fpl7WYdNu0",
    "outputId": "e4ca6af1-f8fc-4cff-f02d-1b0066ae7487"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4KbHLlB0hdj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1nweMDxcWic"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "3ef816be-0097-4227-81b7-95512842fed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  gpuname=\"\"\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  n_gpu=torch.cuda.device_count()\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "34721c4e-cf31-4d04-c359-7f4e7b5b3861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ayt4_mQnr5n7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "headers=['id','text','average_ind','average_grp','average_oth','std_ind','std_grp','std_oth']\n",
    "taskc = pd.read_csv(\"task_c_distant_ann.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average_ind\":convertToFloat,\n",
    "                                                                                                    \"average_grp\":convertToFloat,\n",
    "                                                                                                    \"average_oth\":convertToFloat,\n",
    "                                                                                                    \"std_ind\":convertToFloat,\n",
    "                                                                                                    \"std_grp\":convertToFloat,\n",
    "                                                                                                    \"std_oth\":convertToFloat})\n",
    "taskc=taskc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m-dCmH8dThOD",
    "outputId": "8c92719b-b1d5-4ad7-f4b9-d719ca8548f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188973"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taskc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "2uXSsl4DrvPa",
    "outputId": "5e2d9fba-baba-4d7d-e312-436de032fdf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              object\n",
       "text            object\n",
       "average_ind    float64\n",
       "average_grp    float64\n",
       "average_oth    float64\n",
       "std_ind        float64\n",
       "std_grp        float64\n",
       "std_oth        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXDd24Fxry8c"
   },
   "outputs": [],
   "source": [
    "#len(taskc)\n",
    "#taskc=taskc[:10000]\n",
    "#taska=taska[1000000:1500000]\n",
    "#taska=taska[1500000:2500000]\n",
    "#taska=taska[3500000:4500000]\n",
    "#taska=taska[5500000:6500000]\n",
    "#taska=taska[6000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
    "englishdata = pd.read_csv(\"/content/drive/My Drive/EnglishData/OLIDv1.0/olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
    "englishdata=englishdata[['id','tweet','subtask_c']]\n",
    "englishdata=englishdata[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKDwFMQdrusQ"
   },
   "outputs": [],
   "source": [
    "englishdata = englishdata.dropna(subset=['subtask_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "leV4AIvO56Jp",
    "outputId": "083c0a31-78d7-4739-eec6-5d1ef696a359"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(englishdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "B9dY5nerCi3z",
    "outputId": "09c472b2-a872-434a-cced-db2528b89b98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52415</td>\n",
       "      <td>@USER was literally just talking about this lo...</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13384</td>\n",
       "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28414</td>\n",
       "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              tweet subtask_c\n",
       "2   90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       IND\n",
       "6   97670                  @USER Liberals are all Kookoo !!!       OTH\n",
       "8   52415  @USER was literally just talking about this lo...       GRP\n",
       "10  13384  @USER Canada doesn’t need another CUCK! We alr...       IND\n",
       "13  28414  @USER you are a lying corrupt traitor!!! Nobod...       IND"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "85xVmaYRHFab",
    "outputId": "2030fdec-5a6d-45b5-e03b-e18a6733b6f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\\nexport_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\\nprint (englishtrain.head())\\n#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\\nexport_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\\nprint (englishtest.head())\""
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\n",
    "export_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtrain.head())\n",
    "#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\n",
    "export_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtest.head())'''\n",
    "#export_csv = englishpredict.to_csv ('/content/drive/My Drive/EnglishData/predictFileEnglish.csv', index = None, header=True)\n",
    "#print (englishpredict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn8dOMH10Cla"
   },
   "outputs": [],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "\n",
    "def giveIds(sentence):\n",
    "  maxlength=0\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "  return maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMeqzRH7LS5Q"
   },
   "outputs": [],
   "source": [
    "dfnumpy=taskc.to_numpy()\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a40P-fEPNwSC",
    "outputId": "06fa8624-de7b-4de8-c0d3-bcda1bd68632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmbrouMtLk4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def giveLabel(y1,y2,y3):\n",
    "  i=0\n",
    "  largest_index=0\n",
    "  #label1=['IND','GRP','OTH']\n",
    "  ylabels=[]\n",
    "  for r in y1:\n",
    "    if (y1[i] >= y2[i]) and (y1[i] >= y3[i]): \n",
    "        largest_index = 0 \n",
    "    elif (y2[i] >= y1[i]) and (y2[i] >= y3[i]): \n",
    "        largest_index = 1 \n",
    "    else: \n",
    "        largest_index = 2 \n",
    "    \n",
    "    ylabels.append(largest_index)\n",
    "    i=i+1;\n",
    "  return ylabels\n",
    "\n",
    "dfnumpy=taskc.to_numpy();\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train1=dfnumpy[:, 2].reshape(-1, 1)\n",
    "y_train2=dfnumpy[:, 3].reshape(-1, 1)\n",
    "y_train3=dfnumpy[:, 4].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEBKnFqftO5_"
   },
   "outputs": [],
   "source": [
    "y1=giveLabel(y_train1,y_train2,y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVBwzETtK9a-"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "x_test=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_test=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uXEyC_aKco3l",
    "outputId": "73a7b696-3462-481f-910b-6a1db080a510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3876"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ac_aRXP3Ll_Z",
    "outputId": "ccc078d4-bbec-4546-aa80-6065ca9ee798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152562\n",
      "24917\n",
      "11494\n"
     ]
    }
   ],
   "source": [
    "print(y1.count(0))\n",
    "print(y1.count(1))\n",
    "print(y1.count(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ew7u6ptZMJZs",
    "outputId": "01e0e5e2-b148-4c95-cd1f-4335467f46e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8073216808750456\n",
      "0.1318548152381557\n",
      "0.06082350388679864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IND', 'GRP', 'OTH']"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y1.count(0)/len(y1))\n",
    "print(y1.count(1)/len(y1))\n",
    "print(y1.count(2)/len(y1))\n",
    "['IND','GRP','OTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_NKcxDqLOGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train,y_train=shuffle(x_train,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0E_1X_qqOw8Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def giveLabel2(y1):\n",
    "  i=0\n",
    "  largest_index=0\n",
    "  #label1=['IND','GRP','OTH']\n",
    "  ylabels=[]\n",
    "  for r in y1:\n",
    "    if (r==\"IND\"): \n",
    "        largest_index = 0 \n",
    "    elif (r==\"GRP\"):\n",
    "        largest_index = 1 \n",
    "    else: \n",
    "        largest_index = 2 \n",
    "    \n",
    "    ylabels.append(largest_index)\n",
    "    i=i+1;\n",
    "  return ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BSZGqjvlBIDa",
    "outputId": "d2d635e6-faa9-43bf-85e2-b3483c8ce08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3876, 1)\n",
      "(188973,)\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "#print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_predict.shape)\n",
    "yTrain=le.fit_transform(y_train)\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "#le.fit_transform(['IND','GRP','OTH'])\n",
    "yl=giveLabel2(y_test.flatten())\n",
    "yTest=le.fit_transform(y1)\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMCPsKyZBK7f",
    "outputId": "317e323d-8421-4e3a-8d0d-f12ce5d0ee7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11494"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest.flatten().tolist().count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QmG6tesd1euz",
    "outputId": "fbea704b-3378-4993-e02e-cacf268f4673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###IMPORTANT\n",
    "'''xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
    "x_test_pytorch=torch.tensor(xtest)\n",
    "y_test_pytorch=torch.tensor(y_test)\n",
    "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
    "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
    "tesampler=RandomSampler(tedata)\n",
    "bsize=64\n",
    "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
    "print(len(xtest))\n",
    "print(len(y_test))\n",
    "len(x_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZbZxkgcBhfag",
    "outputId": "b0d10b5b-f6c3-4da9-aea6-4f04d7953eea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-uncased',num_labels=3,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZPr_Sj12LY-y",
    "outputId": "e45cf250-47f4-403f-bd80-8a731a4811f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ONLY FOR THE FIRST TIME SAVE ELSE LOAD\n",
    "#torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/BERTNEWsubtaskc.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BERTNEWsubtaskc.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDzvjKyWMio7"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQQ5__z5Mio-"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frZAYslgMipB"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au4tTkrfMipE"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['predicted']=['X']\n",
    "data['true']=['X']\n",
    "data.to_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/OLIDSUBTASKCBERT.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwqSDP2KL71z"
   },
   "outputs": [],
   "source": [
    "MAXLENGTH=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTurXRofNATj",
    "outputId": "2bd4ff31-dbde-460c-91dd-f2c239be9b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nz=0;\\nfor batch_idx, data in enumerate(tdataloader): \\n  if z==100:\\n    break;\\n  z=z+1;'"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnglishTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U47_yavmOa7S"
   },
   "outputs": [],
   "source": [
    "class EnglishTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VObEL94h-bU8"
   },
   "outputs": [],
   "source": [
    "MAXLENGTH=64\n",
    "xytrain=[x_train,yTrain]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tdataset = EnglishTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjp1U9q9xaI"
   },
   "outputs": [],
   "source": [
    "xytest=[x_test,yTest]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tedataset = EnglishTestDataset(xytest) \n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q_DY3ZT4j8z6",
    "outputId": "f183d7a2-85f3-4f7b-9c5f-7ed5758483d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188973"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "0rPrZ3_M-LZx",
    "outputId": "c2094ef6-fa1e-4c22-8667-b5f31d6343f0"
   },
   "outputs": [],
   "source": [
    "epochs=4\n",
    "total_steps=len(tdataloader)*epochs\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cqmnbPGdMipR",
    "outputId": "c1aa4ea6-4e4b-4afe-e764-d99b1739296c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "keeptrack=0\n",
    "epochs=4\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    \n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    if device.type==\"cpu\":\n",
    "     model.to(device)\n",
    "     map_location='cpu'\n",
    "    else:\n",
    "      model.cuda()\n",
    "      map_location=lambda storage, loc: storage.cuda()\n",
    "    checkpoint = torch.load('/content/drive/My Drive/EnglishData/BERTNEWsubtaskc.pth.tar',map_location=map_location)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "    \n",
    "    for batch_idx, data in enumerate(tedataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in data)            \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "           outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        print(keeptrack)\n",
    "        keeptrack+=32\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "    torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/BERTNEWsubtaskc.pth.tar')\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "      \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If model already present use below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLID Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSdEEzMJMipH"
   },
   "outputs": [],
   "source": [
    "##F1 score calculate and store\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"Predictions Argmax\",predictionArgmax)\n",
    "  print(\"labels Flattened\",labelsFlattend)\n",
    "  data=pd.read_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/OLIDSUBTASKCBERT.csv')#,converters={'predicted': eval,'true': eval})\n",
    "  ypred=data['predicted'].to_numpy().tolist()\n",
    "  for t in predictionArgmax:\n",
    "    ypred.append(t)\n",
    "\n",
    "  print(len(ypred))\n",
    "  ytrue=data['true'].to_numpy().tolist()\n",
    "  for t in labelsFlattend:\n",
    "    ytrue.append(t)\n",
    "  data = pd.DataFrame()\n",
    "  data['predicted']=ypred\n",
    "  data['true']=ytrue\n",
    "  data.to_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/OLIDSUBTASKCBERT.csv') \n",
    "\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sEdMU6iS9upN",
    "outputId": "68a83874-a9cd-42a7-e9bc-2c61c929a4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Argmax [0 1 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 1 2 2 0 0 0 2 0 0 0 1 1]\n",
      "labels Flattened [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0]\n",
      "33\n",
      "Predictions Argmax [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 2 1 1 1 0 1 1 2 0 1 1 0 0 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 2 0 1 0 0]\n",
      "65\n",
      "Predictions Argmax [0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 2 0 0 1 0 0 0 0]\n",
      "labels Flattened [1 0 2 0 1 2 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "97\n",
      "Predictions Argmax [0 1 0 0 1 0 0 0 0 1 0 2 1 0 1 2 2 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 2 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 2]\n",
      "129\n",
      "Predictions Argmax [1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0]\n",
      "labels Flattened [1 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 2 0 0 0 0]\n",
      "161\n",
      "Predictions Argmax [0 0 2 0 1 2 1 0 0 1 2 1 0 0 0 1 1 0 2 2 1 0 0 1 0 0 0 1 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "193\n",
      "Predictions Argmax [1 1 2 1 0 0 2 1 0 1 0 0 0 1 0 0 1 0 0 2 2 1 1 1 0 0 1 0 0 1 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0]\n",
      "225\n",
      "Predictions Argmax [0 0 1 2 1 1 2 2 0 0 0 1 0 1 0 0 1 1 2 0 1 1 0 1 1 0 1 2 2 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 1 2 0 1 0 0 1 2 1 0 1]\n",
      "257\n",
      "Predictions Argmax [0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 0]\n",
      "289\n",
      "Predictions Argmax [0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 2 2 1 0 0 0 0 1 0 0 0 1]\n",
      "labels Flattened [0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "321\n",
      "Predictions Argmax [0 0 1 0 0 0 1 0 1 2 1 1 1 1 2 1 0 0 0 1 0 0 1 1 1 0 2 2 1 0 1 2]\n",
      "labels Flattened [1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 2 0 0 1 0 1]\n",
      "353\n",
      "Predictions Argmax [0 0 0 2 0 1 0 0 2 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 2 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "385\n",
      "Predictions Argmax [1 2 1 0 0 1 1 0 0 1 0 0 2 0 1 1 0 0 1 1 2 1 2 0 0 2 0 0 0 2 0 0]\n",
      "labels Flattened [0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 2 0 2 1 0 0 1 1 0 2 0 2 2]\n",
      "417\n",
      "Predictions Argmax [0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0]\n",
      "labels Flattened [1 0 0 2 0 0 0 0 0 0 0 1 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "449\n",
      "Predictions Argmax [2 1 0 1 0 1 0 0 0 1 1 0 2 0 1 1 1 0 1 1 2 2 1 1 0 0 1 0 0 2 0 1]\n",
      "labels Flattened [0 0 2 0 0 0 0 1 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "481\n",
      "Predictions Argmax [1 0 0 0 0 0 2 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0]\n",
      "labels Flattened [0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "513\n",
      "Predictions Argmax [2 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [1 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "545\n",
      "Predictions Argmax [1 2 0 0 0 1 1 2 1 1 0 0 0 0 0 1 1 0 0 1 1 1 2 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "577\n",
      "Predictions Argmax [2 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0]\n",
      "labels Flattened [0 0 2 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 1]\n",
      "609\n",
      "Predictions Argmax [0 0 0 2 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1]\n",
      "labels Flattened [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "641\n",
      "Predictions Argmax [0 0 1 1 0 0 2 0 1 0 1 0 1 2 1 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 2 0 0 2 0 0 0]\n",
      "673\n",
      "Predictions Argmax [0 0 1 0 1 0 2 1 1 0 0 2 0 2 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2]\n",
      "705\n",
      "Predictions Argmax [0 0 0 2 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 2]\n",
      "737\n",
      "Predictions Argmax [1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1]\n",
      "labels Flattened [1 0 0 2 1 0 0 0 0 0 2 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 2 0 0 0]\n",
      "769\n",
      "Predictions Argmax [1 0 1 0 2 1 2 0 0 1 1 0 0 2 0 0 0 1 0 2 0 0 0 0 0 1 1 1 0 2 0 0]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 1 0 0 0 0]\n",
      "801\n",
      "Predictions Argmax [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 2 0 1 2 1 1 1]\n",
      "labels Flattened [1 0 0 0 2 0 1 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0]\n",
      "833\n",
      "Predictions Argmax [1 0 2 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 2 0 0 1 0 2 1 0 1 0 2 1 0 0]\n",
      "labels Flattened [0 0 2 0 0 1 0 1 0 0 0 0 2 2 0 1 0 2 0 0 0 1 0 0 0 2 0 1 0 0 0 0]\n",
      "865\n",
      "Predictions Argmax [0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 2 1 0 0 0 1 0 0 1 1 0 1 2 1 0 0]\n",
      "labels Flattened [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "897\n",
      "Predictions Argmax [0 0 2 0 0 0 0 2 0 0 1 1 0 0 2 0 0 0 0 1 2 2 1 1 0 0 0 0 2 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0]\n",
      "929\n",
      "Predictions Argmax [0 0 0 0 1 0 1 2 0 0 1 0 2 0 1 0 0 2 1 0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
      "labels Flattened [2 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 2 0 0 0 0 1 0 0]\n",
      "961\n",
      "Predictions Argmax [0 0 2 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 2 0 1 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "993\n",
      "Predictions Argmax [0 1 0 1 0 0 0 0 1 0 0 2 0 0 2 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0]\n",
      "1025\n",
      "Predictions Argmax [0 0 1 0 0 2 2 0 1 1 1 2 0 0 0 0 0 0 0 2 0 2 1 0 0 0 0 1 1 1 0 1]\n",
      "labels Flattened [0 0 0 1 0 2 0 0 2 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      "1057\n",
      "Predictions Argmax [1 2 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 2 1 2 0 0 0 1 2 0 0 0]\n",
      "labels Flattened [2 1 1 2 0 0 0 0 0 0 0 0 0 1 2 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "1089\n",
      "Predictions Argmax [1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0]\n",
      "labels Flattened [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "1121\n",
      "Predictions Argmax [0 1 0 2 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 2 2 0 0 2 0 0 0 1 0]\n",
      "labels Flattened [0 0 2 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 1]\n",
      "1153\n",
      "Predictions Argmax [2 1 2 0 1 0 0 1 1 2 0 1 0 1 2 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 0 1 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1185\n",
      "Predictions Argmax [0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "1217\n",
      "Predictions Argmax [1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0]\n",
      "labels Flattened [0 0 1 0 0 1 0 0 1 1 0 0 2 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "1249\n",
      "Predictions Argmax [1 1 0 0 0 0 0 0 2 0 1 1 0 0 2 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "labels Flattened [0 1 0 0 1 1 0 1 0 0 0 0 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 1]\n",
      "1281\n",
      "Predictions Argmax [1 0 1 2 0 1 0 0 1 1 2 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 2 2 1 2 1 2]\n",
      "labels Flattened [0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "1313\n",
      "Predictions Argmax [1 0 0 0 0 1 1 0 0 0 0 0 0 2 0 0 1 0 0 0 1 0 0 0 2 0 2 0 0 1 1 1]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 0 0 1 0 1 2 0 0 0 1 0 1 0 0 0 0 0 1 0 0 2 0 1 0]\n",
      "1345\n",
      "Predictions Argmax [2 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 2 0 2]\n",
      "labels Flattened [0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "1377\n",
      "Predictions Argmax [0 0 0 0 1 1 0 0 0 0 0 0 0 1 2 0 1 0 1 0 2 0 1 0 1 0 0 1 0 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 1 2 0 0 0 0 0 0 0 0]\n",
      "1409\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
      "labels Flattened [1 0 0 1 1 0 0 1 0 0 0 2 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 2 1 0 0]\n",
      "1441\n",
      "Predictions Argmax [1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 2 0 0 2 1 1 0 1 0]\n",
      "labels Flattened [2 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "1473\n",
      "Predictions Argmax [0 0 1 0 0 0 2 0 0 1 1 1 0 1 0 0 0 2 0 1 1 0 0 0 0 0 1 0 0 2 0 1]\n",
      "labels Flattened [1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 2 0 0 0 0]\n",
      "1505\n",
      "Predictions Argmax [1 0 0 2 0 0 0 0 1 2 1 0 2 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1]\n",
      "labels Flattened [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 1 0 2 0 0]\n",
      "1537\n",
      "Predictions Argmax [0 0 1 0 1 2 1 2 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      "1569\n",
      "Predictions Argmax [0 0 1 1 1 0 1 1 0 1 2 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 2 1 0 0]\n",
      "labels Flattened [1 0 0 0 0 0 0 0 2 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 0 0 0]\n",
      "1601\n",
      "Predictions Argmax [1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 2 0 0 1 1 0 0 1 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 2 0 0 0 0 0 1 0 0 0 0]\n",
      "1633\n",
      "Predictions Argmax [0 0 2 0 0 0 0 0 0 0 0 0 1 0 1 1 1 2 0 0 1 2 1 1 0 2 1 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1665\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0]\n",
      "labels Flattened [2 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "1697\n",
      "Predictions Argmax [0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0]\n",
      "labels Flattened [0 0 0 1 2 1 0 2 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "1729\n",
      "Predictions Argmax [2 0 1 2 0 0 0 0 0 1 0 1 0 0 1 1 2 0 1 1 1 2 0 1 1 0 0 0 2 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 1 0 1 0 2 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0]\n",
      "1761\n",
      "Predictions Argmax [0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0]\n",
      "labels Flattened [0 0 0 0 2 0 0 0 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "1793\n",
      "Predictions Argmax [0 0 0 0 2 0 0 1 0 0 0 0 0 0 2 1 0 0 1 0 0 2 2 1 0 0 1 0 1 0 0 1]\n",
      "labels Flattened [0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1]\n",
      "1825\n",
      "Predictions Argmax [2 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1]\n",
      "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "1857\n",
      "Predictions Argmax [2 0 1 0 2 0 0 1 1 0 0 0 2 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 2 1 0 2 2 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "1889\n",
      "Predictions Argmax [0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 2 0 1 0 1 0 1 2 0 1 2 0 0 1 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 2 0 0 0 2 1 2 0 0 0]\n",
      "1921\n",
      "Predictions Argmax [1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 2 2 0 1 1 2 1 2 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 1 0 0 0 0 1 0 1 0 2 0 0 2 2 1 2 0]\n",
      "1953\n",
      "Predictions Argmax [0 1 1 0 0 0 0 0 0 0 2 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 2 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 2 0 0 0]\n",
      "1985\n",
      "Predictions Argmax [0 0 0 0 0 2 0 1 0 2 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 2 0 0 2 0 1]\n",
      "labels Flattened [1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      "2017\n",
      "Predictions Argmax [0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 1 1 0 1 0 0 1 0]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 1 1 0 0 0 1]\n",
      "2049\n",
      "Predictions Argmax [0 1 1 0 0 0 0 0 1 1 0 2 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 2 1 0 0 0 1 0 0 0 0 0 0 0 0 0 2 1]\n",
      "2081\n",
      "Predictions Argmax [1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 2 1 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 2 0 1 0 1 0 0 0 1 0 1 0 0 0 0 2 0]\n",
      "2113\n",
      "Predictions Argmax [0 0 0 0 1 0 1 1 2 1 0 0 1 0 0 0 2 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0]\n",
      "labels Flattened [0 0 1 0 0 0 1 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "2145\n",
      "Predictions Argmax [0 1 1 0 0 0 0 0 0 1 0 0 2 1 2 1 0 1 0 0 0 0 1 0 2 1 0 1 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0]\n",
      "2177\n",
      "Predictions Argmax [0 1 0 0 2 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 2 1 0 0 1]\n",
      "labels Flattened [1 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 2 2 0 0 1 1 0 0 0]\n",
      "2209\n",
      "Predictions Argmax [0 0 1 1 0 0 0 0 0 0 0 0 0 2 0 0 0 1 1 0 1 1 1 0 0 0 0 0 2 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0]\n",
      "2241\n",
      "Predictions Argmax [1 0 0 0 0 0 1 0 1 1 2 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 2 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 2 0 0 1 0 2 0 0 0 0 0 0 1]\n",
      "2273\n",
      "Predictions Argmax [1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 2 1 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "2305\n",
      "Predictions Argmax [0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 2 0 1 0 2 1 1]\n",
      "labels Flattened [2 1 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 2 0 0]\n",
      "2337\n",
      "Predictions Argmax [0 1 1 2 0 0 0 0 1 2 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 2 1 0 2 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0]\n",
      "2369\n",
      "Predictions Argmax [0 0 0 0 0 0 0 2 0 1 0 0 0 1 2 0 0 0 0 0 0 1 0 0 0 1 0 0 2 1 1 0]\n",
      "labels Flattened [1 1 0 0 0 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 0 1 0 0 0 1 0 0]\n",
      "2401\n",
      "Predictions Argmax [1 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 2 0 0 0 0 0 1]\n",
      "labels Flattened [1 0 0 0 0 0 1 1 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "2433\n",
      "Predictions Argmax [0 1 1 2 1 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 2 0 0]\n",
      "labels Flattened [0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 0 0 0]\n",
      "2465\n",
      "Predictions Argmax [0 0 1 0 1 0 2 0 0 0 0 0 0 0 0 0 1 1 1 0 0 2 0 0 1 1 0 0 1 0 1 0]\n",
      "labels Flattened [0 0 0 1 0 0 2 0 0 0 0 0 1 0 0 0 0 0 1 0 0 2 0 0 0 0 0 1 0 0 0 0]\n",
      "2497\n",
      "Predictions Argmax [0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 2 1 0 1]\n",
      "labels Flattened [0 0 0 0 0 2 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "2529\n",
      "Predictions Argmax [1 1 0 0 0 0 1 2 0 0 1 1 0 0 0 2 0 0 0 0 0 2 0 0 1 1 2 1 0 0 1 0]\n",
      "labels Flattened [0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "2561\n",
      "Predictions Argmax [1 0 1 2 2 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 2 0 0 1 0 0 2]\n",
      "labels Flattened [0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0]\n",
      "2593\n",
      "Predictions Argmax [0 0 1 0 0 1 1 0 1 0 2 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 2 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "2625\n",
      "Predictions Argmax [1 0 0 0 1 0 0 0 0 2 1 0 2 0 1 0 0 2 0 0 1 1 1 0 0 2 1 1 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 2 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      "2657\n",
      "Predictions Argmax [1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 2 0 0 0 1 0 1 2 1 0 1 0 0 0 1 0 1]\n",
      "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 1 2 0 0 0 2 0 1 0]\n",
      "2689\n",
      "Predictions Argmax [0 0 0 0 0 0 0 1 0 1 2 0 1 2 1 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 1]\n",
      "labels Flattened [0 2 0 0 1 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 2 0]\n",
      "2721\n",
      "Predictions Argmax [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 1 0 0 1 1 0 1 1 2 1 1 2]\n",
      "labels Flattened [0 0 1 0 0 2 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 1 0]\n",
      "2753\n",
      "Predictions Argmax [1 1 0 1 0 0 0 0 0 0 0 1 2 2 1 2 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 2 0 1 0]\n",
      "2785\n",
      "Predictions Argmax [0 1 2 0 1 2 2 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 2 0 2 1]\n",
      "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 2 0 1 0 0 0 1]\n",
      "2817\n",
      "Predictions Argmax [1 0 0 0 1 2 0 0 0 1 0 2 2 0 1 0 0 1 0 0 2 1 0 1 0 0 0 1 1 0 0 1]\n",
      "labels Flattened [0 2 0 0 0 2 0 2 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "2849\n",
      "Predictions Argmax [0 1 1 0 1 0 0 0 1 1 0 2 0 1 2 0 1 0 0 1 1 0 0 0 2 1 2 2 2 1 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "2881\n",
      "Predictions Argmax [0 1 0 0 0 0 1 0 2 0 0 2 2 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 2 2 0 1]\n",
      "2913\n",
      "Predictions Argmax [0 0 0 1 0 0 0 0 1 1 2 1 2 2 0 2 0 0 0 0 0 2 0 1 1 0 0 2 1 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0]\n",
      "2945\n",
      "Predictions Argmax [0 0 1 1 0 2 0 1 0 0 0 0 1 0 0 1 1 2 1 2 0 0 2 0 1 0 2 0 1 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 2 0 0 0 0 2 1 0 0 0]\n",
      "2977\n",
      "Predictions Argmax [2 0 1 1 1 0 0 1 0 0 0 0 1 1 2 1 0 1 2 0 2 1 0 0 0 1 1 0 0 0 0 0]\n",
      "labels Flattened [0 1 0 0 2 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 2 1 1 0 0 0 0 2 0 0 1]\n",
      "3009\n",
      "Predictions Argmax [1 0 0 1 1 2 0 0 0 0 1 1 0 0 0 1 1 0 2 0 1 1 1 2 0 0 2 2 1 2 1 0]\n",
      "labels Flattened [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 2 0 0 0 1 0 0]\n",
      "3041\n",
      "Predictions Argmax [1 1 0 2 1 0 0 0 0 2 0 1 0 2 1 1 0 1 0 2 0 0 1 1 1 0 1 0 0 1 1 2]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 2 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
      "3073\n",
      "Predictions Argmax [0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0]\n",
      "labels Flattened [0 0 1 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      "3105\n",
      "Predictions Argmax [0 2 1 0 1 1 1 0 0 1 0 0 2 0 0 2 0 0 0 0 1 1 0 1 0 0 2 0 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "3137\n",
      "Predictions Argmax [1 1 0 0 0 0 0 0 0 0 0 0 1 2 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 0 0 0 2 1 0 0 0 2 0 0 0 0 1 2]\n",
      "3169\n",
      "Predictions Argmax [0 1 2 1 1 0 1 2 0 0 1 0 0 1 0 0 2 1 1 0 2 0 0 0 0 0 1 0 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "3201\n",
      "Predictions Argmax [0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 2 0 1 0 1 0 1 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "3233\n",
      "Predictions Argmax [0 0 1 1 2 0 1 1 1 1 0 2 1 0 1 0 0 2 1 0 0 1 0 0 0 0 1 1 1 2 0 1]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 1 0 0 0 2 0 0 0 1]\n",
      "3265\n",
      "Predictions Argmax [2 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 2 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 2 0 2 0 0 1 1 0 0 0 0 0 2 0 0 1 0 0 0 2 1 0 0 0 0 0]\n",
      "3297\n",
      "Predictions Argmax [1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 2 0 0 2 0 1]\n",
      "labels Flattened [2 0 1 0 1 1 0 2 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3329\n",
      "Predictions Argmax [1 0 0 0 0 2 0 0 0 0 0 0 0 0 1 1 0 1 1 2 1 1 1 0 0 0 0 0 0 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      "3361\n",
      "Predictions Argmax [1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 2 0 1 2 0 0 1 0 0 1 0 0 2]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 1 0 0 0 0 0 0]\n",
      "3393\n",
      "Predictions Argmax [0 2 0 0 1 0 0 2 1 0 0 0 0 0 0 2 0 1 2 0 1 0 0 1 1 2 2 1 1 0 1 0]\n",
      "labels Flattened [0 1 2 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1]\n",
      "3425\n",
      "Predictions Argmax [1 0 0 1 0 1 0 2 1 0 0 1 0 1 2 1 0 0 1 1 0 0 1 1 2 0 1 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 2]\n",
      "3457\n",
      "Predictions Argmax [0 2 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 2 1 1 0 2 1 0 0 2 1 0 1 1 0 1]\n",
      "labels Flattened [0 1 0 2 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 2 1 1 0 0 1 0 0 0 0 1 0]\n",
      "3489\n",
      "Predictions Argmax [1 0 0 0 1 0 0 0 0 2 0 1 0 2 0 0 2 1 0 0 0 2 1 1 1 0 0 0 1 0 1 0]\n",
      "labels Flattened [1 0 0 0 0 0 0 0 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 2 2 1 2 0 0 0 0 0]\n",
      "3521\n",
      "Predictions Argmax [0 0 0 0 1 1 1 1 0 0 1 0 2 2 1 1 0 0 0 1 0 1 2 1 0 0 0 0 0 0 1 0]\n",
      "labels Flattened [0 0 0 1 2 0 0 0 0 2 0 2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3553\n",
      "Predictions Argmax [2 1 1 0 1 1 1 1 1 0 1 0 0 1 2 1 0 1 1 0 2 0 1 2 0 2 1 1 1 0 1 1]\n",
      "labels Flattened [0 0 0 2 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 2 1 0 1 0 0 0 2 0 0 0]\n",
      "3585\n",
      "Predictions Argmax [0 0 0 0 1 0 0 2 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 2 0 0 1 0 0 0 0]\n",
      "3617\n",
      "Predictions Argmax [2 0 1 1 0 0 0 1 0 0 1 0 0 1 2 0 0 1 1 0 0 2 0 0 0 1 1 1 0 0 0 0]\n",
      "labels Flattened [2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "3649\n",
      "Predictions Argmax [1 0 1 0 0 1 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "labels Flattened [1 2 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 2 0 2 0 0 1 0 2 0 0 1 1 0 0 1]\n",
      "3681\n",
      "Predictions Argmax [0 2 2 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 2 1 0 0 2 0 0]\n",
      "labels Flattened [0 1 0 2 1 0 0 0 0 0 0 0 2 2 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 2]\n",
      "3713\n",
      "Predictions Argmax [0 0 1 0 0 0 2 0 0 2 0 0 1 0 1 0 2 2 0 0 0 0 0 0 1 0 0 1 1 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 2 1 1 0 0 1 0 0 0 0 0 2 1 0 0 1 2]\n",
      "3745\n",
      "Predictions Argmax [1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 2 1 0 2 0 0 0 1 2 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3777\n",
      "Predictions Argmax [1 0 0 0 0 2 0 1 0 2 0 0 0 0 0 1 2 0 0 0 2 0 0 0 0 0 1 1 0 1 0 1]\n",
      "labels Flattened [1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3809\n",
      "Predictions Argmax [0 0 1 0 0 0 2 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 2 0 1 0 2]\n",
      "labels Flattened [0 0 0 1 1 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "3841\n",
      "Predictions Argmax [0 1 0 0 0 0 2 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 1]\n",
      "3873\n",
      "Predictions Argmax [1 0 0 0]\n",
      "labels Flattened [1 1 1 1]\n",
      "3877\n",
      "  F1 score: 0.304\n",
      "  Accuracy score: 0.521\n",
      "  Validating one epoch time taken  9.360229730606079\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=4\n",
    "lossList=[]\n",
    "if device.type==\"cpu\":\n",
    "     model.to(device)\n",
    "     map_location='cpu'\n",
    "else:\n",
    "      model.cuda()\n",
    "      map_location=lambda storage, loc: storage.cuda()\n",
    "checkpoint = torch.load('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BERTNEWsubtaskc.pth.tar',map_location=map_location)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "max_grad_norm=1.0\n",
    "t1 = time.time()\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "eval_f1=0\n",
    "eval_acc=0\n",
    " \n",
    "for batch_idx, data in enumerate(tedataloader):\n",
    "        \n",
    "      batch = tuple(t.to(device) for t in data)            \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "      with torch.no_grad():        \n",
    "         outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "      #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "t2=time.time()\n",
    "print(\"  Validating one epoch time taken \",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "QnjQQy3v4c3T",
    "outputId": "c029a8a3-4132-48e2-c54d-9a22f53ab496"
   },
   "outputs": [],
   "source": [
    "def toLabels(i):\n",
    "  if i=='0':\n",
    "    return 'IND'\n",
    "  elif i =='1':\n",
    "    return 'GRP'\n",
    "  else:\n",
    "    return 'OTH'\n",
    "\n",
    "tweetsOLID=englishdata[['id','tweet']]\n",
    "print(len(tweetsOLID))\n",
    "dfnumpy=tweetsOLID.to_numpy()\n",
    "TWEETS1=dfnumpy[:, 1].reshape(-1, 1).tolist()\n",
    "teets=np.squeeze(TWEETS1).tolist()\n",
    "print(teets)\n",
    "print(len(TWEETS1))\n",
    "data=pd.read_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/OLIDSUBTASKCBERT.csv')\n",
    "ypred=data['predicted'].to_numpy().tolist()\n",
    "len(ypred)\n",
    "ypred=ypred[1:]\n",
    "ypred=[toLabels(i) for i in ypred]\n",
    "#ypred=[ypred[i].flatten().tolist() for i in range(len(ypred))]\n",
    "print(ypred)\n",
    "print(len(ypred))\n",
    "ytrue=data['true'].to_numpy().tolist()\n",
    "ytrue=ytrue[1:]\n",
    "ytrue=[toLabels(i) for i in ytrue]\n",
    "#ytrue=[ytrue[i].flatten().tolist() for i in range(len(ytrue))]\n",
    "\n",
    "print(ytrue)\n",
    "print(len(ytrue))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['tweets']=teets\n",
    "data['predicted']=ypred\n",
    "data['true']=ytrue\n",
    "data.to_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/OLIDSUBTASKCBERT.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ezRXStHsENAx",
    "outputId": "aad13485-6575-4868-b52c-010837c8046c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf=confusion_matrix(ytrue, ypred, labels=['IND', 'GRP', 'OTH'])\n",
    "print(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "284cFyv3GPQW",
    "outputId": "e767b069-8912-42ea-cc5e-b17fb5d15ad1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(cnf,['IND', 'GRP', 'OTH'], ['IND', 'GRP', 'OTH'])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True,fmt='.2f') # font size\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL ind baseline result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w73MW1laq9_u"
   },
   "outputs": [],
   "source": [
    "ygiven=[]\n",
    "ypredicted=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiNRnoKuMmVw"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['predicted']=['X']\n",
    "data['true']=['X']\n",
    "data.to_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BASELINESUBTASKCBERT.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouJRJPjjMmV1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"Predictions Argmax\",predictionArgmax)\n",
    "  print(\"labels Flattened\",labelsFlattend)\n",
    "  data=pd.read_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BASELINESUBTASKCBERT.csv')#,converters={'predicted': eval,'true': eval})\n",
    "  ypred=data['predicted'].to_numpy().tolist()\n",
    "  for t in predictionArgmax:\n",
    "    ypred.append(t)\n",
    "\n",
    "  print(len(ypred))\n",
    "  ytrue=data['true'].to_numpy().tolist()\n",
    "  for t in labelsFlattend:\n",
    "    ytrue.append(t)\n",
    "  data = pd.DataFrame()\n",
    "  data['predicted']=ypred\n",
    "  data['true']=ytrue\n",
    "  data.to_csv('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BASELINESUBTASKCBERT.csv') \n",
    "\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNAIZ5Wbq994"
   },
   "outputs": [],
   "source": [
    "def readData1():\n",
    "  headers=['id','ypredicted']\n",
    "  greekdataBaseline = pd.read_csv(\"test_c_baseline.csv\", delimiter=',',names=headers)\n",
    "  #,converters={\"id\":convertToInt}       \n",
    "  #greekdataBaseline.id = greekdataBaseline.id.astype(int)\n",
    "  #greekdataBaseline=greekdataBaseline[1:]\n",
    "  print(greekdataBaseline.head())\n",
    "  print(greekdataBaseline.shape)\n",
    "\n",
    "  headers=['id','tweet']\n",
    "  greekDataTest = pd.read_csv(\"test_c_tweets.tsv\", delimiter='\\t',names=headers)\n",
    "                                #converters={\"id\":convertToInt})\n",
    "  #greekDataTest=greekDataTest[1:]\n",
    "  print(greekDataTest.head())\n",
    "  #print(greekDataTest.dtypes)\n",
    "  print(greekDataTest.shape)\n",
    "  result = pd.merge(greekDataTest, greekdataBaseline, on='id', how='inner')\n",
    "  print(result.head())\n",
    "  print(result.dtypes)\n",
    "  print(result.shape)\n",
    "\n",
    "  #result=\n",
    "  #result.sort_values(by=['id'], inplace=True)\n",
    "  #print(result.head())\n",
    "  dfnumpy=result.to_numpy();\n",
    "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
    "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  preprocessedTweets=X[:,0]\n",
    "  return preprocessedTweets,y,tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "Lgou-pTnq97z",
    "outputId": "f125595c-ad09-40e5-fe8b-7a3917295fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id ypredicted\n",
      "0   BC0        IND\n",
      "1   BC3        IND\n",
      "2   BC9        IND\n",
      "3  BC10        IND\n",
      "4  BC19        IND\n",
      "(850, 2)\n",
      "     id                                              tweet\n",
      "0    id                                              tweet\n",
      "1   BC0  @USER Lmao bihhh dis what u do to your homies ...\n",
      "2   BC3  @USER The POTUS is a racist, racist, racist, r...\n",
      "3   BC9  @USER He then grinned, raising his brow.  Oh d...\n",
      "4  BC10         Niggas priorities be fucked all the way up\n",
      "(851, 2)\n",
      "     id                                              tweet ypredicted\n",
      "0   BC0  @USER Lmao bihhh dis what u do to your homies ...        IND\n",
      "1   BC3  @USER The POTUS is a racist, racist, racist, r...        IND\n",
      "2   BC9  @USER He then grinned, raising his brow.  Oh d...        IND\n",
      "3  BC10         Niggas priorities be fucked all the way up        IND\n",
      "4  BC19  You bitches really be walking around talking s...        IND\n",
      "id            object\n",
      "tweet         object\n",
      "ypredicted    object\n",
      "dtype: object\n",
      "(850, 3)\n"
     ]
    }
   ],
   "source": [
    "preprocessedTweets,y,tid=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nx6XYg43q94R"
   },
   "outputs": [],
   "source": [
    "ftid=[]\n",
    "for t in tid.flatten().tolist():\n",
    "  ftid.append(int(t.split(\"BC\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCD9UC4sfL2_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "class GreekPredictDataset(Dataset):\n",
    "    def __init__(self,xypredict):\n",
    "        self.xypredict = xypredict\n",
    "        self.maxlength=128\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
    "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
    "        tid_predict_pytorch=torch.tensor(self.xypredict[2][index])\n",
    "        \n",
    "        return x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch,tid_predict_pytorch\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.xypredict[0])\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0CcvhMPDUy6"
   },
   "outputs": [],
   "source": [
    "yres=[]\n",
    "finalTid=[]\n",
    "def predictingData(pTweets,ypred,tid):\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ypredict=le.fit_transform(ypred.flatten())\n",
    "  map_location=\"\"\n",
    "  xypredict=[pTweets,ypredict,tid]\n",
    "  \n",
    "  tdataset = GreekPredictDataset(xypredict)\n",
    "  tsampler=RandomSampler(tdataset)\n",
    "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "  print(device.type)\n",
    "  model=bfsc.from_pretrained('bert-base-uncased',num_labels=3,output_attentions=False,output_hidden_states=False)\n",
    "  if device.type==\"cpu\":\n",
    "    model.to(device)\n",
    "    map_location='cpu'\n",
    "  else:\n",
    "    model.cuda()\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/EnglishData/SUBTASKC1/2/BERTNEWsubtaskc.pth.tar',map_location=map_location)\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "  i=0\n",
    "  for batch in predictdataloader:\n",
    "      print(i)\n",
    "      i=i+1\n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2],\"tids\":batch[3]}\n",
    "      \n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      trueLabels.append(label_ids)\n",
    "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
    "      finalTid.append(tidl)\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      \n",
    "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "  return predictedLabels,trueLabels,finalTid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "D3nsmTDD88jH",
    "outputId": "fe0c30e4-9942-41d7-d5a6-a4203c60a373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id ypredicted\n",
      "0   BC0        IND\n",
      "1   BC3        IND\n",
      "2   BC9        IND\n",
      "3  BC10        IND\n",
      "4  BC19        IND\n",
      "(850, 2)\n",
      "     id                                              tweet\n",
      "0    id                                              tweet\n",
      "1   BC0  @USER Lmao bihhh dis what u do to your homies ...\n",
      "2   BC3  @USER The POTUS is a racist, racist, racist, r...\n",
      "3   BC9  @USER He then grinned, raising his brow.  Oh d...\n",
      "4  BC10         Niggas priorities be fucked all the way up\n",
      "(851, 2)\n",
      "     id                                              tweet ypredicted\n",
      "0   BC0  @USER Lmao bihhh dis what u do to your homies ...        IND\n",
      "1   BC3  @USER The POTUS is a racist, racist, racist, r...        IND\n",
      "2   BC9  @USER He then grinned, raising his brow.  Oh d...        IND\n",
      "3  BC10         Niggas priorities be fucked all the way up        IND\n",
      "4  BC19  You bitches really be walking around talking s...        IND\n",
      "id            object\n",
      "tweet         object\n",
      "ypredicted    object\n",
      "dtype: object\n",
      "(850, 3)\n"
     ]
    }
   ],
   "source": [
    "#gpuname,device=initGpus1()  \n",
    "preprocessedTweets,y,tid=readData1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39EuSD1k9Ahz"
   },
   "outputs": [],
   "source": [
    "ftid=[]\n",
    "for t in tid.flatten().tolist():\n",
    "  ftid.append(int(t.split(\"BC\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bS2579tA9Dov"
   },
   "outputs": [],
   "source": [
    "tid=ftid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4i_Mve1H9I_t",
    "outputId": "138f09b1-200b-46b9-f9cb-d2f2adfbce6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IND'}"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULT ON all IND baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3mKwI2ef9Ld9",
    "outputId": "c29ad067-1cc9-4b35-d06e-3cd5b414d20b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n",
      "Predictions Argmax [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "1\n",
      "Predictions Argmax [0 0 1 0 0 1 0 1 2 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "65\n",
      "2\n",
      "Predictions Argmax [0 0 2 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "97\n",
      "3\n",
      "Predictions Argmax [1 1 1 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "129\n",
      "4\n",
      "Predictions Argmax [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "161\n",
      "5\n",
      "Predictions Argmax [0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "193\n",
      "6\n",
      "Predictions Argmax [0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 2 1 1 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "225\n",
      "7\n",
      "Predictions Argmax [0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "257\n",
      "8\n",
      "Predictions Argmax [1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "289\n",
      "9\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "321\n",
      "10\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 1 0 1 0 2 0 1 1 0 0 0 0 0 0 0 0 0 2 0 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "353\n",
      "11\n",
      "Predictions Argmax [0 0 0 0 0 0 1 1 0 2 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "385\n",
      "12\n",
      "Predictions Argmax [1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 2 0 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "417\n",
      "13\n",
      "Predictions Argmax [1 0 0 0 1 0 2 2 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 2 0 0 1 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "449\n",
      "14\n",
      "Predictions Argmax [0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 2 0 0 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "481\n",
      "15\n",
      "Predictions Argmax [0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "513\n",
      "16\n",
      "Predictions Argmax [1 0 1 2 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "545\n",
      "17\n",
      "Predictions Argmax [0 0 1 0 1 0 0 1 1 2 1 0 0 0 0 0 1 2 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "577\n",
      "18\n",
      "Predictions Argmax [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 2 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "609\n",
      "19\n",
      "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "641\n",
      "20\n",
      "Predictions Argmax [0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "673\n",
      "21\n",
      "Predictions Argmax [0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "705\n",
      "22\n",
      "Predictions Argmax [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 2 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "737\n",
      "23\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 2 0 1 0 0 0 0 0 0 1 1 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "769\n",
      "24\n",
      "Predictions Argmax [0 1 0 0 1 0 2 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "801\n",
      "25\n",
      "Predictions Argmax [0 0 2 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 2]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "833\n",
      "26\n",
      "Predictions Argmax [0 1 0 0 1 0 0 0 0 2 1 0 1 0 1 0 0 1]\n",
      "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "851\n",
      "  F1 score: 0.337\n",
      "  Accuracy score: 0.762\n"
     ]
    }
   ],
   "source": [
    "predictedLabels,trueLabels,finalTid=predictingData(preprocessedTweets,y,tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzyQ9dRN9PIH"
   },
   "outputs": [],
   "source": [
    "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
    "ytrue=[trueLabels[i].flatten().tolist() for i in range(len(trueLabels))]\n",
    "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixnRwaNl9S4X"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "yans=list(chain.from_iterable(yans))\n",
    "\n",
    "ytrue=list(chain.from_iterable(ytrue))\n",
    "\n",
    "ytid=list(chain.from_iterable(ytid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mDieJRSQRnBc",
    "outputId": "35f92a7e-20e1-4644-d5fe-0b81830d8d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUFlIuBE9YEf"
   },
   "outputs": [],
   "source": [
    "ytid2=[\"BC\"+str(t) for t in ytid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REE5x9ofRr-T"
   },
   "outputs": [],
   "source": [
    "len(ytid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "le60Azr-EHrG"
   },
   "outputs": [],
   "source": [
    "yans1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKylH_QNGHL6"
   },
   "outputs": [],
   "source": [
    "yans3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gD4MoT1aAB-B"
   },
   "outputs": [],
   "source": [
    "yans1=[]\n",
    "for i in range(len(yans)):\n",
    "  if yans[i]==0:\n",
    "    yans3.append(\"IND\")\n",
    "  elif yans[i]==1:\n",
    "    yans3.append(\"GRP\")\n",
    "  else:\n",
    "    yans3.append(\"OTH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAJQxwr5G_OV"
   },
   "outputs": [],
   "source": [
    "ytrue3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXQRYq92Aj3D"
   },
   "outputs": [],
   "source": [
    "for i in range(len(ytrue)):\n",
    "  if ytrue[i]==0:\n",
    "    ytrue3.append(\"IND\")\n",
    "  elif ytrue[i]==1:\n",
    "    ytrue3.append(\"GRP\")\n",
    "  else:\n",
    "    ytrue3.append(\"OTH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcZ3NkNB9ipY"
   },
   "outputs": [],
   "source": [
    "print(yans3.count(\"IND\"))\n",
    "print(yans3.count(\"GRP\"))\n",
    "print(yans3.count(\"OTH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_68h4bXDZPb"
   },
   "outputs": [],
   "source": [
    "len(yans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlCkm0Mc9jE9"
   },
   "outputs": [],
   "source": [
    "print(ytrue3.count(\"IND\"))\n",
    "print(ytrue3.count(\"GRP\"))\n",
    "print(ytrue3.count(\"OTH\"))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SUBTASKCFINAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
