{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "8c165e9a-3578-41cc-fb44-6a7e97401e97"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "46Fpl7WYdNu0",
    "outputId": "360098a9-61a4-49eb-fa1e-ab865b0be66f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1nweMDxcWic"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "81a84a4c-2b0b-4fb6-e1fc-ff3d73bb27b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n",
      "The device name is Tesla K80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  gpuname=\"\"\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  n_gpu=torch.cuda.device_count()\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "d61d278a-c24b-44a7-de4d-df8e0be6c4b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0iCZDHmlWSjY",
    "outputId": "888d07e6-e246-44cf-f342-c9c344f3e644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace task_c_distant_ann.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##NOT FOR SYSTEMS\n",
    "!unzip -P ****** -qq '/content/drive/My Drive/EnglishData/task_c_distant.zip' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ayt4_mQnr5n7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "headers=['id','text','average_ind','average_grp','average_oth','std_ind','std_grp','std_oth']\n",
    "taskc = pd.read_csv(\"task_c_distant_ann.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average_ind\":convertToFloat,\n",
    "                                                                                                    \"average_grp\":convertToFloat,\n",
    "                                                                                                    \"average_oth\":convertToFloat,\n",
    "                                                                                                    \"std_ind\":convertToFloat,\n",
    "                                                                                                    \"std_grp\":convertToFloat,\n",
    "                                                                                                    \"std_oth\":convertToFloat})\n",
    "taskc=taskc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m-dCmH8dThOD",
    "outputId": "f6c14b87-8571-4325-8c5c-10cdf651e8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188973"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taskc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "2uXSsl4DrvPa",
    "outputId": "2a42fca8-5906-4abf-d46f-fcd4fa91f75d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              object\n",
       "text            object\n",
       "average_ind    float64\n",
       "average_grp    float64\n",
       "average_oth    float64\n",
       "std_ind        float64\n",
       "std_grp        float64\n",
       "std_oth        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
    "englishdata = pd.read_csv(\"/content/drive/My Drive/EnglishData/OLIDv1.0/olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
    "englishdata=englishdata[['id','tweet','subtask_c']]\n",
    "englishdata=englishdata[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKDwFMQdrusQ"
   },
   "outputs": [],
   "source": [
    "englishdata = englishdata.dropna(subset=['subtask_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "B9dY5nerCi3z",
    "outputId": "ce9f5277-2dec-4714-8603-68cd14871b3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52415</td>\n",
       "      <td>@USER was literally just talking about this lo...</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13384</td>\n",
       "      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28414</td>\n",
       "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              tweet subtask_c\n",
       "2   90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       IND\n",
       "6   97670                  @USER Liberals are all Kookoo !!!       OTH\n",
       "8   52415  @USER was literally just talking about this lo...       GRP\n",
       "10  13384  @USER Canada doesn’t need another CUCK! We alr...       IND\n",
       "13  28414  @USER you are a lying corrupt traitor!!! Nobod...       IND"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "85xVmaYRHFab",
    "outputId": "8c230493-0744-4ec2-e286-6163c4bd65d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\\nexport_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\\nprint (englishtrain.head())\\n#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\\nexport_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\\nprint (englishtest.head())\""
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\n",
    "export_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtrain.head())\n",
    "#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\n",
    "export_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtest.head())'''\n",
    "#export_csv = englishpredict.to_csv ('/content/drive/My Drive/EnglishData/predictFileEnglish.csv', index = None, header=True)\n",
    "#print (englishpredict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn8dOMH10Cla"
   },
   "outputs": [],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "\n",
    "def giveIds(sentence):\n",
    "  maxlength=0\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "  return maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMeqzRH7LS5Q"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a40P-fEPNwSC",
    "outputId": "2635c72f-8c70-4292-81f8-6e66fd721327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking (mean - std deviation) as score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqEXLUu-KN6b"
   },
   "outputs": [],
   "source": [
    "\n",
    "def getNewLabel(y1,y2):\n",
    "  i=0\n",
    "  largest_index=0\n",
    "  #label1=['IND','GRP','OTH']\n",
    "  ylabels=[]\n",
    "  for r in y1:\n",
    "    ylabels.append(y1[i]-y2[i])\n",
    "    i=i+1;\n",
    "  return ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmbrouMtLk4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfnumpy=taskc.to_numpy();\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train1=dfnumpy[:, 2].reshape(-1, 1)\n",
    "y_train2=dfnumpy[:, 3].reshape(-1, 1)\n",
    "y_train3=dfnumpy[:, 4].reshape(-1, 1)\n",
    "y_std1=dfnumpy[:, 5].reshape(-1, 1)\n",
    "y_std2=dfnumpy[:, 6].reshape(-1, 1)\n",
    "y_std3=dfnumpy[:, 7].reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0djsY5LtTPc"
   },
   "outputs": [],
   "source": [
    "y_t1=getNewLabel(y_train1,y_std1)\n",
    "y_t2=getNewLabel(y_train2,y_std2)\n",
    "y_t3=getNewLabel(y_train3,y_std3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEBKnFqftO5_"
   },
   "outputs": [],
   "source": [
    "y1=giveLabel(y_t1,y_t2,y_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVBwzETtK9a-"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "x_test=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_test=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzsKG85LBeb-"
   },
   "outputs": [],
   "source": [
    "#preprocessedTweets=x_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_NKcxDqLOGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train,y_train=shuffle(x_train,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_KQpestKlz4"
   },
   "outputs": [],
   "source": [
    "#x_train,x_test,y_train,y_test= train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0E_1X_qqOw8Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def giveLabel2(y1):\n",
    "  i=0\n",
    "  largest_index=0\n",
    "  #label1=['IND','GRP','OTH']\n",
    "  ylabels=[]\n",
    "  for r in y1:\n",
    "    if (r==\"IND\"): \n",
    "        largest_index = 0 \n",
    "    elif (r==\"GRP\"):\n",
    "        largest_index = 1 \n",
    "    else: \n",
    "        largest_index = 2 \n",
    "    \n",
    "    ylabels.append(largest_index)\n",
    "    i=i+1;\n",
    "  return ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "BSZGqjvlBIDa",
    "outputId": "a35fb97c-20ea-4f83-9515-74b45a1c5919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3876, 1)\n",
      "(188973,)\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "#print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_predict.shape)\n",
    "yTrain=le.fit_transform(y_train)\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "#le.fit_transform(['IND','GRP','OTH'])\n",
    "yl=giveLabel2(y_test.flatten())\n",
    "yTest=le.fit_transform(y1)\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMCPsKyZBK7f",
    "outputId": "e06eb8bb-b191-4fa4-f7c8-192b8e272a29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11832"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest.flatten().tolist().count(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZbZxkgcBhfag",
    "outputId": "e036bda7-4965-4b19-f276-54620ba5474c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-uncased',num_labels=3,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZPr_Sj12LY-y",
    "outputId": "0c88d74d-3eea-4e44-89f6-d47b7d39cdc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ONLY FOR THE FIRST TIME SAVE ELSE LOAD\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertsubtaskcworst.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertsubtaskcworst.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDzvjKyWMio7"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQQ5__z5Mio-"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frZAYslgMipB"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au4tTkrfMipE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSdEEzMJMipH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"Predictions Argmax\",predictionArgmax)\n",
    "  print(\"labels Flattened\",labelsFlattend)   \n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwqSDP2KL71z"
   },
   "outputs": [],
   "source": [
    "MAXLENGTH=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTurXRofNATj",
    "outputId": "ebf7e0d8-58f1-46ba-e77b-388d5d9cb6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nz=0;\\nfor batch_idx, data in enumerate(tdataloader): \\n  if z==100:\\n    break;\\n  z=z+1;'"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnglishTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])\n",
    " \n",
    "\n",
    "'''\n",
    "z=0;\n",
    "for batch_idx, data in enumerate(tdataloader): \n",
    "  if z==100:\n",
    "    break;\n",
    "  z=z+1;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U47_yavmOa7S"
   },
   "outputs": [],
   "source": [
    "class EnglishTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VObEL94h-bU8"
   },
   "outputs": [],
   "source": [
    "#xytrain=[x_train[:8000],y_train[:8000]]\\\n",
    "MAXLENGTH=64\n",
    "xytrain=[x_train,yTrain]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tdataset = EnglishTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjp1U9q9xaI"
   },
   "outputs": [],
   "source": [
    "\n",
    "#xytest=[x_test[:8000],y_test[:8000]]\n",
    "xytest=[x_test,yTest]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tedataset = EnglishTestDataset(xytest) \n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
    "#trainData(tdataloader,tedataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rPrZ3_M-LZx"
   },
   "outputs": [],
   "source": [
    "epochs=2\n",
    "total_steps=len(tdataloader)*epochs\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kp-PmVUP9N9c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cqmnbPGdMipR",
    "outputId": "6399f398-027a-482d-cf96-972d809d04b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch Number 1\n",
      "Start Training\n",
      "Batch Completed  50  of  5,906.    Elapsed time is  34.81188607215881\n",
      "Batch Completed  100  of  5,906.    Elapsed time is  69.43283224105835\n",
      "Batch Completed  150  of  5,906.    Elapsed time is  104.00731062889099\n",
      "Batch Completed  200  of  5,906.    Elapsed time is  138.65957117080688\n",
      "Batch Completed  250  of  5,906.    Elapsed time is  173.25541973114014\n",
      "Batch Completed  300  of  5,906.    Elapsed time is  207.8219439983368\n",
      "Batch Completed  350  of  5,906.    Elapsed time is  242.4476125240326\n",
      "Batch Completed  400  of  5,906.    Elapsed time is  277.0151674747467\n",
      "Batch Completed  450  of  5,906.    Elapsed time is  311.5773117542267\n",
      "Batch Completed  500  of  5,906.    Elapsed time is  346.15000319480896\n",
      "Batch Completed  550  of  5,906.    Elapsed time is  380.71263575553894\n",
      "Batch Completed  600  of  5,906.    Elapsed time is  415.32913041114807\n",
      "Batch Completed  650  of  5,906.    Elapsed time is  449.93105363845825\n",
      "Batch Completed  700  of  5,906.    Elapsed time is  484.51293420791626\n",
      "Batch Completed  750  of  5,906.    Elapsed time is  519.1139278411865\n",
      "Batch Completed  800  of  5,906.    Elapsed time is  553.6900639533997\n",
      "Batch Completed  850  of  5,906.    Elapsed time is  588.2930958271027\n",
      "Batch Completed  900  of  5,906.    Elapsed time is  622.9138717651367\n",
      "Batch Completed  950  of  5,906.    Elapsed time is  657.523589849472\n",
      "Batch Completed  1,000  of  5,906.    Elapsed time is  692.1292884349823\n",
      "Batch Completed  1,050  of  5,906.    Elapsed time is  726.6560020446777\n",
      "Batch Completed  1,100  of  5,906.    Elapsed time is  761.1789479255676\n",
      "Batch Completed  1,150  of  5,906.    Elapsed time is  795.7136967182159\n",
      "Batch Completed  1,200  of  5,906.    Elapsed time is  830.2596774101257\n",
      "Batch Completed  1,250  of  5,906.    Elapsed time is  864.8075416088104\n",
      "Batch Completed  1,300  of  5,906.    Elapsed time is  899.4039416313171\n",
      "Batch Completed  1,350  of  5,906.    Elapsed time is  933.9817147254944\n",
      "Batch Completed  1,400  of  5,906.    Elapsed time is  968.6020777225494\n",
      "Batch Completed  1,450  of  5,906.    Elapsed time is  1003.1854479312897\n",
      "Batch Completed  1,500  of  5,906.    Elapsed time is  1037.7301959991455\n",
      "Batch Completed  1,550  of  5,906.    Elapsed time is  1072.345759153366\n",
      "Batch Completed  1,600  of  5,906.    Elapsed time is  1106.9239003658295\n",
      "Batch Completed  1,650  of  5,906.    Elapsed time is  1141.4886467456818\n",
      "Batch Completed  1,700  of  5,906.    Elapsed time is  1176.0465750694275\n",
      "Batch Completed  1,750  of  5,906.    Elapsed time is  1210.6553647518158\n",
      "Batch Completed  1,800  of  5,906.    Elapsed time is  1245.2139229774475\n",
      "Batch Completed  1,850  of  5,906.    Elapsed time is  1279.7676236629486\n",
      "Batch Completed  1,900  of  5,906.    Elapsed time is  1314.3375222682953\n",
      "Batch Completed  1,950  of  5,906.    Elapsed time is  1348.8666956424713\n",
      "Batch Completed  2,000  of  5,906.    Elapsed time is  1383.47110581398\n",
      "Batch Completed  2,050  of  5,906.    Elapsed time is  1418.0460748672485\n",
      "Batch Completed  2,100  of  5,906.    Elapsed time is  1452.620521068573\n",
      "Batch Completed  2,150  of  5,906.    Elapsed time is  1487.173351764679\n",
      "Batch Completed  2,200  of  5,906.    Elapsed time is  1521.7777745723724\n",
      "Batch Completed  2,250  of  5,906.    Elapsed time is  1556.3524568080902\n",
      "Batch Completed  2,300  of  5,906.    Elapsed time is  1590.8769986629486\n",
      "Batch Completed  2,350  of  5,906.    Elapsed time is  1625.4796555042267\n",
      "Batch Completed  2,400  of  5,906.    Elapsed time is  1660.105742931366\n",
      "Batch Completed  2,450  of  5,906.    Elapsed time is  1694.7063119411469\n",
      "Batch Completed  2,500  of  5,906.    Elapsed time is  1729.3627626895905\n",
      "Batch Completed  2,550  of  5,906.    Elapsed time is  1763.989996433258\n",
      "Batch Completed  2,600  of  5,906.    Elapsed time is  1798.5504291057587\n",
      "Batch Completed  2,650  of  5,906.    Elapsed time is  1833.1338546276093\n",
      "Batch Completed  2,700  of  5,906.    Elapsed time is  1867.7331550121307\n",
      "Batch Completed  2,750  of  5,906.    Elapsed time is  1902.3096718788147\n",
      "Batch Completed  2,800  of  5,906.    Elapsed time is  1936.899231672287\n",
      "Batch Completed  2,850  of  5,906.    Elapsed time is  1971.4172868728638\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=2\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    \n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    if device.type==\"cpu\":\n",
    "     model.to(device)\n",
    "     map_location='cpu'\n",
    "    else:\n",
    "      model.cuda()\n",
    "      map_location=lambda storage, loc: storage.cuda()\n",
    "    checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertsubtaskcworst.pth.tar',map_location=map_location)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()        \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "    \n",
    "    for batch_idx, data in enumerate(tedataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in data)            \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "           outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "    torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertsubtaskcworst.pth.tar')\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "      \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w73MW1laq9_u"
   },
   "outputs": [],
   "source": [
    "ygiven=[]\n",
    "ypredicted=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNAIZ5Wbq994"
   },
   "outputs": [],
   "source": [
    "def readData1():\n",
    "  headers=['id','ypredicted']\n",
    "  greekdataBaseline = pd.read_csv(\"test_c_baseline.csv\", delimiter=',',names=headers)\n",
    "  #,converters={\"id\":convertToInt}       \n",
    "  #greekdataBaseline.id = greekdataBaseline.id.astype(int)\n",
    "  #greekdataBaseline=greekdataBaseline[1:]\n",
    "  print(greekdataBaseline.head())\n",
    "  print(greekdataBaseline.shape)\n",
    "\n",
    "  headers=['id','tweet']\n",
    "  greekDataTest = pd.read_csv(\"test_c_tweets.tsv\", delimiter='\\t',names=headers)\n",
    "                                #converters={\"id\":convertToInt})\n",
    "  #greekDataTest=greekDataTest[1:]\n",
    "  print(greekDataTest.head())\n",
    "  #print(greekDataTest.dtypes)\n",
    "  print(greekDataTest.shape)\n",
    "  result = pd.merge(greekDataTest, greekdataBaseline, on='id', how='inner')\n",
    "  print(result.head())\n",
    "  print(result.dtypes)\n",
    "  print(result.shape)\n",
    "\n",
    "  #result=\n",
    "  #result.sort_values(by=['id'], inplace=True)\n",
    "  #print(result.head())\n",
    "  dfnumpy=result.to_numpy();\n",
    "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
    "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  preprocessedTweets=X[:,0]\n",
    "  return preprocessedTweets,y,tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "Lgou-pTnq97z",
    "outputId": "f14baedf-69ff-46bb-ef5c-57b545286418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id ypredicted\n",
      "0   BC0        IND\n",
      "1   BC3        IND\n",
      "2   BC9        IND\n",
      "3  BC10        IND\n",
      "4  BC19        IND\n",
      "(850, 2)\n",
      "     id                                              tweet\n",
      "0    id                                              tweet\n",
      "1   BC0  @USER Lmao bihhh dis what u do to your homies ...\n",
      "2   BC3  @USER The POTUS is a racist, racist, racist, r...\n",
      "3   BC9  @USER He then grinned, raising his brow.  Oh d...\n",
      "4  BC10         Niggas priorities be fucked all the way up\n",
      "(851, 2)\n",
      "     id                                              tweet ypredicted\n",
      "0   BC0  @USER Lmao bihhh dis what u do to your homies ...        IND\n",
      "1   BC3  @USER The POTUS is a racist, racist, racist, r...        IND\n",
      "2   BC9  @USER He then grinned, raising his brow.  Oh d...        IND\n",
      "3  BC10         Niggas priorities be fucked all the way up        IND\n",
      "4  BC19  You bitches really be walking around talking s...        IND\n",
      "id            object\n",
      "tweet         object\n",
      "ypredicted    object\n",
      "dtype: object\n",
      "(850, 3)\n"
     ]
    }
   ],
   "source": [
    "preprocessedTweets,y,tid=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nx6XYg43q94R"
   },
   "outputs": [],
   "source": [
    "ftid=[]\n",
    "for t in tid.flatten().tolist():\n",
    "  ftid.append(int(t.split(\"BC\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCD9UC4sfL2_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "class GreekPredictDataset(Dataset):\n",
    "    def __init__(self,xypredict):\n",
    "        self.xypredict = xypredict\n",
    "        self.maxlength=128\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
    "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
    "        tid_predict_pytorch=torch.tensor(self.xypredict[2][index])\n",
    "        \n",
    "        return x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch,tid_predict_pytorch\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.xypredict[0])\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT-hPPlCfaqh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  yres.append(predictionArgmax.flatten())\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    "  print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0CcvhMPDUy6"
   },
   "outputs": [],
   "source": [
    "yres=[]\n",
    "finalTid=[]\n",
    "def predictingData(pTweets,ypred,tid):\n",
    "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ypredict=le.fit_transform(ypred.flatten())\n",
    "  map_location=\"\"\n",
    "  xypredict=[pTweets,ypredict,tid]\n",
    "  \n",
    "  tdataset = GreekPredictDataset(xypredict)\n",
    "  tsampler=RandomSampler(tdataset)\n",
    "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "  print(device.type)\n",
    "  model=bfsc.from_pretrained('bert-base-uncased',num_labels=3,output_attentions=False,output_hidden_states=False)\n",
    "  if device.type==\"cpu\":\n",
    "    model.to(device)\n",
    "    map_location='cpu'\n",
    "  else:\n",
    "    model.cuda()\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertsubtaskcworst.pth.tar',map_location=map_location)\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "  i=0\n",
    "  for batch in predictdataloader:\n",
    "      print(i)\n",
    "      i=i+1\n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2],\"tids\":batch[3]}\n",
    "      \n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      trueLabels.append(label_ids)\n",
    "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
    "      finalTid.append(tidl)\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      \n",
    "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "  return predictedLabels,trueLabels,finalTid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "D3nsmTDD88jH",
    "outputId": "a9b993f8-7ae4-4fbd-ede7-a0fe8e7fe20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id ypredicted\n",
      "0   BC0        IND\n",
      "1   BC3        IND\n",
      "2   BC9        IND\n",
      "3  BC10        IND\n",
      "4  BC19        IND\n",
      "(850, 2)\n",
      "     id                                              tweet\n",
      "0    id                                              tweet\n",
      "1   BC0  @USER Lmao bihhh dis what u do to your homies ...\n",
      "2   BC3  @USER The POTUS is a racist, racist, racist, r...\n",
      "3   BC9  @USER He then grinned, raising his brow.  Oh d...\n",
      "4  BC10         Niggas priorities be fucked all the way up\n",
      "(851, 2)\n",
      "     id                                              tweet ypredicted\n",
      "0   BC0  @USER Lmao bihhh dis what u do to your homies ...        IND\n",
      "1   BC3  @USER The POTUS is a racist, racist, racist, r...        IND\n",
      "2   BC9  @USER He then grinned, raising his brow.  Oh d...        IND\n",
      "3  BC10         Niggas priorities be fucked all the way up        IND\n",
      "4  BC19  You bitches really be walking around talking s...        IND\n",
      "id            object\n",
      "tweet         object\n",
      "ypredicted    object\n",
      "dtype: object\n",
      "(850, 3)\n"
     ]
    }
   ],
   "source": [
    "#gpuname,device=initGpus1()  \n",
    "preprocessedTweets,y,tid=readData1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39EuSD1k9Ahz"
   },
   "outputs": [],
   "source": [
    "ftid=[]\n",
    "for t in tid.flatten().tolist():\n",
    "  ftid.append(int(t.split(\"BC\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bS2579tA9Dov"
   },
   "outputs": [],
   "source": [
    "tid=ftid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4i_Mve1H9I_t",
    "outputId": "9b7b72f6-c13f-4d41-bb71-8cc58515c971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IND'}"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3mKwI2ef9Ld9",
    "outputId": "70be2c6a-e845-4268-96b9-97ca45729adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Hello\n",
      "0\n",
      "predictionArgmax [0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1\n",
      "predictionArgmax [0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "predictionArgmax [0 0 1 0 1 1 0 0 1 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 1 2 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "predictionArgmax [1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 2 0 0 1 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "predictionArgmax [1 0 0 2 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 2 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "8\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "predictionArgmax [0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 2 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "10\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 2 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "11\n",
      "predictionArgmax [0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "12\n",
      "predictionArgmax [0 1 0 0 0 0 1 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "13\n",
      "predictionArgmax [1 2 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "14\n",
      "predictionArgmax [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 2 0 0 0 0 0 2 1 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "16\n",
      "predictionArgmax [0 0 0 2 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 2 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "17\n",
      "predictionArgmax [0 1 0 0 0 0 0 2 0 0 2 2 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 2 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "18\n",
      "predictionArgmax [2 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "19\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "20\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "21\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "22\n",
      "predictionArgmax [0 0 0 2 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "23\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "24\n",
      "predictionArgmax [0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "25\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "26\n",
      "predictionArgmax [0 0 0 1 1 0 0 0 2 0 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  F1 score: 0.331\n",
      "  Accuracy score: 0.747\n"
     ]
    }
   ],
   "source": [
    "predictedLabels,trueLabels,finalTid=predictingData(preprocessedTweets,y,tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzyQ9dRN9PIH"
   },
   "outputs": [],
   "source": [
    "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
    "ytrue=[trueLabels[i].flatten().tolist() for i in range(len(trueLabels))]\n",
    "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixnRwaNl9S4X"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "yans=list(chain.from_iterable(yans))\n",
    "\n",
    "ytrue=list(chain.from_iterable(ytrue))\n",
    "\n",
    "ytid=list(chain.from_iterable(ytid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUFlIuBE9YEf"
   },
   "outputs": [],
   "source": [
    "ytid2=[\"BC\"+str(t) for t in ytid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "le60Azr-EHrG"
   },
   "outputs": [],
   "source": [
    "yans1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKylH_QNGHL6"
   },
   "outputs": [],
   "source": [
    "yans3=[]\n",
    "#yans3.append(\"IND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gD4MoT1aAB-B"
   },
   "outputs": [],
   "source": [
    "yans1=[]\n",
    "for i in range(len(yans)):\n",
    "  if yans[i]==0:\n",
    "    yans3.append(\"IND\")\n",
    "  elif yans[i]==1:\n",
    "    yans3.append(\"GRP\")\n",
    "  else:\n",
    "    yans3.append(\"OTH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAJQxwr5G_OV"
   },
   "outputs": [],
   "source": [
    "ytrue3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXQRYq92Aj3D"
   },
   "outputs": [],
   "source": [
    "for i in range(len(ytrue)):\n",
    "  if ytrue[i]==0:\n",
    "    ytrue3.append(\"IND\")\n",
    "  elif ytrue[i]==1:\n",
    "    ytrue3.append(\"GRP\")\n",
    "  else:\n",
    "    ytrue3.append(\"OTH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "4ceos-lg9a4_",
    "outputId": "53d606e2-51d1-4183-9ac1-c3db83f3f6c9"
   },
   "outputs": [],
   "source": [
    "#yans1=[\"IND\" if yans[i]==0 \"GRP\" elif yans[i]==1 else \"OTH\" for i in range(len(yans))]\n",
    "#ytrue1=[\"IND\" if ytrue[i]==0 \"GRP\" elif ytrue[i]==1 else \"OTH\" for i in range(len(ytrue))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "zcZ3NkNB9ipY",
    "outputId": "0771be45-4757-4739-ba20-57db99f5e5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635\n",
      "188\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(yans3.count(\"IND\"))\n",
    "print(yans3.count(\"GRP\"))\n",
    "print(yans3.count(\"OTH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M_68h4bXDZPb",
    "outputId": "46ef503c-d3dd-493c-f681-5824134a0a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yans3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SUBTASKC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
