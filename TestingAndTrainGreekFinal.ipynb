{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestingAndTrainGreekPhase1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b88bf36131364ef9a6c0a5ebc855baef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ec008f15cd24d4dada574b98a8859d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b2eafbf491946b4a32bf991d210e889",
              "IPY_MODEL_8a80aeb5e20947df948cf55a72e3d8a0"
            ]
          }
        },
        "4ec008f15cd24d4dada574b98a8859d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b2eafbf491946b4a32bf991d210e889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db4210f2af2040f8b043212166c0257d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aae73cf9b076463492a01ef354f0e0c2"
          }
        },
        "8a80aeb5e20947df948cf55a72e3d8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06e03ad0d3ca468fb969bfbd7bd14409",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:01&lt;00:00, 897kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09efaf2baccd40638e10c539b074d954"
          }
        },
        "db4210f2af2040f8b043212166c0257d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aae73cf9b076463492a01ef354f0e0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06e03ad0d3ca468fb969bfbd7bd14409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09efaf2baccd40638e10c539b074d954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44448dab32354f398a7b12ec3fda8d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d5a161ebdf346a3b3cbe48556818ba0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_908cde692e5f4f9da889829870505cca",
              "IPY_MODEL_d0cc333952f340c29834760a2b3e39bb"
            ]
          }
        },
        "0d5a161ebdf346a3b3cbe48556818ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "908cde692e5f4f9da889829870505cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a48382d23424fa4b1133834995867d9",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2527c696adc400485cd882a0c1af854"
          }
        },
        "d0cc333952f340c29834760a2b3e39bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b3c792bd9074ba6a1ba28a68bfe87e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 31.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4addf242d7ba44edbcc7772ecc0b1aeb"
          }
        },
        "4a48382d23424fa4b1133834995867d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2527c696adc400485cd882a0c1af854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b3c792bd9074ba6a1ba28a68bfe87e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4addf242d7ba44edbcc7772ecc0b1aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "909b975e587d4e478ae18cb14cb72ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3617ad3922624e4fb35773a616994fb0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be0be54852464913844254440eb8281e",
              "IPY_MODEL_02762057c5424618a972fb34c64f6011"
            ]
          }
        },
        "3617ad3922624e4fb35773a616994fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be0be54852464913844254440eb8281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cff01522d0f44d88f9bb57acd58f895",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10fc9448465e4b2a90c8ca052459c16e"
          }
        },
        "02762057c5424618a972fb34c64f6011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44261b8bfcb64b2582cd6e14f5de36cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:54&lt;00:00, 13.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47f44238bf944d1fa28abbc37510d755"
          }
        },
        "0cff01522d0f44d88f9bb57acd58f895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10fc9448465e4b2a90c8ca052459c16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44261b8bfcb64b2582cd6e14f5de36cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47f44238bf944d1fa28abbc37510d755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0-z91UlfiRk",
        "colab_type": "code",
        "outputId": "5b0a6ef1-d8c8-4b5d-9488-2a3e8d0820ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "#all imports\n",
        "import tensorflow as tf\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d15YleLXL2z",
        "colab_type": "text"
      },
      "source": [
        "This training code is based on the run_glue.py script here:\n",
        "https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "Also based on the following tutorials\n",
        "https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsZ4bSdhBEP",
        "colab_type": "code",
        "outputId": "322b2c8c-2171-47ab-e3d6-5ace27ddc7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "gpuname=tf.test.gpu_device_name()\n",
        "if gpuname=='/device:GPU:0':\n",
        "  print('Found GPU at :{}'.format(gpuname))\n",
        "else:\n",
        "  raise(SystemError('GPU device not found'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at :/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3ZtD-zg4k1",
        "colab_type": "code",
        "outputId": "510ea4b6-906a-4804-947d-df09e79dee81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
        "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available using only CPU instead\")\n",
        "  device=torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU DEVICES available \n",
            "The device name is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buldkQJQiKYI",
        "colab_type": "code",
        "outputId": "8c13a897-5625-48ae-a265-956dd59d170f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
            "\r\u001b[K     |▊                               | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 2.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 30.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 35.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 25.4MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 14.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 16.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 15.9MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 13.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 13.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 13.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 22.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=4a79a64b7614e12cd3de5be3ff55d02de1d795736eeb0315bdb559361c4f282f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.0 transformers-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKdaEMufiiAu",
        "colab_type": "code",
        "outputId": "8366f133-d519-400b-baa6-996a94c096b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZDHmlWSjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/Greek.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr20Wv8gpF9w",
        "colab_type": "code",
        "outputId": "a41a1237-cc42-46e2-f8c6-309a5db7e248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Hello\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHoGZVoSCPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAFIEswSPcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a']\n",
        "greekdata = pd.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
        "data=greekdata[1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnhbuYtZL0zO",
        "colab_type": "code",
        "outputId": "c0ed68a3-159e-49dd-9e8f-5f095b05f017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.to_numpy()[:,2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OFF', 'NOT', 'NOT', ..., 'NOT', 'NOT', 'NOT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNuys5ZaNOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVERT TO X AND Y LABELS\n",
        "#https://towardsdatascience.com/linear-regression-in-6-lines-of-python-5e1d0cd05b8d\n",
        "#https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array\n",
        "dfnumpy=data.to_numpy();\n",
        "x=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y=dfnumpy[:, 2].reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoqOUnmNZO07",
        "colab_type": "code",
        "outputId": "86e0f945-dcf3-4300-ee1d-960428af1b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "pip install tweet-preprocessor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=ce3c379951f98458306e7923c398d3b541e9819f3a9f3b708189ee83a0dd1500\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U89nu4PBSSZD",
        "colab_type": "code",
        "outputId": "89b54f59-9623-4406-a2ad-2cd9d8b57305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"el_core_news_md\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('el_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5vGRQYdq5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LEMMATIZATION\n",
        "import string\n",
        "import spacy\n",
        "#import el_core_news_sm \n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "import preprocessor as p2\n",
        "\n",
        "\n",
        "nlp =  spacy.load('el_core_news_md')\n",
        "#Preprocessing # to HASHTAG so that spacy can tokenize it properly\n",
        "p=re.compile(r\"(#)\",re.UNICODE)\n",
        "p1=re.compile(r\"\\.*\",re.UNICODE)\n",
        "##tokenization with NLTK and SPACY DIDNT WORK TOGETHER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOEIfAgyr83C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1M-zbEcXXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chD2GSH5dHb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrt=x[:,0]\n",
        "#allTokens=preprocess1(arrt)\n",
        "allTokens=arrt\n",
        "#allTokenstrain, allTokenstest, y_train, y_test = train_test_split(allTokens,y, test_size=0.2, random_state=42)\n",
        "#allTokensPredict, _, y_predict, _ = train_test_split(allTokenstest,y_test, test_size=0.5, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZALP47hKO4HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X-eKHng4jUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=allTokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZLNpEq1VVUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.utils import shuffle\n",
        "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7m4cgbJLwXW",
        "colab_type": "code",
        "outputId": "b377f3eb-2a87-4273-94f5-fffae00e73b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ...,\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzyloI-QNt2a",
        "colab_type": "code",
        "outputId": "56443332-d762-478e-b615-d79a2a5684c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\n",
        "  f.write(str(x))'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\\n  f.write(str(x))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TImBZYl4wih",
        "colab_type": "code",
        "outputId": "991c1c83-16e6-422b-9dd9-383363ff2680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(preprocessedTweets[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ντρέπομαι. #gntmgr'\n",
            " '@USER Γιατί ρε; σε αγαπάμε κι ας είσαι με το Γιάνη!'\n",
            " '@USER ΓΙΑ ΠΕΣΜΟΥ ΓΙΑ ΣΕΝΑ ΠΟΣΟ ΜΕΤΡΑ ΤΟ ΠΟΣΟ ΗΛΗΘΙΟΣ ΕΙΣΑΙ! ΓΙΑ ΝΑ ΜΠΩΡΕΙΣ ΝΑ ΛΕΣ ΟΤΙ Η ΗΛΗΘΙΟΤΗΤΑ ΕΧΕΙ ΜΕΤΡΟ! ΕΧΕΙΣ ΜΕΤΡΗΣΗ ΤΟΝ ΕΑΥΤΟ ΣΟΥ; ΠΩΣ ΜΠΩΡΕΙΣ ΝΑ ΚΡΙΝΕΙΣ ΕΜΕΝΑ;'\n",
            " '@USER Είσαι μλκ αγόρι μου; Τι αηδιες λες;'\n",
            " \"Μωρή Ασημίνα πρωτευουσιανα αη φτυσ'τα μπούτια σ' που θα μιλήσεις υποτιμητικά για το χωριό της Μαρίας. Σιχτιρ μαζί με την Μαρτινα που είχε πει για την λαϊκή #gntmgr\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufM4upXK2UOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSxRGBU-jXr",
        "colab_type": "code",
        "outputId": "80d0110b-b811-48ef-c83e-3a88d50338c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvnzPv3Ar4O",
        "colab_type": "code",
        "outputId": "584f42b9-0028-4f69-abbb-b60d081f5813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b88bf36131364ef9a6c0a5ebc855baef",
            "4ec008f15cd24d4dada574b98a8859d2",
            "6b2eafbf491946b4a32bf991d210e889",
            "8a80aeb5e20947df948cf55a72e3d8a0",
            "db4210f2af2040f8b043212166c0257d",
            "aae73cf9b076463492a01ef354f0e0c2",
            "06e03ad0d3ca468fb969bfbd7bd14409",
            "09efaf2baccd40638e10c539b074d954"
          ]
        }
      },
      "source": [
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b88bf36131364ef9a6c0a5ebc855baef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch6CWnxu5TG3",
        "colab_type": "code",
        "outputId": "278b81c4-1a13-4214-c5d9-af6dd664c69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
        "'''\n",
        "ids_of_sentence=[]\n",
        "maxlength=0\n",
        "for t in preprocessedTweets:\n",
        "      #token ids\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      #for t in tokenized_sentence_id:\n",
        "      #Checking max length\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      \n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "\n",
        "ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nids_of_sentence=[]\\nmaxlength=0\\nfor t in preprocessedTweets:\\n      #token ids\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      #for t in tokenized_sentence_id:\\n      #Checking max length\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n      \\n      ids_of_sentence.append(tokenized_sentence_id)\\n\\nids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIbY9ING13E",
        "colab_type": "code",
        "outputId": "a70aa7bb-5fce-4d23-cbb2-23fb9c70d7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''attention_masks = []\n",
        "for inds in ids_of_sentence_words:\n",
        "    att_mask = [int(t_id > 0) for t_id in inds]  \n",
        "    attention_masks.append(att_mask)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'attention_masks = []\\nfor inds in ids_of_sentence_words:\\n    att_mask = [int(t_id > 0) for t_id in inds]  \\n    attention_masks.append(att_mask)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsBprzLM6iuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s47V63nd6u1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpdgDWB7-ja",
        "colab_type": "code",
        "outputId": "d527b75d-d020-46c2-8455-0befd33e0780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "\n",
        "def giveIds(sentence,y_):\n",
        "  ids_of_sentence=[]\n",
        "  ids_of_sentence_words=[]\n",
        "  attention_masks=[]\n",
        "  maxlength=0\n",
        "  averageLength=0\n",
        "  allLens=[]\n",
        "  totalLen=len(sentence)\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      len1=len(tokenized_sentence_id)\n",
        "      if(maxlength<len1):\n",
        "          maxlength=len1\n",
        "          allLens.append(len1*1.0)/totalLen)\n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "  averageLength=[for s in allLens] \n",
        "  print(maxlength)\n",
        "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
        "  #print(len(attention_masks))\n",
        "  #print(len(ids_of_sentence_words))\n",
        "  return ids_of_sentence_words,attention_masks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-5a83c8f8cb78>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    allLens.append(len1*1.0)/totalLen)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2S1fYRTXYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "def giveIds(sentence,y_):\n",
        "  ids_of_sentence=[]\n",
        "  ids_of_sentence_words=[]\n",
        "  attention_masks=[]\n",
        "  maxlength=0\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "  print(maxlength)\n",
        "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
        "  #print(len(attention_masks))\n",
        "  #print(len(ids_of_sentence_words))\n",
        "  return ids_of_sentence_words,attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh02lGbz79_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIn1L3EaG_Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_train, sentence_test1, y_train, y_test1 = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n",
        "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQDZFAOzcNYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##do this at the time of training only \n",
        "#sentence_train, sentence_test1, y_train, y_test1 = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42) only this for code submission\n",
        "sentence_test,sentence_predict, y_test,y_predict = train_test_split(sentence_test1,y_test1, test_size=0.5, random_state=42)\n",
        "#x_predict_mask,_,_,_=train_test_split(x_test_mask,y_test, test_size=0.5, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBt1IAUnLZYs",
        "colab_type": "code",
        "outputId": "268ef23e-8c65-49d7-e1b4-46ff58758544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_predict.flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF',\n",
              "       'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'OFF', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'OFF', 'OFF', 'OFF', 'NOT', 'OFF', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'OFF', 'OFF', 'NOT', 'OFF', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'OFF', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'OFF', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'OFF', 'OFF',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF',\n",
              "       'OFF', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'OFF', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'OFF',\n",
              "       'NOT', 'NOT', 'OFF', 'OFF', 'OFF', 'OFF', 'NOT', 'NOT', 'NOT',\n",
              "       'NOT', 'NOT', 'NOT', 'NOT', 'NOT', 'OFF', 'OFF', 'NOT', 'NOT',\n",
              "       'OFF', 'NOT', 'NOT', 'OFF', 'NOT', 'NOT', 'NOT', 'OFF', 'NOT',\n",
              "       'OFF', 'NOT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Z4zlYAJRCb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_qRN1yU04y",
        "colab_type": "code",
        "outputId": "45c43216-61a9-459b-acec-f617f225c982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
        "#print(len(z))\n",
        "C = {'tweet': sentence_predict,\n",
        "        'subtask_a': y_predict.flatten(),\n",
        "    }\n",
        "df = pd.DataFrame(C, columns=['tweet', 'subtask_a'])\n",
        "export_csv = df.to_csv ('/content/drive/My Drive/GreekData/PredictFile.csv', index = None, header=True)\n",
        "print (df)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 tweet subtask_a\n",
            "0              @USER Είσαι σαν ένας νεαρός ερωτευμένος       NOT\n",
            "1    #gntmgr η Κάτια στην κατοχή θα φορούσε κουκούλ...       OFF\n",
            "2    @USER Πρέπει να σε θεωρεί πολυ ωραία γυναίκα γ...       NOT\n",
            "3    Ο Κούλης μας διδάσκει πώς να μπάζεις τη χούντα...       NOT\n",
            "4                 Κερεμ σωστό αρπακτικό #kokkinopotami       NOT\n",
            "..                                                 ...       ...\n",
            "870  Εγώ παιδιά για κάτι γκομενικά ξέρω πως έκρινε ...       NOT\n",
            "871                                   Ρε άι στο διάολο       OFF\n",
            "872  Μακάρι να το πάρει ο Μανώλης αν και δεν τρελάθ...       NOT\n",
            "873  Ανίδεη τσοκαρία.. που νομίζεις οτι είσαι ; στο...       OFF\n",
            "874              Ναι αυτό είναι το #GNTMgr που θέλουμε       NOT\n",
            "\n",
            "[875 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFcDGmeNVbKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW2xSi-YSrz2",
        "colab_type": "code",
        "outputId": "aabc22ef-00fa-49b9-dbd6-ef79bd4060de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x_train,x_train_mask=giveIds(sentence_train,y_train)\n",
        "x_test,x_test_mask=giveIds(sentence_test,y_test)\n",
        "x_predict,x_predict_mask=giveIds(sentence_predict,y_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "169\n",
            "154\n",
            "166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFFhDIdIlh-j",
        "colab_type": "code",
        "outputId": "c9244e46-48d2-4871-fa1f-62b56ad3f76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_predict.shape)\n",
        "\n",
        "yTrain=le.fit_transform(y_train.flatten())\n",
        "print(yTrain.shape)\n",
        "print(le.classes_)\n",
        "yTest=le.fit_transform(y_test.flatten())\n",
        "\n",
        "print(le.classes_)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6994, 1)\n",
            "(874, 1)\n",
            "(875, 1)\n",
            "(6994,)\n",
            "['NOT' 'OFF']\n",
            "['NOT' 'OFF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERcbmzubJF2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pytorch=torch.tensor(x_train)\n",
        "y_train_pytorch=torch.tensor(yTrain)\n",
        "\n",
        "x_test_pytorch=torch.tensor(x_test)\n",
        "y_test_pytorch=torch.tensor(yTest)\n",
        "\n",
        "\n",
        "x_train_mask_pytorch=torch.tensor(x_train_mask)\n",
        "x_test_mask_pytorch=torch.tensor(x_test_mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnnN9RzhaRlP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygtp5wI3WAh4",
        "colab_type": "code",
        "outputId": "98b31ce1-1f4a-4cb0-e228-24136b444d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(x_train_mask))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjby3Z8L7zz",
        "colab_type": "code",
        "outputId": "83d87048-3139-48eb-d373-2c5c08ba239f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print(x_train.shape,y_train.shape,x_test.shape,y_test.shape,x_mask.shape,y_mask.shape)\n",
        "print(len(x_train_pytorch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwMZZeOMxTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "bsize=32\n",
        "\n",
        "tdata=TensorDataset(x_train_pytorch,x_train_mask_pytorch,y_train_pytorch)\n",
        "tsampler=RandomSampler(tdata)\n",
        "tdataloader=DataLoader(tdata,sampler=tsampler,batch_size=bsize)\n",
        "\n",
        "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
        "tesampler=RandomSampler(tedata)\n",
        "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bOBLycdL0lc",
        "colab_type": "code",
        "outputId": "88c32e5c-26ae-410f-d309-e20f1d764d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "44448dab32354f398a7b12ec3fda8d57",
            "0d5a161ebdf346a3b3cbe48556818ba0",
            "908cde692e5f4f9da889829870505cca",
            "d0cc333952f340c29834760a2b3e39bb",
            "4a48382d23424fa4b1133834995867d9",
            "a2527c696adc400485cd882a0c1af854",
            "2b3c792bd9074ba6a1ba28a68bfe87e4",
            "4addf242d7ba44edbcc7772ecc0b1aeb",
            "909b975e587d4e478ae18cb14cb72ee3",
            "3617ad3922624e4fb35773a616994fb0",
            "be0be54852464913844254440eb8281e",
            "02762057c5424618a972fb34c64f6011",
            "0cff01522d0f44d88f9bb57acd58f895",
            "10fc9448465e4b2a90c8ca052459c16e",
            "44261b8bfcb64b2582cd6e14f5de36cf",
            "47f44238bf944d1fa28abbc37510d755"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44448dab32354f398a7b12ec3fda8d57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "909b975e587d4e478ae18cb14cb72ee3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAnMr0EjM_Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyH9yvdIO208",
        "colab_type": "code",
        "outputId": "91a9393a-56d3-4609-f5b3-6ea7ae869b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4guWRdOTS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params=list(model.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKOeqrn-jopN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "{\n",
        "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "\"weight_decay\": 0.01,\n",
        "},\n",
        "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RlThDORmMrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(optimizer_grouped_parameters,lr=2e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FRiX25tlMdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs=4\n",
        "total_steps=len(tdataloader)*epochs\n",
        "\n",
        "sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6LNSaNZpKVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  print(\"predictionArgmax\",predictionArgmax)\n",
        "  print(\"labelsFlattend\",labelsFlattend)\n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brS_TJmHJs0I",
        "colab_type": "code",
        "outputId": "689c3875-3c73-422e-8f6a-150cd65d92ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import time \n",
        "\n",
        "def set_seed(seed,ngpu):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if ngpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "      \n",
        "set_seed(42,torch.cuda.device_count())\n",
        "#remove later\n",
        "\n",
        "epochs=3\n",
        "lossList=[]\n",
        "max_grad_norm=1.0\n",
        "for e in range(0, epochs):\n",
        "    print(\"Start Epoch Number\",(e + 1))\n",
        "    print(\"Start Training\")\n",
        "    \n",
        "    #Amount of time taken for training\n",
        "    t1 = time.time()\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.train()\n",
        "    tsteps=0\n",
        "    for step, batch in enumerate(tdataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        model.zero_grad()        \n",
        "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        tsteps+=1\n",
        "        optimizer.step()\n",
        "        sch.step()\n",
        "\n",
        "    a_tr_loss = tr_loss /(tsteps)               \n",
        "    lossList.append(a_tr_loss)\n",
        "    \n",
        "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
        "    t2=time.time()\n",
        "    print(\"  Training one epoch time taken\",t2-t1)\n",
        "    print(\" Validation starts here \")\n",
        "   \n",
        "    t1 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_f1=0\n",
        "    eval_acc=0\n",
        "\n",
        "    for batch in tedataloader:       \n",
        "        batch = tuple(t.to(device) for t in batch)        \n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "        eval_f1 = eval_f1+tmpf1score\n",
        "        eval_acc=eval_acc+tmpaccscore\n",
        "        nb_eval_steps += 1\n",
        "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
        "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
        "\n",
        "\n",
        "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "    \n",
        "    t2=time.time()\n",
        "    print(\"  Validating one epoch time taken \",t2-t1)\n",
        "    \n",
        "print(\"ALL DONE!!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Epoch Number 1\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  27.228426456451416\n",
            "Batch Completed  100  of  219.    Elapsed time is  54.22010278701782\n",
            "Batch Completed  150  of  219.    Elapsed time is  81.18226647377014\n",
            "Batch Completed  200  of  219.    Elapsed time is  108.16591358184814\n",
            " The training loss incured is  0.523\n",
            "  Training one epoch time taken 118.23422408103943\n",
            " Validation starts here \n",
            "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            "labelsFlattend [1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            "labelsFlattend [1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1]\n",
            "predictionArgmax [0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1]\n",
            "predictionArgmax [0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
            "predictionArgmax [1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0]\n",
            "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0]\n",
            "predictionArgmax [1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            "labelsFlattend [1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0]\n",
            "predictionArgmax [1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "predictionArgmax [1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0]\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            "labelsFlattend [1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 1 0]\n",
            "  F1 score: 0.755\n",
            "  Accuracy score: 0.826\n",
            "  Validating one epoch time taken  4.277456521987915\n",
            "Start Epoch Number 2\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  26.971622705459595\n",
            "Batch Completed  100  of  219.    Elapsed time is  53.95281958580017\n",
            "Batch Completed  150  of  219.    Elapsed time is  80.92771005630493\n",
            "Batch Completed  200  of  219.    Elapsed time is  107.89867568016052\n",
            " The training loss incured is  0.390\n",
            "  Training one epoch time taken 117.94453954696655\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1]\n",
            "labelsFlattend [1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1]\n",
            "labelsFlattend [1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0]\n",
            "labelsFlattend [1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1]\n",
            "predictionArgmax [1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1]\n",
            "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0]\n",
            "labelsFlattend [1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1]\n",
            "labelsFlattend [1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 1 1 0 0 0 0 1]\n",
            "labelsFlattend [0 0 1 0 1 0 0 0 0 1]\n",
            "  F1 score: 0.798\n",
            "  Accuracy score: 0.849\n",
            "  Validating one epoch time taken  4.2789599895477295\n",
            "Start Epoch Number 3\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  26.959994554519653\n",
            "Batch Completed  100  of  219.    Elapsed time is  53.96218395233154\n",
            "Batch Completed  150  of  219.    Elapsed time is  80.94009494781494\n",
            "Batch Completed  200  of  219.    Elapsed time is  107.92240452766418\n",
            " The training loss incured is  0.318\n",
            "  Training one epoch time taken 117.9666121006012\n",
            " Validation starts here \n",
            "predictionArgmax [1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0]\n",
            "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]\n",
            "labelsFlattend [1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1]\n",
            "predictionArgmax [0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1]\n",
            "predictionArgmax [1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0]\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0]\n",
            "labelsFlattend [1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0]\n",
            "labelsFlattend [0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 0 0 0]\n",
            "  F1 score: 0.814\n",
            "  Accuracy score: 0.862\n",
            "  Validating one epoch time taken  4.278019905090332\n",
            "ALL DONE!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rWdrUSxJIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##WITH AND WITHOUT PREPROCESSING F1 and accuracy score stuck at 0.755"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFcl1gBfU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.794 after 6 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3Gp5gPddxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictingData(xpredict,ypredict,xpredictmask):\n",
        "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
        "  ids_of_sentence=[]\n",
        "  predictedLabels,trueLabels=[],[]\n",
        "  '''\n",
        "  tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)  \n",
        "  maxlength=0 //uncomment during prediction\n",
        "  print(xpredict[0])\n",
        "\n",
        "  for t in xpredict:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      \n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "  \n",
        "  print(\"Hello\")\n",
        "  \n",
        "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  attention_masks = []\n",
        "  for inds in ids_of_sentence_words:\n",
        "    att_mask = [int(t_id > 0) for t_id in inds]  \n",
        "    attention_masks.append(att_mask)\n",
        "  '''\n",
        "  ypredict=le.fit_transform(ypredict.flatten())\n",
        "  x_predict_pytorch=torch.tensor(xpredict)\n",
        "  y_predict_pytorch=torch.tensor(ypredict)\n",
        "  x_predict_mask_pytorch=torch.tensor(xpredictmask)\n",
        "  batch_size = 32\n",
        "  predictdata=TensorDataset(x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch)\n",
        "  predictsampler=RandomSampler(tedata)\n",
        "  predictdataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
        "  '''\n",
        "  //Load the model \n",
        "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "  model.cuda()\n",
        "  '''\n",
        "  eval_f1=0\n",
        "  eval_acc=0\n",
        "  nb_eval_steps=0\n",
        "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  model.eval()\n",
        "\n",
        "  for batch in predictdataloader: \n",
        "      batch = tuple(t.to(device) for t in batch)        \n",
        "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "      with torch.no_grad():       \n",
        "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "      predictedLabels.append(logits)\n",
        "      trueLabels.append(label_ids)\n",
        "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "      eval_f1 = eval_f1+tmpf1score\n",
        "      eval_acc=eval_acc+tmpaccscore\n",
        "      nb_eval_steps += 1\n",
        "      \n",
        "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "  return predictedLabels,trueLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3ajuk04jw-",
        "colab_type": "code",
        "outputId": "fea1ee9a-1465-449a-eada-f567697273ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ-v9vkBMEZo",
        "colab_type": "code",
        "outputId": "f729798f-bbaa-4e02-9b0a-087483d0e609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#modelInitialize tokenizer and sequence classification\n",
        "predictedLabels,trueLabels=predictingData(x_predict,y_predict,x_predict_mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictionArgmax [0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1]\n",
            "labelsFlattend [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0]\n",
            "predictionArgmax [1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "predictionArgmax [1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1]\n",
            "predictionArgmax [1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1]\n",
            "labelsFlattend [1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1]\n",
            "predictionArgmax [0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "labelsFlattend [1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "predictionArgmax [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0]\n",
            "predictionArgmax [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 0 0]\n",
            "  F1 score: 0.826\n",
            "  Accuracy score: 0.862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBxBKJFVaFjr",
        "colab_type": "code",
        "outputId": "5592cd99-9094-44c7-b5de-d19b8cdd04c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "\n",
        "  #predictionArgmax=np.argmax(predictedLabels[0],axis=1).flatten()\n",
        "  #labelsFlattend=trueLabels[0].flatten()\n",
        "  #print(\"predictionArgmax\",predictionArgmax)\n",
        "  #print(\"labelsFlattend\",labelsFlattend)\n",
        "  #print(f1_score(labelsFlattend, predictionArgmax, average='macro'))\n",
        "  #print(accuracy_score(labelsFlattend, predictionArgmax))\n",
        "  print(len(predictedLabels))\n",
        "  print(len(trueLabels))\n",
        "  \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n  #predictionArgmax=np.argmax(predictedLabels[0],axis=1).flatten()\\n  #labelsFlattend=trueLabels[0].flatten()\\n  #print(\"predictionArgmax\",predictionArgmax)\\n  #print(\"labelsFlattend\",labelsFlattend)\\n  #print(f1_score(labelsFlattend, predictionArgmax, average=\\'macro\\'))\\n  #print(accuracy_score(labelsFlattend, predictionArgmax))\\n  print(len(predictedLabels))\\n  print(len(trueLabels))\\n  \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}