{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstWorkingF1TestingAndTrainDanishFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4b2f1b80af64cf294c83367f7feef96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_710102fc46d24bde8e9c2268110763df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_edf4a13c213f47c2860e9998338acf52",
              "IPY_MODEL_54e7a176fb7a4517a756e76666cc11db"
            ]
          }
        },
        "710102fc46d24bde8e9c2268110763df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edf4a13c213f47c2860e9998338acf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1eb52c41a1349bba1d42a4506cf8f93",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11c33de5a69f4c71970f81f8ae967206"
          }
        },
        "54e7a176fb7a4517a756e76666cc11db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5287976e9b44d28910dbfdbea381cd2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 2.57MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc7db3f513814da5832cbe03f153c0e2"
          }
        },
        "c1eb52c41a1349bba1d42a4506cf8f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11c33de5a69f4c71970f81f8ae967206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5287976e9b44d28910dbfdbea381cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc7db3f513814da5832cbe03f153c0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1f73ba7917f4cb4909a5509523c7f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe378365bbb247a0b962b68270510cde",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29da3f4282cc46db8651b55a0efa7932",
              "IPY_MODEL_1203d552324e4b15aca03342ac27e5c3"
            ]
          }
        },
        "fe378365bbb247a0b962b68270510cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29da3f4282cc46db8651b55a0efa7932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ded77ef029a4700984021c66d8a640f",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85eb3f4926db41b8bc8fdb6d947502d9"
          }
        },
        "1203d552324e4b15aca03342ac27e5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bbd914f0215497986d37fc135e072eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 23.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d745f5e04c744270a8809e0b363d0e19"
          }
        },
        "3ded77ef029a4700984021c66d8a640f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85eb3f4926db41b8bc8fdb6d947502d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bbd914f0215497986d37fc135e072eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d745f5e04c744270a8809e0b363d0e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2035119af7054cff9d53373660feff59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bc43821fecd4623899347b65ee352cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9ac0830e456c46daaf9c4bad3f59a4c3",
              "IPY_MODEL_4f70072be9b64548ae8a190ba4b81abe"
            ]
          }
        },
        "0bc43821fecd4623899347b65ee352cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ac0830e456c46daaf9c4bad3f59a4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4409ae9cdaa487383e6af8b695a92f9",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cd1b75c772842bfb272573cc49dcd16"
          }
        },
        "4f70072be9b64548ae8a190ba4b81abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af62a440d3514d58a0a4e40476802dd0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:20&lt;00:00, 34.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_203cc2490d794b93b191b5125ea68afb"
          }
        },
        "f4409ae9cdaa487383e6af8b695a92f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cd1b75c772842bfb272573cc49dcd16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af62a440d3514d58a0a4e40476802dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "203cc2490d794b93b191b5125ea68afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0-z91UlfiRk",
        "colab_type": "code",
        "outputId": "e83cadb3-2c69-4c83-80e3-bdb14aa8d878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "#all imports\n",
        "import tensorflow as tf\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsZ4bSdhBEP",
        "colab_type": "code",
        "outputId": "48cd2144-6c94-4eba-abb7-cef1f2713722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "gpuname=tf.test.gpu_device_name()\n",
        "if gpuname=='/device:GPU:0':\n",
        "  print('Found GPU at :{}'.format(gpuname))\n",
        "else:\n",
        "  raise(SystemError('GPU device not found'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at :/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3ZtD-zg4k1",
        "colab_type": "code",
        "outputId": "2e92b2cf-edde-490a-c0ae-621e93b28ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
        "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available using only CPU instead\")\n",
        "  device=torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU DEVICES available \n",
            "The device name is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buldkQJQiKYI",
        "colab_type": "code",
        "outputId": "0594f1cb-b8e9-4c83-b3c8-b0905471a71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 48.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 46.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=df53b38542a3989a794b9f16f83b149e1859c88a21aefd1e5690b1a566dc04ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKdaEMufiiAu",
        "colab_type": "code",
        "outputId": "faa8284a-8670-4325-f08f-0316cdbd65b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_byFfpTf1D9",
        "colab_type": "text"
      },
      "source": [
        "#Custom Data set and Data loader has been inspired from \n",
        "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZDHmlWSjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/DanishData/Danish.zip'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr20Wv8gpF9w",
        "colab_type": "code",
        "outputId": "fe8cba6d-6490-4343-f8dd-38d4da5ce52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Hello\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cx_z-bmJsVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdtlBC5Rbyk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHoGZVoSCPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAFIEswSPcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a']\n",
        "greekdata = pd.read_csv(\"Danish/offenseval-da-training-v1.tsv\", delimiter='\\t',names=headers)\n",
        "data=greekdata[1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSe3Jv-QkZ8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data[:2960]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnhbuYtZL0zO",
        "colab_type": "code",
        "outputId": "7e99df09-917f-4879-bf3c-4c69f496f15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.to_numpy()[:,2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NOT', 'NOT', 'OFF', ..., 'NOT', 'NOT', 'OFF'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNuys5ZaNOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dfnumpy=data.to_numpy();\n",
        "x=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y=dfnumpy[:, 2].reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoqOUnmNZO07",
        "colab_type": "code",
        "outputId": "91c56341-2dad-473c-e978-44126f53afe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install tweet-preprocessor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=37f3372bf01604c7e38756171c3b57dacd95b7e1ba858f64379101d1472f15e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U89nu4PBSSZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5vGRQYdq5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOEIfAgyr83C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1M-zbEcXXo",
        "colab_type": "code",
        "outputId": "ec241ca7-a983-475d-be7e-28cfbab7056b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''import json\n",
        "x=\"\"\n",
        "y=\"\"\n",
        "\n",
        "with open('Danish/tweet.json','r') as xjson:\n",
        "    x=json.load(xjson)\n",
        "x=x[1:]\n",
        "print(x[:5])\n",
        "with open('Danish/label.json','r') as yjson:\n",
        "    y=json.load(yjson)\n",
        "\n",
        "y=y[1:]\n",
        "print(y[:5])'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import json\\nx=\"\"\\ny=\"\"\\n\\nwith open(\\'Danish/tweet.json\\',\\'r\\') as xjson:\\n    x=json.load(xjson)\\nx=x[1:]\\nprint(x[:5])\\nwith open(\\'Danish/label.json\\',\\'r\\') as yjson:\\n    y=json.load(yjson)\\n\\ny=y[1:]\\nprint(y[:5])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o2uRGnpbyIT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx9r1Hdqbyo5",
        "colab_type": "code",
        "outputId": "de493a75-a9da-4205-92a8-9f5d9d310e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''def sentences(x):\n",
        "  preprocessedTweets=[]\n",
        "  for t in x:\n",
        "    sentence=\" \".join(t)\n",
        "    preprocessedTweets.append(sentence)\n",
        "\n",
        "  return preprocessedTweets'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def sentences(x):\\n  preprocessedTweets=[]\\n  for t in x:\\n    sentence=\" \".join(t)\\n    preprocessedTweets.append(sentence)\\n\\n  return preprocessedTweets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chD2GSH5dHb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrt=x[:,0]\n",
        "#allTokens=preprocess1(arrt)\n",
        "allTokens=arrt\n",
        "#allTokenstrain, allTokenstest, y_train, y_test = train_test_split(allTokens,y, test_size=0.2, random_state=42)\n",
        "#allTokensPredict, _, y_predict, _ = train_test_split(allTokenstest,y_test, test_size=0.5, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZALP47hKO4HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X-eKHng4jUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=allTokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZLNpEq1VVUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.utils import shuffle\n",
        "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7m4cgbJLwXW",
        "colab_type": "code",
        "outputId": "2ebe1a1a-d418-4071-f41a-80a946d8828c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ...,\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzyloI-QNt2a",
        "colab_type": "code",
        "outputId": "e8173a9d-0c16-400b-baf7-f004f3f896f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\n",
        "  f.write(str(x))'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\\n  f.write(str(x))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TImBZYl4wih",
        "colab_type": "code",
        "outputId": "6ed8cfc1-01f7-43be-c44d-a340940b4005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(preprocessedTweets[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['TIL: Der kan falde vand ned fra himlen :O'\n",
            " 'Jeg mangler lidt noget info om hvordan jeg drÃ¦ber fÃ¦rre viber til hverdags?'\n",
            " 'I er okay til tider :)'\n",
            " 'Men hvorfor ser du dog et show om den vÃ¦rste \"nation\" i verden?'\n",
            " 'Eller en Anaconda fra Elite: Dangerous computerspil?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufM4upXK2UOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSxRGBU-jXr",
        "colab_type": "code",
        "outputId": "6a74399e-42f4-4e57-b6be-46a8a6317966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvnzPv3Ar4O",
        "colab_type": "code",
        "outputId": "87afc490-c2ca-4ee0-d515-7c50423033fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e4b2f1b80af64cf294c83367f7feef96",
            "710102fc46d24bde8e9c2268110763df",
            "edf4a13c213f47c2860e9998338acf52",
            "54e7a176fb7a4517a756e76666cc11db",
            "c1eb52c41a1349bba1d42a4506cf8f93",
            "11c33de5a69f4c71970f81f8ae967206",
            "e5287976e9b44d28910dbfdbea381cd2",
            "dc7db3f513814da5832cbe03f153c0e2"
          ]
        }
      },
      "source": [
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4b2f1b80af64cf294c83367f7feef96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch6CWnxu5TG3",
        "colab_type": "code",
        "outputId": "92dec054-b2f3-4e63-964c-edcd5a0f8f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "'''\n",
        "ids_of_sentence=[]\n",
        "maxlength=0\n",
        "for t in preprocessedTweets:\n",
        "      #token ids\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      #for t in tokenized_sentence_id:\n",
        "      #Checking max length\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      \n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "\n",
        "ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nids_of_sentence=[]\\nmaxlength=0\\nfor t in preprocessedTweets:\\n      #token ids\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      #for t in tokenized_sentence_id:\\n      #Checking max length\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n      \\n      ids_of_sentence.append(tokenized_sentence_id)\\n\\nids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIbY9ING13E",
        "colab_type": "code",
        "outputId": "649aaf78-aeff-4819-e9f7-10cecd112c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''attention_masks = []\n",
        "for inds in ids_of_sentence_words:\n",
        "    att_mask = [int(t_id > 0) for t_id in inds]  \n",
        "    attention_masks.append(att_mask)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'attention_masks = []\\nfor inds in ids_of_sentence_words:\\n    att_mask = [int(t_id > 0) for t_id in inds]  \\n    attention_masks.append(att_mask)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsBprzLM6iuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s47V63nd6u1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wm8lSK5cSPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpdgDWB7-ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2S1fYRTXYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "def giveIds(sentence,y_):\n",
        "  ids_of_sentence=[]\n",
        "  ids_of_sentence_words=[]\n",
        "  attention_masks=[]\n",
        "  maxlength=0\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "  print(maxlength)\n",
        "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
        "  #print(len(attention_masks))\n",
        "  #print(len(ids_of_sentence_words))\n",
        "  return ids_of_sentence_words,attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh02lGbz79_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIn1L3EaG_Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_train, sentence_test, y_train, y_test = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n",
        "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQDZFAOzcNYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##do this at the time of training only \n",
        "#sentence_train, sentence_test1, y_train, y_test1 = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42) only this for code submission\n",
        "#sentence_test,sentence_predict, y_test,y_predict = train_test_split(sentence_test1,y_test1, test_size=0.5, random_state=42)\n",
        "#x_predict_mask,_,_,_=train_test_split(x_test_mask,y_test, test_size=0.5, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Z4zlYAJRCb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_qRN1yU04y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3cQT-_ejd9R",
        "colab_type": "code",
        "outputId": "6290d9c0-db0c-4ef2-c5cb-961516600459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['OFF'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CYsPFfkdWL9",
        "colab_type": "code",
        "outputId": "e6e04b30-c9aa-4f11-edfd-57dae9e9261b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "yTrain=le.fit_transform(y_train.flatten())\n",
        "print(yTrain.shape)\n",
        "print(le.classes_)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2368, 1)\n",
            "(592, 1)\n",
            "(2368,)\n",
            "['NOT' 'OFF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwrbFDiqjh1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yTest=le.fit_transform(y_test.flatten())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17cc-80ujmKS",
        "colab_type": "code",
        "outputId": "8d4642ca-4059-4de3-e6a6-3d92afe0f449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(y_test.flatten())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NOT', 'OFF'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cVrhEIdd2FL",
        "colab_type": "code",
        "outputId": "a44da1ad-6f07-4e7c-e477-bc9ca06fe6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(yTest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFcDGmeNVbKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekTrainDataset(Dataset):\n",
        "    def __init__(self,xytrain):\n",
        "        self.xytrain = xytrain\n",
        "        self.maxlength=256\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
        "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytrain[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MRzkZ70fqRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.utils.data import Dataset\n",
        "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekTestDataset(Dataset):\n",
        "    def __init__(self,xytest):\n",
        "        self.xytest = xytest\n",
        "        self.maxlength=256\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength-2]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
        "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytest[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt6HvS5-dpok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xytrain=[sentence_train,yTrain]\n",
        "tdataset = GreekTrainDataset(xytrain)\n",
        "tsampler=RandomSampler(tdataset)\n",
        "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGJiYjC1fb1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xytest=[sentence_test,yTest]\n",
        "tedataset = GreekTestDataset(xytest)\n",
        "tesampler=RandomSampler(tedataset)\n",
        "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bOBLycdL0lc",
        "colab_type": "code",
        "outputId": "01b2b9f8-2691-44d4-e47d-4a7ce4d10638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d1f73ba7917f4cb4909a5509523c7f2e",
            "fe378365bbb247a0b962b68270510cde",
            "29da3f4282cc46db8651b55a0efa7932",
            "1203d552324e4b15aca03342ac27e5c3",
            "3ded77ef029a4700984021c66d8a640f",
            "85eb3f4926db41b8bc8fdb6d947502d9",
            "2bbd914f0215497986d37fc135e072eb",
            "d745f5e04c744270a8809e0b363d0e19",
            "2035119af7054cff9d53373660feff59",
            "0bc43821fecd4623899347b65ee352cf",
            "9ac0830e456c46daaf9c4bad3f59a4c3",
            "4f70072be9b64548ae8a190ba4b81abe",
            "f4409ae9cdaa487383e6af8b695a92f9",
            "6cd1b75c772842bfb272573cc49dcd16",
            "af62a440d3514d58a0a4e40476802dd0",
            "203cc2490d794b93b191b5125ea68afb"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1f73ba7917f4cb4909a5509523c7f2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2035119af7054cff9d53373660feff59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyH9yvdIO208",
        "colab_type": "code",
        "outputId": "e8de00a0-1da2-4179-e5fe-b6e9d4b543fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/DanishData/bertdanish.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/DanishData/bertdanish.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4guWRdOTS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params=list(model.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKOeqrn-jopN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "{\n",
        "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "\"weight_decay\": 0.01,\n",
        "},\n",
        "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RlThDORmMrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)\n",
        "#############CAN CHANGE LEARNING RATE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FRiX25tlMdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs=4\n",
        "total_steps=len(tdataloader)*epochs\n",
        "\n",
        "sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6LNSaNZpKVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  print(\"predictionArgmax\",predictionArgmax)\n",
        "  print(\"labelsFlattend\",labelsFlattend)\n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKBAgRkViOV",
        "colab_type": "text"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "#Also based on the following tutorials\n",
        "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brS_TJmHJs0I",
        "colab_type": "code",
        "outputId": "ad448cb1-c0c2-4904-885c-2316e0dd6712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import time \n",
        "\n",
        "def set_seed(seed,ngpu):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if ngpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "      \n",
        "set_seed(42,torch.cuda.device_count())\n",
        "#remove later\n",
        "\n",
        "epochs=4\n",
        "lossList=[]\n",
        "max_grad_norm=1.0\n",
        "for e in range(0, epochs):\n",
        "    print(\"Start Epoch Number\",(e + 1))\n",
        "    print(\"Start Training\")\n",
        "    \n",
        "    #Amount of time taken for training\n",
        "    t1 = time.time()\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.train()\n",
        "    tsteps=0\n",
        "    for step, batch in enumerate(tdataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        model.zero_grad()        \n",
        "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        tsteps+=1\n",
        "        optimizer.step()\n",
        "        sch.step()\n",
        "\n",
        "    a_tr_loss = tr_loss /(tsteps)               \n",
        "    lossList.append(a_tr_loss)\n",
        "    \n",
        "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
        "    t2=time.time()\n",
        "    print(\"  Training one epoch time taken\",t2-t1)\n",
        "    print(\" Validation starts here \")\n",
        "   \n",
        "    t1 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_f1=0\n",
        "    eval_acc=0\n",
        "\n",
        "    for batch in tedataloader:       \n",
        "        batch = tuple(t.to(device) for t in batch)        \n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "        eval_f1 = eval_f1+tmpf1score\n",
        "        eval_acc=eval_acc+tmpaccscore\n",
        "        nb_eval_steps += 1\n",
        "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
        "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
        "\n",
        "\n",
        "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "    \n",
        "    t2=time.time()\n",
        "    print(\"  Validating one epoch time taken \",t2-t1)\n",
        "    \n",
        "print(\"ALL DONE!!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Epoch Number 1\n",
            "Start Training\n",
            "Batch Completed  50  of  74.    Elapsed time is  40.510250091552734\n",
            " The training loss incured is  0.405\n",
            "  Training one epoch time taken 59.829336404800415\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            "  F1 score: 0.465\n",
            "  Accuracy score: 0.872\n",
            "  Validating one epoch time taken  4.704200983047485\n",
            "Start Epoch Number 2\n",
            "Start Training\n",
            "Batch Completed  50  of  74.    Elapsed time is  41.05295729637146\n",
            " The training loss incured is  0.379\n",
            "  Training one epoch time taken 60.7094304561615\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "  F1 score: 0.466\n",
            "  Accuracy score: 0.873\n",
            "  Validating one epoch time taken  4.704154968261719\n",
            "Start Epoch Number 3\n",
            "Start Training\n",
            "Batch Completed  50  of  74.    Elapsed time is  40.416749715805054\n",
            " The training loss incured is  0.316\n",
            "  Training one epoch time taken 60.14295244216919\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  F1 score: 0.696\n",
            "  Accuracy score: 0.916\n",
            "  Validating one epoch time taken  4.707428216934204\n",
            "Start Epoch Number 4\n",
            "Start Training\n",
            "Batch Completed  50  of  74.    Elapsed time is  40.699851989746094\n",
            " The training loss incured is  0.235\n",
            "  Training one epoch time taken 59.909507751464844\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "  F1 score: 0.783\n",
            "  Accuracy score: 0.928\n",
            "  Validating one epoch time taken  4.700415372848511\n",
            "ALL DONE!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rWdrUSxJIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFcl1gBfU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojs4mzqQhkR4",
        "colab_type": "code",
        "outputId": "94ae390c-0d24-4924-9f71-4692af6dee5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/DanishData/DanishPredict.zip'\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/DanishData/Danish.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace Danish/offenseval-da-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Danish/readme-trainingset-da.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19c06d4ChmVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ygiven=[]\n",
        "ypredicted=[]\n",
        "\n",
        "def convertToInt(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.int64(val)\n",
        "    except:        \n",
        "        return np.int64(0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRhcqakGho3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Use blob\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "def readData1():\n",
        "  headers=['id','tweet']\n",
        "  greekDataTest = pd.read_csv(\"offenseval-da-test-v1-nolabels.tsv\", delimiter='\\t',names=headers,\n",
        "                                converters={\"id\":convertToInt})\n",
        "  greekDataTest=greekDataTest[1:]\n",
        "  print(greekDataTest.head())\n",
        "  print(greekDataTest.dtypes)\n",
        "  print(greekDataTest.shape)\n",
        "  \n",
        "  dfnumpy=greekDataTest.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
        "  print(tid)\n",
        "  arrt=X[:,0]\n",
        "  #allTokens=preprocess1(arrt)\n",
        "  preprocessedTweets=arrt\n",
        "  return preprocessedTweets,tid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CgDHQVwhsFY",
        "colab_type": "code",
        "outputId": "e50108d8-e98f-4177-f66f-bfd1076a6ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "preprocessedTweets,tid=readData1()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id                                              tweet\n",
            "1  1382  Der er syriske \"flygtninge\" som rejser til Ira...\n",
            "2  1384                             Danmark = Vitryssland?\n",
            "3   547  Ja tvangsfjernelser af bÃ¸rn pÃ¥ urigtige oplysn...\n",
            "4  1269  Han kan ikke Svensk og forventer et job. Hvis ...\n",
            "5  1695                                  NED MED SVENSKEN!\n",
            "id        int64\n",
            "tweet    object\n",
            "dtype: object\n",
            "(329, 2)\n",
            "[[1382]\n",
            " [1384]\n",
            " [547]\n",
            " [1269]\n",
            " [1695]\n",
            " [2320]\n",
            " [990]\n",
            " [2665]\n",
            " [1414]\n",
            " [262]\n",
            " [1459]\n",
            " [3375]\n",
            " [1431]\n",
            " [137]\n",
            " [8]\n",
            " [2964]\n",
            " [2542]\n",
            " [1375]\n",
            " [1458]\n",
            " [799]\n",
            " [976]\n",
            " [305]\n",
            " [2643]\n",
            " [386]\n",
            " [715]\n",
            " [2041]\n",
            " [2194]\n",
            " [60]\n",
            " [2181]\n",
            " [720]\n",
            " [552]\n",
            " [2560]\n",
            " [775]\n",
            " [848]\n",
            " [1754]\n",
            " [2363]\n",
            " [1330]\n",
            " [885]\n",
            " [974]\n",
            " [1205]\n",
            " [2589]\n",
            " [2172]\n",
            " [159]\n",
            " [3425]\n",
            " [544]\n",
            " [1371]\n",
            " [30]\n",
            " [1973]\n",
            " [22]\n",
            " [1813]\n",
            " [1379]\n",
            " [99]\n",
            " [1614]\n",
            " [1038]\n",
            " [633]\n",
            " [1275]\n",
            " [924]\n",
            " [962]\n",
            " [1314]\n",
            " [926]\n",
            " [33]\n",
            " [2627]\n",
            " [3396]\n",
            " [1321]\n",
            " [2321]\n",
            " [391]\n",
            " [1143]\n",
            " [1596]\n",
            " [3222]\n",
            " [3122]\n",
            " [716]\n",
            " [173]\n",
            " [2382]\n",
            " [3560]\n",
            " [2046]\n",
            " [1291]\n",
            " [2858]\n",
            " [102]\n",
            " [2577]\n",
            " [1507]\n",
            " [987]\n",
            " [2639]\n",
            " [1505]\n",
            " [3499]\n",
            " [325]\n",
            " [3482]\n",
            " [2068]\n",
            " [1497]\n",
            " [647]\n",
            " [2674]\n",
            " [632]\n",
            " [3522]\n",
            " [133]\n",
            " [3163]\n",
            " [142]\n",
            " [1893]\n",
            " [513]\n",
            " [1487]\n",
            " [883]\n",
            " [219]\n",
            " [1919]\n",
            " [777]\n",
            " [972]\n",
            " [2131]\n",
            " [570]\n",
            " [371]\n",
            " [1344]\n",
            " [3406]\n",
            " [1816]\n",
            " [1469]\n",
            " [3165]\n",
            " [2832]\n",
            " [964]\n",
            " [3150]\n",
            " [1886]\n",
            " [1766]\n",
            " [1599]\n",
            " [224]\n",
            " [2932]\n",
            " [1520]\n",
            " [757]\n",
            " [1315]\n",
            " [3316]\n",
            " [709]\n",
            " [3562]\n",
            " [2192]\n",
            " [3117]\n",
            " [2196]\n",
            " [485]\n",
            " [2076]\n",
            " [1148]\n",
            " [108]\n",
            " [73]\n",
            " [852]\n",
            " [2925]\n",
            " [1455]\n",
            " [1946]\n",
            " [3114]\n",
            " [927]\n",
            " [526]\n",
            " [1189]\n",
            " [3437]\n",
            " [1738]\n",
            " [1659]\n",
            " [678]\n",
            " [2389]\n",
            " [1923]\n",
            " [3012]\n",
            " [850]\n",
            " [218]\n",
            " [753]\n",
            " [1940]\n",
            " [736]\n",
            " [3240]\n",
            " [1545]\n",
            " [3571]\n",
            " [995]\n",
            " [2380]\n",
            " [3398]\n",
            " [85]\n",
            " [2291]\n",
            " [2167]\n",
            " [860]\n",
            " [2502]\n",
            " [3245]\n",
            " [727]\n",
            " [3400]\n",
            " [413]\n",
            " [2204]\n",
            " [1082]\n",
            " [1220]\n",
            " [1546]\n",
            " [712]\n",
            " [646]\n",
            " [2493]\n",
            " [2075]\n",
            " [28]\n",
            " [379]\n",
            " [1928]\n",
            " [2626]\n",
            " [2506]\n",
            " [2245]\n",
            " [2746]\n",
            " [104]\n",
            " [23]\n",
            " [3211]\n",
            " [705]\n",
            " [2137]\n",
            " [774]\n",
            " [2895]\n",
            " [1593]\n",
            " [975]\n",
            " [1534]\n",
            " [1818]\n",
            " [3299]\n",
            " [1809]\n",
            " [2256]\n",
            " [246]\n",
            " [3492]\n",
            " [2085]\n",
            " [1139]\n",
            " [1907]\n",
            " [1285]\n",
            " [380]\n",
            " [1698]\n",
            " [3545]\n",
            " [2725]\n",
            " [3323]\n",
            " [4]\n",
            " [699]\n",
            " [1251]\n",
            " [966]\n",
            " [2153]\n",
            " [1439]\n",
            " [3108]\n",
            " [1558]\n",
            " [209]\n",
            " [3494]\n",
            " [2934]\n",
            " [1064]\n",
            " [1942]\n",
            " [492]\n",
            " [1089]\n",
            " [621]\n",
            " [940]\n",
            " [1188]\n",
            " [3143]\n",
            " [2049]\n",
            " [2066]\n",
            " [763]\n",
            " [579]\n",
            " [2449]\n",
            " [375]\n",
            " [2063]\n",
            " [2155]\n",
            " [261]\n",
            " [859]\n",
            " [1292]\n",
            " [1105]\n",
            " [3397]\n",
            " [3431]\n",
            " [2532]\n",
            " [3524]\n",
            " [2111]\n",
            " [2191]\n",
            " [2907]\n",
            " [1167]\n",
            " [1164]\n",
            " [3084]\n",
            " [1200]\n",
            " [534]\n",
            " [2299]\n",
            " [3069]\n",
            " [1103]\n",
            " [3177]\n",
            " [1889]\n",
            " [3424]\n",
            " [2373]\n",
            " [341]\n",
            " [658]\n",
            " [651]\n",
            " [442]\n",
            " [2677]\n",
            " [1944]\n",
            " [1311]\n",
            " [430]\n",
            " [2040]\n",
            " [1096]\n",
            " [581]\n",
            " [2683]\n",
            " [2540]\n",
            " [2414]\n",
            " [701]\n",
            " [1095]\n",
            " [2959]\n",
            " [769]\n",
            " [2836]\n",
            " [274]\n",
            " [1846]\n",
            " [94]\n",
            " [1044]\n",
            " [1791]\n",
            " [890]\n",
            " [26]\n",
            " [79]\n",
            " [2080]\n",
            " [1131]\n",
            " [798]\n",
            " [2048]\n",
            " [620]\n",
            " [404]\n",
            " [1427]\n",
            " [519]\n",
            " [2864]\n",
            " [3304]\n",
            " [3166]\n",
            " [546]\n",
            " [459]\n",
            " [2050]\n",
            " [880]\n",
            " [1123]\n",
            " [138]\n",
            " [1425]\n",
            " [1996]\n",
            " [2036]\n",
            " [1568]\n",
            " [1303]\n",
            " [1917]\n",
            " [734]\n",
            " [641]\n",
            " [2412]\n",
            " [2928]\n",
            " [9]\n",
            " [2799]\n",
            " [3062]\n",
            " [1106]\n",
            " [184]\n",
            " [3534]\n",
            " [3512]\n",
            " [2634]\n",
            " [1338]\n",
            " [2238]\n",
            " [3326]\n",
            " [3567]\n",
            " [1591]\n",
            " [1769]\n",
            " [2443]\n",
            " [3221]\n",
            " [400]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AukQQ0jWhxTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekPredictDataset(Dataset):\n",
        "    def __init__(self,xypredict):\n",
        "        self.xypredict = xypredict\n",
        "        self.maxlength=128\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
        "        tid_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
        "        \n",
        "        return x_predict_pytorch,x_predict_mask_pytorch,tid_predict_pytorch\n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.xypredict[0])\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf_TvSaYn1AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "def calculateScore(predictions):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  yres.append(predictionArgmax.flatten())\n",
        "  print(\"predictionArgmax\",predictionArgmax)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWKfHXfplWQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yres=[]\n",
        "finalTid=[]\n",
        "def predictingData(pTweets,tid):\n",
        "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
        "  ids_of_sentence=[]\n",
        "  predictedLabels,trueLabels=[],[]\n",
        "  \n",
        "  map_location=\"\"\n",
        "  xypredict=[pTweets,tid.flatten()]\n",
        "  \n",
        "  tdataset = GreekPredictDataset(xypredict)\n",
        "  tsampler=RandomSampler(tdataset)\n",
        "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "  print(device.type)\n",
        "  '''model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "  if device.type==\"cpu\":\n",
        "    model.to(device)\n",
        "    map_location='cpu'\n",
        "  else:\n",
        "    model.cuda()\n",
        "    map_location=lambda storage, loc: storage.cuda()\n",
        "  params=list(model.named_parameters())\n",
        "  eval_f1=0\n",
        "  eval_acc=0\n",
        "  nb_eval_steps=0\n",
        "  checkpoint = torch.load('/content/drive/My Drive/DanishData/bertdanish.pth.tar',map_location=map_location)\n",
        "  print(\"Hello\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])'''\n",
        "  model.eval()\n",
        "  i=0\n",
        "  for batch in predictdataloader:\n",
        "      print(i)\n",
        "      i=i+1\n",
        "      batch = tuple(t.to(device) for t in batch)        \n",
        "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"tids\":batch[2]}\n",
        "      \n",
        "      with torch.no_grad():       \n",
        "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      predictedLabels.append(logits)\n",
        "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
        "      finalTid.append(tidl)\n",
        "      calculateScore(logits)\n",
        "      \n",
        "  return predictedLabels,finalTid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3Gp5gPddxj",
        "colab_type": "code",
        "outputId": "78090cf2-2373-4043-8161-3b2dab5b253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "preprocessedTweets,tid=readData1()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id                                              tweet\n",
            "1  1382  Der er syriske \"flygtninge\" som rejser til Ira...\n",
            "2  1384                             Danmark = Vitryssland?\n",
            "3   547  Ja tvangsfjernelser af bÃ¸rn pÃ¥ urigtige oplysn...\n",
            "4  1269  Han kan ikke Svensk og forventer et job. Hvis ...\n",
            "5  1695                                  NED MED SVENSKEN!\n",
            "id        int64\n",
            "tweet    object\n",
            "dtype: object\n",
            "(329, 2)\n",
            "[[1382]\n",
            " [1384]\n",
            " [547]\n",
            " [1269]\n",
            " [1695]\n",
            " [2320]\n",
            " [990]\n",
            " [2665]\n",
            " [1414]\n",
            " [262]\n",
            " [1459]\n",
            " [3375]\n",
            " [1431]\n",
            " [137]\n",
            " [8]\n",
            " [2964]\n",
            " [2542]\n",
            " [1375]\n",
            " [1458]\n",
            " [799]\n",
            " [976]\n",
            " [305]\n",
            " [2643]\n",
            " [386]\n",
            " [715]\n",
            " [2041]\n",
            " [2194]\n",
            " [60]\n",
            " [2181]\n",
            " [720]\n",
            " [552]\n",
            " [2560]\n",
            " [775]\n",
            " [848]\n",
            " [1754]\n",
            " [2363]\n",
            " [1330]\n",
            " [885]\n",
            " [974]\n",
            " [1205]\n",
            " [2589]\n",
            " [2172]\n",
            " [159]\n",
            " [3425]\n",
            " [544]\n",
            " [1371]\n",
            " [30]\n",
            " [1973]\n",
            " [22]\n",
            " [1813]\n",
            " [1379]\n",
            " [99]\n",
            " [1614]\n",
            " [1038]\n",
            " [633]\n",
            " [1275]\n",
            " [924]\n",
            " [962]\n",
            " [1314]\n",
            " [926]\n",
            " [33]\n",
            " [2627]\n",
            " [3396]\n",
            " [1321]\n",
            " [2321]\n",
            " [391]\n",
            " [1143]\n",
            " [1596]\n",
            " [3222]\n",
            " [3122]\n",
            " [716]\n",
            " [173]\n",
            " [2382]\n",
            " [3560]\n",
            " [2046]\n",
            " [1291]\n",
            " [2858]\n",
            " [102]\n",
            " [2577]\n",
            " [1507]\n",
            " [987]\n",
            " [2639]\n",
            " [1505]\n",
            " [3499]\n",
            " [325]\n",
            " [3482]\n",
            " [2068]\n",
            " [1497]\n",
            " [647]\n",
            " [2674]\n",
            " [632]\n",
            " [3522]\n",
            " [133]\n",
            " [3163]\n",
            " [142]\n",
            " [1893]\n",
            " [513]\n",
            " [1487]\n",
            " [883]\n",
            " [219]\n",
            " [1919]\n",
            " [777]\n",
            " [972]\n",
            " [2131]\n",
            " [570]\n",
            " [371]\n",
            " [1344]\n",
            " [3406]\n",
            " [1816]\n",
            " [1469]\n",
            " [3165]\n",
            " [2832]\n",
            " [964]\n",
            " [3150]\n",
            " [1886]\n",
            " [1766]\n",
            " [1599]\n",
            " [224]\n",
            " [2932]\n",
            " [1520]\n",
            " [757]\n",
            " [1315]\n",
            " [3316]\n",
            " [709]\n",
            " [3562]\n",
            " [2192]\n",
            " [3117]\n",
            " [2196]\n",
            " [485]\n",
            " [2076]\n",
            " [1148]\n",
            " [108]\n",
            " [73]\n",
            " [852]\n",
            " [2925]\n",
            " [1455]\n",
            " [1946]\n",
            " [3114]\n",
            " [927]\n",
            " [526]\n",
            " [1189]\n",
            " [3437]\n",
            " [1738]\n",
            " [1659]\n",
            " [678]\n",
            " [2389]\n",
            " [1923]\n",
            " [3012]\n",
            " [850]\n",
            " [218]\n",
            " [753]\n",
            " [1940]\n",
            " [736]\n",
            " [3240]\n",
            " [1545]\n",
            " [3571]\n",
            " [995]\n",
            " [2380]\n",
            " [3398]\n",
            " [85]\n",
            " [2291]\n",
            " [2167]\n",
            " [860]\n",
            " [2502]\n",
            " [3245]\n",
            " [727]\n",
            " [3400]\n",
            " [413]\n",
            " [2204]\n",
            " [1082]\n",
            " [1220]\n",
            " [1546]\n",
            " [712]\n",
            " [646]\n",
            " [2493]\n",
            " [2075]\n",
            " [28]\n",
            " [379]\n",
            " [1928]\n",
            " [2626]\n",
            " [2506]\n",
            " [2245]\n",
            " [2746]\n",
            " [104]\n",
            " [23]\n",
            " [3211]\n",
            " [705]\n",
            " [2137]\n",
            " [774]\n",
            " [2895]\n",
            " [1593]\n",
            " [975]\n",
            " [1534]\n",
            " [1818]\n",
            " [3299]\n",
            " [1809]\n",
            " [2256]\n",
            " [246]\n",
            " [3492]\n",
            " [2085]\n",
            " [1139]\n",
            " [1907]\n",
            " [1285]\n",
            " [380]\n",
            " [1698]\n",
            " [3545]\n",
            " [2725]\n",
            " [3323]\n",
            " [4]\n",
            " [699]\n",
            " [1251]\n",
            " [966]\n",
            " [2153]\n",
            " [1439]\n",
            " [3108]\n",
            " [1558]\n",
            " [209]\n",
            " [3494]\n",
            " [2934]\n",
            " [1064]\n",
            " [1942]\n",
            " [492]\n",
            " [1089]\n",
            " [621]\n",
            " [940]\n",
            " [1188]\n",
            " [3143]\n",
            " [2049]\n",
            " [2066]\n",
            " [763]\n",
            " [579]\n",
            " [2449]\n",
            " [375]\n",
            " [2063]\n",
            " [2155]\n",
            " [261]\n",
            " [859]\n",
            " [1292]\n",
            " [1105]\n",
            " [3397]\n",
            " [3431]\n",
            " [2532]\n",
            " [3524]\n",
            " [2111]\n",
            " [2191]\n",
            " [2907]\n",
            " [1167]\n",
            " [1164]\n",
            " [3084]\n",
            " [1200]\n",
            " [534]\n",
            " [2299]\n",
            " [3069]\n",
            " [1103]\n",
            " [3177]\n",
            " [1889]\n",
            " [3424]\n",
            " [2373]\n",
            " [341]\n",
            " [658]\n",
            " [651]\n",
            " [442]\n",
            " [2677]\n",
            " [1944]\n",
            " [1311]\n",
            " [430]\n",
            " [2040]\n",
            " [1096]\n",
            " [581]\n",
            " [2683]\n",
            " [2540]\n",
            " [2414]\n",
            " [701]\n",
            " [1095]\n",
            " [2959]\n",
            " [769]\n",
            " [2836]\n",
            " [274]\n",
            " [1846]\n",
            " [94]\n",
            " [1044]\n",
            " [1791]\n",
            " [890]\n",
            " [26]\n",
            " [79]\n",
            " [2080]\n",
            " [1131]\n",
            " [798]\n",
            " [2048]\n",
            " [620]\n",
            " [404]\n",
            " [1427]\n",
            " [519]\n",
            " [2864]\n",
            " [3304]\n",
            " [3166]\n",
            " [546]\n",
            " [459]\n",
            " [2050]\n",
            " [880]\n",
            " [1123]\n",
            " [138]\n",
            " [1425]\n",
            " [1996]\n",
            " [2036]\n",
            " [1568]\n",
            " [1303]\n",
            " [1917]\n",
            " [734]\n",
            " [641]\n",
            " [2412]\n",
            " [2928]\n",
            " [9]\n",
            " [2799]\n",
            " [3062]\n",
            " [1106]\n",
            " [184]\n",
            " [3534]\n",
            " [3512]\n",
            " [2634]\n",
            " [1338]\n",
            " [2238]\n",
            " [3326]\n",
            " [3567]\n",
            " [1591]\n",
            " [1769]\n",
            " [2443]\n",
            " [3221]\n",
            " [400]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw_7IjQpiLHw",
        "colab_type": "code",
        "outputId": "9a6dc86c-7ab7-4b0b-f1e2-bb6bbb7ea23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "predictedLabels,finalTid=predictingData(preprocessedTweets,tid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "0\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "1\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "2\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "3\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
            "4\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "5\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "6\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "7\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "8\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "9\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "10\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3ajuk04jw-",
        "colab_type": "code",
        "outputId": "abc6aa0d-9302-4ae8-eb48-cb24b8cbe1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/DanishData/bertdanish.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/DanishData/bertdanish.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBxBKJFVaFjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
        "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdm6cxWpodZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "yans=list(chain.from_iterable(yans))\n",
        "ytid=list(chain.from_iterable(ytid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8HSGUkNofbW",
        "colab_type": "code",
        "outputId": "43f46b8c-8e86-4245-fbba-95c49472d089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ytid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveSLjS4oRXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans1=[\"NOT\" if yans[i]==0 else \"OFF\" for i in range(len(yans))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtxToRGIoNtc",
        "colab_type": "code",
        "outputId": "8c263b8f-645e-4049-ed64-336ef209af34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(yans1.count(\"OFF\"))\n",
        "print(yans1.count(\"NOT\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25c0lKP1oYAr",
        "colab_type": "code",
        "outputId": "69a88668-faba-4259-e3ed-283a2ee1e3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
        "#print(len(z))\n",
        "C = {'id': ytid,\n",
        "        'predicted': yans1,\n",
        "    }\n",
        "df = pd.DataFrame(C)\n",
        "print (df[df['id'] == 400] )\n",
        "\n",
        "export_csv = df.to_csv ('/content/drive/My Drive/DanishData/Answer.csv', index = None, header=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id predicted\n",
            "63  400       NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3_AaAvxliJm",
        "colab_type": "text"
      },
      "source": [
        "from 80 ,10 ,10 split getting  # F1 score: 0.836 Accuracy score: 0.867"
      ]
    }
  ]
}