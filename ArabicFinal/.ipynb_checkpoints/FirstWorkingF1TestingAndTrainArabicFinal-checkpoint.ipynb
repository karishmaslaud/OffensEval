{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "l0-z91UlfiRk",
    "outputId": "c9be26c2-b911-40ae-f604-948fbfdac0f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all imports\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "9b0ba3e4-f2fd-49fe-f8b4-a1bed34ffbe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  raise(SystemError('GPU device not found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "4406b953-a856-452f-dd21-3f904ed9d8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU DEVICES available \n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "colab_type": "code",
    "id": "buldkQJQiKYI",
    "outputId": "a7c77130-d7e3-48a7-bfbd-bc0648a04430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 14.0MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 20kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 30kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 40kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 51kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 61kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 71kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 81kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 92kB 4.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 102kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 112kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 122kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 133kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 143kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 153kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 163kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 174kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 184kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 194kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 204kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 215kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 225kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 235kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 245kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 256kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 266kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 276kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 286kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 296kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 307kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 317kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 327kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 337kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 348kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 358kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 368kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 378kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 389kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 399kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 409kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 419kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 430kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 440kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 450kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 460kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 471kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 481kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 491kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 501kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 36.1MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 30.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 31.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=8d73a13b62a8fd9395191b49b55d73c812554edc86a6ec21ac103ddcbddddc2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "2d489978-6a04-4f34-eb4e-0e2f2ec62853",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "6_byFfpTf1D9"
   },
   "source": [
    "#Custom Data set and Data loader has  been adapted and inspired from \n",
    "Michael Sugimura,\"BERT Classifier: Just Another Pytorch Model\",Medium/TowardsDataScience,10 June.2019.https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784\n",
    "Github Repository:https://github.com/sugi-chan/custom_bert_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BERT based fine tuning adapted and inspired from:Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning Tutorial with PyTorch. Retrieved from http://www.mccormickml.com"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#for all references refer README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iCZDHmlWSjY"
   },
   "outputs": [],
   "source": [
    "!unzip -P ****** -qq '/content/drive/My Drive/ArabicData/Arabic.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucAFIEswSPcQ"
   },
   "outputs": [],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a']\n",
    "greekdata = pd.read_csv(\"Arabic/offenseval-ar-training-v1.tsv\", delimiter='\\t',names=headers)\n",
    "data=greekdata[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "gSe3Jv-QkZ8a",
    "outputId": "d3991a16-090e-40bf-d9c4-f1d3e658f231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>الحمدلله يارب فوز مهم يا زمالك.. كل الدعم ليكم...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>فدوه يا بخت فدوه يا زمن واحد منكم يجيبه</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @USER: يا رب يا واحد يا أحد بحق يوم الاحد ا...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @USER: #هوا_الحرية يا وجع قلبي عليكي يا امي...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>يا بكون بحياتك الأهم يا إما ما بدي أكون 🎼</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                              tweet subtask_a\n",
       "1  1  الحمدلله يارب فوز مهم يا زمالك.. كل الدعم ليكم...       NOT\n",
       "2  2            فدوه يا بخت فدوه يا زمن واحد منكم يجيبه       NOT\n",
       "3  3  RT @USER: يا رب يا واحد يا أحد بحق يوم الاحد ا...       OFF\n",
       "4  4  RT @USER: #هوا_الحرية يا وجع قلبي عليكي يا امي...       NOT\n",
       "5  5          يا بكون بحياتك الأهم يا إما ما بدي أكون 🎼       NOT"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bnhbuYtZL0zO",
    "outputId": "4f08c93d-a62c-4ee3-8751-856bc14cdabc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7839"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXNuys5ZaNOQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "dfnumpy=data.to_numpy();\n",
    "x=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExTr4SRfO6Iv"
   },
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in y:\n",
    "  if i == 'NOT':\n",
    "   c = c+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "U89nu4PBSSZD",
    "outputId": "e7cf529d-5da6-4ce7-c74e-48db607bea5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "\r",
      "\u001b[K     |███████▌                        | 10kB 20.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=c7fea69e7f143d5ce9580cb6e08fd06cdac417e13344b65f167741de897790f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY5vGRQYdq5F"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ft1(l):\n",
    "    a = re.split('|\\]|\\[|\\)|\\(|; |,|\\*|\\n',l)\n",
    "    li = []\n",
    "    for t in a:\n",
    "        li.append(t.strip(' ,')) \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOEIfAgyr83C"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "def preprocessinglib1(arrt):\n",
    "    ans =[]\n",
    "    for txt in arrt:\n",
    "        txt1=emoji.demojize(txt)\n",
    "        unique_words = dict.fromkeys(txt1.split())\n",
    "        txt2=' '.join(unique_words)\n",
    "        tokens=tknzr.tokenize(txt2)\n",
    "        ctokens=[]\n",
    "        for t in tokens:\n",
    "          if t not in string.punctuation :\n",
    "            ctokens.append(t)\n",
    "        clean_s = ' '.join(ctokens)\n",
    "        ans.append(clean_s)\n",
    "               \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBEJq9Muw__K"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import emoji\n",
    "import string\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "def preprocessinglib(arrt):\n",
    "    ans =[]\n",
    "    for txt in arrt:\n",
    "        txt1=emoji.demojize(txt)\n",
    "        unique_words = dict.fromkeys(txt1.split(\" \"))\n",
    "        txt2=' '.join(unique_words)\n",
    "        ans.append(ft1(txt2))\n",
    "               \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "chD2GSH5dHb1",
    "outputId": "d2bac471-2213-4a73-f586-2a9ab71a40df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "arrt=x[:,0]\n",
    "allTokens=preprocessinglib(arrt)\n",
    "#allTokenstrain, allTokenstest, y_train, y_test = train_test_split(allTokens,y, test_size=0.2, random_state=42)\n",
    "#allTokensPredict, _, y_predict, _ = train_test_split(allTokenstest,y_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2X-eKHng4jUh"
   },
   "outputs": [],
   "source": [
    "preprocessedTweets=allTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "_u9FNcYBwl3t",
    "outputId": "24ebcffd-fb34-492a-dbad-0fb2f56c93ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['الحمدلله يارب فوز مهم يا زمالك.. كل الدعم ليكم رجالة :white_circle::red_circle:<LF>الدوري زمالك .. الدوري زمالك<LF>#صدارة_بس'],\n",
       " ['فدوه يا بخت زمن واحد منكم يجيبه'],\n",
       " ['RT @USER: يا رب واحد أحد بحق يوم الاحد ان تهلك بني سعود المجرمين. لاجل اطفال اليمن شاركوا.'],\n",
       " ['RT @USER: #هوا_الحرية يا وجع قلبي عليكي امي...<LF>الله لا يحرق قلبك ويكسر بخاطرك للمرة الف نقف إجلال لعظمة وقدرة لين قلب الأم ال…'],\n",
       " ['يا بكون بحياتك الأهم إما ما بدي أكون :musical_score:']]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedTweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZLNpEq1VVUH"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Y7m4cgbJLwXW",
    "outputId": "2dc0169c-eb8d-4c0e-955f-c25bad055993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NOT'],\n",
       "       ['NOT'],\n",
       "       ['OFF'],\n",
       "       ...,\n",
       "       ['NOT'],\n",
       "       ['OFF'],\n",
       "       ['NOT']], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzyloI-QNt2a"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/preprocessedTweetsArabic.txt', 'w') as f:\n",
    "  f.write(str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3TImBZYl4wih",
    "outputId": "6cf61870-9eb0-47d8-b5a8-2d1ee928446b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['RT @USER: أعشق ترابك يا فلسطين قدس منارة الشرائع، طفلة جميلة محروقة الأصابع، حزينة عيناك مدينة البتول، واحة ظليلة…'], ['@USER يا رب تفوتني'], ['RT @USER: @USER امشي يا كلب العسكر خنزير عتلو .. يسقط حكم ويسقط كل كلاب العسكر.'], ['@USER هههههههه اقول يالعبد جيب لك واحد ارجلك منك حطة رئيس عليك بعد ما عرفت انه فيه دول كثير تحكمها ملوك قلت لا انتي دولتك غير يا متخلف حاقد حاسد الاخوانيه صاحبه قطر الارهابيه وسلمتم جزيره سواكن لاردوغان يالعب'], ['يا نهار اسود اسود.. الكوره اوفسايد<LF>والواد رامي نفسه لتاني مره<LF>ده انت حكم ابن جذمه']]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessedTweets[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iFSxRGBU-jXr",
    "outputId": "34e2a6e6-87f0-450d-89a6-549854323ba5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "de69f51d3d824c33953f631ff2c7827e",
      "019cf06ee412408f8ec88ea06a28ab80",
      "61521ec16c7c409da353251dbcede184",
      "66ba47367b75420eb4e3e7884ca5785e",
      "bcfcc6ea587047769185394612df25ad",
      "dec954f1256343c9869a341eecb6248f",
      "11581289e21e4dd8a8d6911e719fa932",
      "354a654ed57a4123b57bea3b4f88cd7f"
     ]
    },
    "colab_type": "code",
    "id": "utvnzPv3Ar4O",
    "outputId": "c55bcb8e-c875-486b-b9a5-6d55d8da9997"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de69f51d3d824c33953f631ff2c7827e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTPHRB940GMF"
   },
   "outputs": [],
   "source": [
    "yavg=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIn1L3EaG_Ts"
   },
   "outputs": [],
   "source": [
    "sentence_train, sentence_test, y_train, y_test = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n",
    "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "7CYsPFfkdWL9",
    "outputId": "8aa9c04c-3b4d-4ce9-ea29-4e5c25bdc18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOT' 'OFF']\n",
      "(6271, 1)\n",
      "(1568, 1)\n",
      "(6271,)\n",
      "['NOT' 'OFF']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit_transform(['NOT','OFF'])\n",
    "print(le.classes_)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "yTrain=le.transform(y_train.flatten())\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwrbFDiqjh1K"
   },
   "outputs": [],
   "source": [
    "yTest=le.transform(y_test.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4cVrhEIdd2FL",
    "outputId": "6ccd951e-b0c6-435e-82d4-c15b4804f2b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFcDGmeNVbKd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=64\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MRzkZ70fqRJ"
   },
   "outputs": [],
   "source": [
    "#from torch.utils.data import Dataset\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=64\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength-2]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt6HvS5-dpok"
   },
   "outputs": [],
   "source": [
    "xytrain=[sentence_train,yTrain]\n",
    "tdataset = GreekTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGJiYjC1fb1V"
   },
   "outputs": [],
   "source": [
    "xytest=[sentence_test,yTest]\n",
    "tedataset = GreekTestDataset(xytest)\n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4b6dec177b4f49fe860546f0ac2e5c9d",
      "57deeeb1a0604b3d8d73b39807141e21",
      "d2a96c74fefc4f0fbd9210b02b571d06",
      "12ecad72345b46f3817abadcef621979",
      "5f718af2835b4ca5b11525ae10c19789",
      "e17ed6d915d44e7fae18874482bc3410",
      "035a935b79c042dea1ee2f5f889e37e8",
      "9e95acafe0cc4ca1a28d84153f684b56",
      "d908f6311d644550a9b456498b44482e",
      "58f8a584e074473ead2570ea9171883c",
      "fad7e96815cd49f38d53a37680378e79",
      "9858d40830794c1b828a30145d1259fe",
      "91c170669c2848d4b31f4786cbfb9582",
      "8456faa7ef4c449c91eef1e73767acc2",
      "b5e59ef255794532b418740669eb54d7",
      "80001acfacee4e18bdb4ddb23cec2915"
     ]
    },
    "colab_type": "code",
    "id": "2bOBLycdL0lc",
    "outputId": "f2d0b902-57f3-4c3b-f2e3-7c28d39a74d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6dec177b4f49fe860546f0ac2e5c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d908f6311d644550a9b456498b44482e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JyH9yvdIO208",
    "outputId": "79f3e8c7-b89e-42cd-c9cb-ac765aed1d04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/ArabicData/bertarabic.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/ArabicData/bertarabic.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iF4guWRdOTS4"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKOeqrn-jopN"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RlThDORmMrf"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FRiX25tlMdG"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs=4\n",
    "total_steps=len(tdataloader)*epochs\n",
    "\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6LNSaNZpKVT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    "  print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "brS_TJmHJs0I",
    "outputId": "b606518c-540b-489f-d880-27218696b0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch Number 1\n",
      "Start Training\n",
      "Batch Completed  50  of  196.    Elapsed time is  12.195894002914429\n",
      "Batch Completed  100  of  196.    Elapsed time is  24.023903369903564\n",
      "Batch Completed  150  of  196.    Elapsed time is  35.7148232460022\n",
      " The training loss incured is  0.412\n",
      "  Training one epoch time taken 46.506860971450806\n",
      " Validation starts here \n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "labelsFlattend [0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "labelsFlattend [1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1]\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "predictionArgmax [1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "labelsFlattend [0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
      "  F1 score: 0.759\n",
      "  Accuracy score: 0.872\n",
      "  Validating one epoch time taken  3.223816156387329\n",
      "Start Epoch Number 2\n",
      "Start Training\n",
      "Batch Completed  50  of  196.    Elapsed time is  11.857626914978027\n",
      "Batch Completed  100  of  196.    Elapsed time is  23.60718083381653\n",
      "Batch Completed  150  of  196.    Elapsed time is  35.3266921043396\n",
      " The training loss incured is  0.285\n",
      "  Training one epoch time taken 46.12631916999817\n",
      " Validation starts here \n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1]\n",
      "labelsFlattend [0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1]\n",
      "labelsFlattend [0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "predictionArgmax [1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1]\n",
      "labelsFlattend [1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1]\n",
      "labelsFlattend [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      "labelsFlattend [0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      "predictionArgmax [1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 0]\n",
      "predictionArgmax [1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "  F1 score: 0.808\n",
      "  Accuracy score: 0.885\n",
      "  Validating one epoch time taken  3.223188877105713\n",
      "Start Epoch Number 3\n",
      "Start Training\n",
      "Batch Completed  50  of  196.    Elapsed time is  11.815305233001709\n",
      "Batch Completed  100  of  196.    Elapsed time is  23.574537992477417\n",
      "Batch Completed  150  of  196.    Elapsed time is  35.25079941749573\n",
      " The training loss incured is  0.197\n",
      "  Training one epoch time taken 46.05664014816284\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
      "predictionArgmax [0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0]\n",
      "predictionArgmax [1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1]\n",
      "labelsFlattend [0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "labelsFlattend [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      "  F1 score: 0.828\n",
      "  Accuracy score: 0.898\n",
      "  Validating one epoch time taken  3.2499141693115234\n",
      "Start Epoch Number 4\n",
      "Start Training\n",
      "Batch Completed  50  of  196.    Elapsed time is  11.777050733566284\n",
      "Batch Completed  100  of  196.    Elapsed time is  23.47594666481018\n",
      "Batch Completed  150  of  196.    Elapsed time is  35.15682601928711\n",
      " The training loss incured is  0.131\n",
      "  Training one epoch time taken 45.927029848098755\n",
      " Validation starts here \n",
      "predictionArgmax [0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      "labelsFlattend [1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      "predictionArgmax [0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      "predictionArgmax [1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1]\n",
      "predictionArgmax [1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0]\n",
      "labelsFlattend [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "predictionArgmax [0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "  F1 score: 0.825\n",
      "  Accuracy score: 0.901\n",
      "  Validating one epoch time taken  3.2318179607391357\n",
      "ALL DONE!!!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=4\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    \n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()        \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    \n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "   \n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "\n",
    "    for batch in tedataloader:       \n",
    "        batch = tuple(t.to(device) for t in batch)        \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "\n",
    "\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    \n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "    \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4su1qmuVG5q"
   },
   "outputs": [],
   "source": [
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/ArabicData/bertarabic.pth.tar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "q4rWdrUSxJIV",
    "outputId": "bf389f3e-baf2-4cc7-9c45-789fcad9b329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /content/drive/My Drive/ArabicData/Arabic/task_a_baseline.zip, /content/drive/My Drive/ArabicData/Arabic/task_a_baseline.zip.zip or /content/drive/My Drive/ArabicData/Arabic/task_a_baseline.zip.ZIP.\n",
      "unzip:  cannot find or open /content/drive/My Drive/ArabicData/Arabic/offenseval-ar-testset-v1.zip, /content/drive/My Drive/ArabicData/Arabic/offenseval-ar-testset-v1.zip.zip or /content/drive/My Drive/ArabicData/Arabic/offenseval-ar-testset-v1.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip -P ****** -qq '/content/drive/My Drive/ArabicData/Arabic/task_a_baseline.zip'\n",
    "!unzip -P ****** -qq '/content/drive/My Drive/ArabicData/Arabic/offenseval-ar-testset-v1.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19c06d4ChmVm"
   },
   "outputs": [],
   "source": [
    "ygiven=[]\n",
    "ypredicted=[]\n",
    "\n",
    "def convertToInt(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.int64(val)\n",
    "    except:        \n",
    "        return np.int64(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRhcqakGho3E"
   },
   "outputs": [],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['id','tweet']\n",
    "  greekDataTest = pd.read_csv(\"offenseval-ar-test-tweets-v1.tsv\", delimiter='\\t',names=headers,quoting=csv.QUOTE_NONE,\n",
    "                                converters={\"id\":convertToInt})\n",
    "  greekDataTest=greekDataTest[1:]\n",
    "  print(greekDataTest.head())\n",
    "  print(greekDataTest.dtypes)\n",
    "  print(greekDataTest.shape)\n",
    "  \n",
    "  dfnumpy=greekDataTest.to_numpy();\n",
    "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  print(tid)\n",
    "  arrt=X[:,0]\n",
    "  allTokens=preprocessinglib(arrt)\n",
    "  preprocessedTweets=arrt\n",
    "  return preprocessedTweets,tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "-CgDHQVwhsFY",
    "outputId": "1359cc02-cc09-43d1-a5a0-6e96fbc98e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              tweet\n",
      "1  8001  @USER اما انت تقعد طول عمرك لا مبدا ولا راي ثا...\n",
      "2  8002  @USER @USER بتخاف نسوانك يزعلوا ولا ايه 😂 اه ي...\n",
      "3  8003  RT @USER: يا عـسانـى نـبـقى يا عـمري حـبايـب و...\n",
      "4  8004  RT @USER: باقي البيان وينو ما شفنه يا برهان <L...\n",
      "5  8005  @USER @USER اللهم انت الشافي المعافي اشفيه وجم...\n",
      "id        int64\n",
      "tweet    object\n",
      "dtype: object\n",
      "(2000, 2)\n",
      "[[8001]\n",
      " [8002]\n",
      " [8003]\n",
      " ...\n",
      " [9998]\n",
      " [9999]\n",
      " [10000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "preprocessedTweets,tid=readData1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AukQQ0jWhxTm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekPredictDataset(Dataset):\n",
    "    def __init__(self,xypredict):\n",
    "        self.xypredict = xypredict\n",
    "        self.maxlength=64\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
    "        tid_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
    "        \n",
    "        return x_predict_pytorch,x_predict_mask_pytorch,tid_predict_pytorch\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.xypredict[0])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf_TvSaYn1AJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def calculateScore(predictions):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  yres.append(predictionArgmax.flatten())\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWKfHXfplWQ_"
   },
   "outputs": [],
   "source": [
    "yres=[]\n",
    "finalTid=[]\n",
    "def predictingData(pTweets,tid):\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  map_location=\"\"\n",
    "  xypredict=[pTweets,tid.flatten()]\n",
    "  \n",
    "  tdataset = GreekPredictDataset(xypredict)\n",
    "  tsampler=RandomSampler(tdataset)\n",
    "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "  print(device.type)\n",
    "  model.eval()\n",
    "  i=0\n",
    "  for batch in predictdataloader:\n",
    "      print(i)\n",
    "      i=i+1\n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"tids\":batch[2]}\n",
    "      \n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
    "      finalTid.append(tidl)\n",
    "      calculateScore(logits)\n",
    "      \n",
    "  return predictedLabels,finalTid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "Cn3Gp5gPddxj",
    "outputId": "90427f28-b325-4553-e50f-ab71eab6d86e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              tweet\n",
      "1  8001  @USER اما انت تقعد طول عمرك لا مبدا ولا راي ثا...\n",
      "2  8002  @USER @USER بتخاف نسوانك يزعلوا ولا ايه 😂 اه ي...\n",
      "3  8003  RT @USER: يا عـسانـى نـبـقى يا عـمري حـبايـب و...\n",
      "4  8004  RT @USER: باقي البيان وينو ما شفنه يا برهان <L...\n",
      "5  8005  @USER @USER اللهم انت الشافي المعافي اشفيه وجم...\n",
      "id        int64\n",
      "tweet    object\n",
      "dtype: object\n",
      "(2000, 2)\n",
      "[[8001]\n",
      " [8002]\n",
      " [8003]\n",
      " ...\n",
      " [9998]\n",
      " [9999]\n",
      " [10000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "preprocessedTweets,tid=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Jw_7IjQpiLHw",
    "outputId": "d17424b9-b0f5-49bb-9b53-fdf94dc5135f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "2\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "3\n",
      "predictionArgmax [1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "predictionArgmax [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "5\n",
      "predictionArgmax [0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1]\n",
      "6\n",
      "predictionArgmax [1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "7\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "8\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "9\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "10\n",
      "predictionArgmax [1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
      "11\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "12\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "13\n",
      "predictionArgmax [0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "14\n",
      "predictionArgmax [0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1]\n",
      "15\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "16\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      "17\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0]\n",
      "18\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "19\n",
      "predictionArgmax [0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "20\n",
      "predictionArgmax [0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "21\n",
      "predictionArgmax [1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0]\n",
      "22\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0]\n",
      "23\n",
      "predictionArgmax [1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "24\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      "25\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0]\n",
      "26\n",
      "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "27\n",
      "predictionArgmax [1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "28\n",
      "predictionArgmax [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      "29\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "30\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1]\n",
      "31\n",
      "predictionArgmax [1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "32\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "34\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "35\n",
      "predictionArgmax [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "36\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "37\n",
      "predictionArgmax [1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1]\n",
      "38\n",
      "predictionArgmax [0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "39\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1]\n",
      "40\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "41\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      "42\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "43\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "44\n",
      "predictionArgmax [0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0]\n",
      "45\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "46\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "47\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "48\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "49\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "50\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "51\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1]\n",
      "52\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "53\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0]\n",
      "54\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "55\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "56\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "57\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "58\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "59\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "60\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "61\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "62\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "predictedLabels,finalTid=predictingData(preprocessedTweets,tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBxBKJFVaFjr"
   },
   "outputs": [],
   "source": [
    "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
    "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdm6cxWpodZ6"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "yans=list(chain.from_iterable(yans))\n",
    "ytid=list(chain.from_iterable(ytid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T8HSGUkNofbW",
    "outputId": "7e4a74fc-b8ab-4b29-ef6c-ca0c439dda9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CveSLjS4oRXx"
   },
   "outputs": [],
   "source": [
    "yans1=[\"NOT\" if yans[i]==0 else \"OFF\" for i in range(len(yans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xtxToRGIoNtc",
    "outputId": "89093cfd-13af-44a3-ae0e-c36cb735eecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "1661\n"
     ]
    }
   ],
   "source": [
    "print(yans1.count(\"OFF\"))\n",
    "print(yans1.count(\"NOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "25c0lKP1oYAr",
    "outputId": "2bed0166-06de-4083-9bb6-0706f24548ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, predicted]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
    "#print(len(z))\n",
    "C = {'id': ytid,\n",
    "        'predicted': yans1,\n",
    "    }\n",
    "df = pd.DataFrame(C)\n",
    "print (df[df['id'] == 400] )\n",
    "\n",
    "export_csv = df.to_csv ('/content/drive/My Drive/ArabicData/ArabicAnswer.csv', index = None, header=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "FirstWorkingF1TestingAndTrainArabicFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019cf06ee412408f8ec88ea06a28ab80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "035a935b79c042dea1ee2f5f889e37e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11581289e21e4dd8a8d6911e719fa932": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12ecad72345b46f3817abadcef621979": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e95acafe0cc4ca1a28d84153f684b56",
      "placeholder": "​",
      "style": "IPY_MODEL_035a935b79c042dea1ee2f5f889e37e8",
      "value": "100% 569/569 [00:00&lt;00:00, 16.8kB/s]"
     }
    },
    "354a654ed57a4123b57bea3b4f88cd7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b6dec177b4f49fe860546f0ac2e5c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2a96c74fefc4f0fbd9210b02b571d06",
       "IPY_MODEL_12ecad72345b46f3817abadcef621979"
      ],
      "layout": "IPY_MODEL_57deeeb1a0604b3d8d73b39807141e21"
     }
    },
    "57deeeb1a0604b3d8d73b39807141e21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58f8a584e074473ead2570ea9171883c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f718af2835b4ca5b11525ae10c19789": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "61521ec16c7c409da353251dbcede184": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dec954f1256343c9869a341eecb6248f",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcfcc6ea587047769185394612df25ad",
      "value": 995526
     }
    },
    "66ba47367b75420eb4e3e7884ca5785e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_354a654ed57a4123b57bea3b4f88cd7f",
      "placeholder": "​",
      "style": "IPY_MODEL_11581289e21e4dd8a8d6911e719fa932",
      "value": "100% 996k/996k [00:00&lt;00:00, 12.2MB/s]"
     }
    },
    "80001acfacee4e18bdb4ddb23cec2915": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8456faa7ef4c449c91eef1e73767acc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91c170669c2848d4b31f4786cbfb9582": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9858d40830794c1b828a30145d1259fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80001acfacee4e18bdb4ddb23cec2915",
      "placeholder": "​",
      "style": "IPY_MODEL_b5e59ef255794532b418740669eb54d7",
      "value": "100% 714M/714M [00:12&lt;00:00, 57.7MB/s]"
     }
    },
    "9e95acafe0cc4ca1a28d84153f684b56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5e59ef255794532b418740669eb54d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcfcc6ea587047769185394612df25ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d2a96c74fefc4f0fbd9210b02b571d06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e17ed6d915d44e7fae18874482bc3410",
      "max": 569,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f718af2835b4ca5b11525ae10c19789",
      "value": 569
     }
    },
    "d908f6311d644550a9b456498b44482e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fad7e96815cd49f38d53a37680378e79",
       "IPY_MODEL_9858d40830794c1b828a30145d1259fe"
      ],
      "layout": "IPY_MODEL_58f8a584e074473ead2570ea9171883c"
     }
    },
    "de69f51d3d824c33953f631ff2c7827e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61521ec16c7c409da353251dbcede184",
       "IPY_MODEL_66ba47367b75420eb4e3e7884ca5785e"
      ],
      "layout": "IPY_MODEL_019cf06ee412408f8ec88ea06a28ab80"
     }
    },
    "dec954f1256343c9869a341eecb6248f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e17ed6d915d44e7fae18874482bc3410": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fad7e96815cd49f38d53a37680378e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8456faa7ef4c449c91eef1e73767acc2",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91c170669c2848d4b31f4786cbfb9582",
      "value": 714314041
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
