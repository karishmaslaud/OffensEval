{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1HZ3sJ-t1SC"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iCcqa_7et4cD",
    "outputId": "8d86580b-64d8-4b3d-8bee-64c13a44c391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  raise(SystemError('GPU device not found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qNFEaLvKt-Zt",
    "outputId": "065572ab-9e29-45e0-914c-ce5ede23165d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU DEVICES available \n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BLjWz-0TuCbl",
    "outputId": "135e0d92-ad3e-464c-b774-f7ce08868559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "lddBU1JluKTa",
    "outputId": "3ea65c45-1904-46a6-d5de-8b1d196bbf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace Greek/offenseval-greek-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace Greek/readme-trainingset-greek.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace readme-testsetA-v1.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace testset_taska.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
     ]
    }
   ],
   "source": [
    "!unzip -P yourpassword -qq '/content/drive/My Drive/GreekData/Greek.zip'\n",
    "!unzip -P yourpassword -qq '/content/drive/My Drive/GreekData/offenseval2020-test-greek.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAUepT0HuPeC"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HB7ngrnscIG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "uVXNdz8auhGR",
    "outputId": "c92d1b58-c0a2-49a0-9f9b-ff7ffaedf9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgkzEygbscIY"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer=BertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R_e-oxPiscJC",
    "outputId": "73eee749-718e-4154-d6a2-5a8e357a3d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bIDGEuatscJM",
    "outputId": "a7b3e5b3-dc14-42c7-8a39-b36a77c355f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i8xtYY9EscJV",
    "outputId": "d98773e9-22c7-45c3-974f-9ba471f93f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3jBiYT5MscJf",
    "outputId": "9a1956c6-f14b-4ac5-c9b2-09e600e395b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-multilingual-cased']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4pIvsO70Ok67",
    "outputId": "43acf107-05a8-4155-b2dc-367770cf0f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jbQ8PWrURW-_",
    "outputId": "e3b59cba-f382-4a86-e1d9-408100a636db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('el_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"el_core_news_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Yr0OS6pRXC-"
   },
   "outputs": [],
   "source": [
    "#LEMMATIZATION\n",
    "import string\n",
    "import spacy\n",
    "#import el_core_news_sm \n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "nlp =  spacy.load('el_core_news_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-N5RmlcYscJm"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    s=\"\"\n",
    "    txt1=emoji.demojize(sentence)\n",
    "    x1=nlp(txt1)\n",
    "    #print(x1)\n",
    "    x2=[]\n",
    "    for t in x1:\n",
    "        z=str(t)\n",
    "        if z not in string.punctuation  and t.is_stop==False:\n",
    "          x2.append(z)\n",
    "    s+=' '.join(x2)\n",
    "    #print(s)  \n",
    "    tokens = tokenizer.tokenize(s) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vICs3ikTJ1LN"
   },
   "outputs": [],
   "source": [
    "tokenize_and_cut(\"@USER Οι μουσουλμάνες που τις βιάζουν έτσι κ αλλιώς, οπότε τις βολεύει να κυνηγούν εμάς κ να αφήσουν αυτές ήσυχες οι άντρες τους.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-IQaMo9scJv"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "#TIDS=data.Field(use_vocab=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VXI0Qa-wy7w"
   },
   "outputs": [],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a']\n",
    "greekdata = pd.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
    "data=greekdata[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PonTY7lu5uqW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_kfrfapw91l"
   },
   "outputs": [],
   "source": [
    "greektrain,greektest= train_test_split(greekdata, test_size=0.2, random_state=42)\n",
    "export_csv = greektrain.to_csv ('Greek/TrainFilegreek.csv', index = None, header=True)\n",
    "print (greektrain.head())\n",
    "export_csv = greektest.to_csv ('Greek/TestFilegreek.csv', index = None, header=True)\n",
    "print (greektest.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8488fpXoJ7Y"
   },
   "outputs": [],
   "source": [
    "ygiven=[]\n",
    "ypredicted=[]\n",
    "\n",
    "def convertToInt(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.int64(val)\n",
    "    except:        \n",
    "        return np.int64(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "UcfDXn36bLxw",
    "outputId": "abdfd8ca-23b2-45a8-d911-a8964cc5fde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1544, 2)\n",
      "     id                                              tweet ypredicted\n",
      "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
      "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
      "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
      "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
      "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n",
      "id             int64\n",
      "tweet         object\n",
      "ypredicted    object\n",
      "dtype: object\n",
      "(1544, 3)\n",
      "     id                                              tweet ypredicted\n",
      "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
      "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
      "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
      "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
      "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n"
     ]
    }
   ],
   "source": [
    "headers=['id','ypredicted']\n",
    "greekdataBaseline = pd.read_csv(\"/content/drive/My Drive/OffensEvalGoldLabels/greek-goldlabels.csv\", delimiter=',',names=headers)\n",
    "#,converters={\"id\":convertToInt}       \n",
    "greekdataBaseline.id = greekdataBaseline.id.astype(int)\n",
    "#greekdataBaseline=greekdataBaseline[1:]\n",
    "#print(greekdataBaseline.dtypes)\n",
    "headers=['id','tweet']\n",
    "greekDataTest = pd.read_csv(\"testset_taska.tsv\", delimiter='\\t',names=headers,\n",
    "                              converters={\"id\":convertToInt})\n",
    "greekDataTest=greekDataTest[1:]\n",
    "#print(greekDataTest.head())\n",
    "#print(greekDataTest.dtypes)\n",
    "print(greekDataTest.shape)\n",
    "result = pd.merge(greekDataTest, greekdataBaseline, on='id', how='inner')\n",
    "print(result.head())\n",
    "print(result.dtypes)\n",
    "print(result.shape)\n",
    "#result=\n",
    "#result.sort_values(by=['id'], inplace=True)\n",
    "print(result.head())\n",
    "dfnumpy=result.to_numpy();\n",
    "X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)\n",
    "tid=dfnumpy[:, 0].reshape(-1, 1)\n",
    "#print(tid)\n",
    "#arrt=X[:,0]\n",
    "#preprocessedTweets=arrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "y4WUHe1obed5",
    "outputId": "d01a95ab-df21-495e-ac18-e72cc2c8137f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              tweet ypredicted\n",
      "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
      "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
      "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
      "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
      "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n"
     ]
    }
   ],
   "source": [
    "export_csv = result.to_csv ('Greek/PredictFilegreek.csv', index = None, header=True)\n",
    "print (result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vMyDTjoscJ2"
   },
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "from torchtext import data\n",
    "\n",
    "train_val_fields = [\n",
    "    ('id', None), # we dont need this, so no processing\n",
    "    ('tweet', TEXT), # process it as label\n",
    "    ('subtask_a', LABEL) # we dont need this, so no processing\n",
    "]\n",
    "\n",
    "train_data, valid_data = data.TabularDataset.splits(path='Greek/', \n",
    "                                            format='csv', \n",
    "                                            train='TrainFilegreek.csv', \n",
    "                                            validation='TestFilegreek.csv',\n",
    "                                            fields=train_val_fields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5WzoFOL1FzS"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_val_fields = [\n",
    "    ('id', None), # we dont need this, so no processing\n",
    "    ('tweet', TEXT), # process it as label\n",
    "    ('y_predicted', LABEL) # we dont need this, so no processing\n",
    "]\n",
    "predict_data = data.TabularDataset(path='Greek/PredictFilegreek.csv', format='csv', skip_header=True,fields=test_val_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "SBYyyNyFscJ7",
    "outputId": "143e8625-0cb7-4125-bf32-a2c229c62921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6995\n",
      "Number of validation examples: 1749\n",
      "Number of prediction examples: 1544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of prediction examples: {len(predict_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YuIRlHjTscKC",
    "outputId": "bf92d424-3812-4852-e7d9-014f00f3bc8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': [466, 97317, 33617, 31796, 13140, 70887, 43202, 31821, 483, 29223, 14669, 35670, 45878, 27393, 465, 24767, 469, 17198, 30645, 64472, 27621, 22013, 70279, 53166, 487, 13140, 63444, 61399, 61399, 22013, 70279, 53166, 168, 28174, 12961, 38278], 'subtask_a': 'NOT'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "n2YLmUNGscKI",
    "outputId": "be5e459a-d543-4f67-f491-39314bf8bfd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['β', '##γη', '##κε', 'αν', '##α', '##κο', '##ιν', '##ωση', 'σ', '##π', '##υ', '##ρι', '##δου', '##λα', 'α', '##κα', 'ε', '##λ', '##λη', '##νι', '##δα', 'master', '##chef', '##gr', 'χ', '##α', '##χ', '##χα', '##χα', 'master', '##chef', '##gr', '_', 'xe', '##ft', '##iles']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['tweet'])\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9lW7T9oscKP"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NUxtDneZscKU",
    "outputId": "24435eda-04e0-4afd-983e-e5b148db875c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f7d23265b70>, {'NOT': 0, 'OFF': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0bCJlCrscKb"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPtyTx08UCum"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prediction_iterator = data.BucketIterator(\n",
    "    predict_data,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7sdPGVtscKg"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wg5pniU7duZA"
   },
   "outputs": [],
   "source": [
    "config1=BertConfig.from_pretrained('bert-base-multilingual-cased',output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kT5N2vZRgpyr"
   },
   "outputs": [],
   "source": [
    "bert =BertModel.from_pretrained('bert-base-multilingual-cased',config=config1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LS8KPV7WscKl"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertConfig\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        xmask=[]\n",
    "        #text = [batch size, sent len]\n",
    "        for b in text:\n",
    "            attention_mask = [int(i > 0) for i in b] \n",
    "            att=torch.tensor(attention_mask)\n",
    "            xmask.append(att)\n",
    "\n",
    "        x_att_mask_pytorch=torch.stack(xmask).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedded= self.bert(text,attention_mask=x_att_mask_pytorch)[0]\n",
    "        packed_output, (hidden, cell) = self.rnn(embedded)\n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "               \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "         \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEIqrIG8scKq"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sbyI1h18scKy",
    "outputId": "0aae619b-2ed1-4f23-c84b-7d4e6358e57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 189,405,185 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkYmbhy9scK3"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kJIl5tYVscK8",
    "outputId": "ac09c8be-e52a-47d1-b3a6-63a92e864492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,551,745 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "c2QcdD9uscLB",
    "outputId": "1ec34c84-30ab-4c76-a1b6-c251872a4f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HCgrge6scLH"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVXs0n9UscLJ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxgQxlJXscLO"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "i8VBV6PHHA7d",
    "outputId": "d1812419-a362-4a50-d582-bd1505182bb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTGRUSentiment(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 512, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  (out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 234,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEU_NUOOscLS"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quYVUygE2u4v"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def binary_accuracy2(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    #print(\"Predicted\",rounded_preds)\n",
    "    #print(\"labelsFlattend\",y)\n",
    "    return f1_score(y.detach().cpu().numpy(), rounded_preds.detach().cpu().numpy(), average='macro'),acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39Nqb8YHtKp1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjVM0U8kscLW"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        #print(batch)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.tweet).squeeze(1)\n",
    "        #print(predictions.dtype)\n",
    "            \n",
    "        loss = criterion(predictions, batch.subtask_a)\n",
    "        #print( batch.subtask_a.dtype)\n",
    "            \n",
    "        acc = binary_accuracy(predictions, batch.subtask_a)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_lToD-qgMvv"
   },
   "outputs": [],
   "source": [
    "kmax=0\n",
    "ktemp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uhjbtc1cscLY"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    kmax=0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    nb_eval_steps=0\n",
    "    eval_acc=0\n",
    "    eval_f1=0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.tweet).squeeze(1)\n",
    "            loss = criterion(predictions, batch.subtask_a)\n",
    "            tmpf1score,acc = binary_accuracy2(predictions, batch.subtask_a)\n",
    "            eval_f1 = eval_f1+tmpf1score\n",
    "            eval_acc=eval_acc+acc\n",
    "            nb_eval_steps += 1\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    ktemp=eval_f1/nb_eval_steps\n",
    "    #if ktemp>kmax:\n",
    "    #  kmax=ktemp\n",
    "    #  print(\"SAVING MODEL for F1 score of \",ktemp )\n",
    "    #  torch.save({'state_dict': model.state_dict()},'/content/drive/My Drive/GreekData/bertlstmoriginal.pth.tar')\n",
    "    f1=eval_f1/nb_eval_steps\n",
    "    print(\"  F1 score: {0:.3f}\".format(f1))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YajpYfx2L-48"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "97GqDDBKpOa-",
    "outputId": "13424e64-b3ba-488c-cb76-80a265418aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1 score: 0.565\n",
      "  Accuracy score: 0.754\n",
      "SAVING MODEL after \n",
      "Epoch Number  0\n",
      "Epoch: 01 | Epoch Time: 1m 19s\n",
      "\tTrain Loss: 0.563 | Train Acc: 72.08%\n",
      "\t Val. Loss: 0.518 |  Val. Acc: 75.45%\n",
      "  F1 score: 0.584\n",
      "  Accuracy score: 0.757\n",
      "SAVING MODEL after \n",
      "Epoch Number  1\n",
      "Epoch: 02 | Epoch Time: 1m 19s\n",
      "\tTrain Loss: 0.540 | Train Acc: 74.08%\n",
      "\t Val. Loss: 0.514 |  Val. Acc: 75.73%\n",
      "  F1 score: 0.671\n",
      "  Accuracy score: 0.763\n",
      "SAVING MODEL after \n",
      "Epoch Number  2\n",
      "Epoch: 03 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.524 | Train Acc: 74.88%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 76.27%\n",
      "  F1 score: 0.702\n",
      "  Accuracy score: 0.803\n",
      "SAVING MODEL after \n",
      "Epoch Number  3\n",
      "Epoch: 04 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.514 | Train Acc: 75.89%\n",
      "\t Val. Loss: 0.460 |  Val. Acc: 80.31%\n",
      "  F1 score: 0.721\n",
      "  Accuracy score: 0.806\n",
      "SAVING MODEL after \n",
      "Epoch Number  4\n",
      "Epoch: 05 | Epoch Time: 1m 19s\n",
      "\tTrain Loss: 0.484 | Train Acc: 77.56%\n",
      "\t Val. Loss: 0.450 |  Val. Acc: 80.59%\n",
      "  F1 score: 0.730\n",
      "  Accuracy score: 0.822\n",
      "SAVING MODEL after \n",
      "Epoch Number  5\n",
      "Epoch: 06 | Epoch Time: 1m 19s\n",
      "\tTrain Loss: 0.473 | Train Acc: 78.99%\n",
      "\t Val. Loss: 0.428 |  Val. Acc: 82.24%\n",
      "  F1 score: 0.740\n",
      "  Accuracy score: 0.828\n",
      "SAVING MODEL after \n",
      "Epoch Number  6\n",
      "Epoch: 07 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.451 | Train Acc: 80.61%\n",
      "\t Val. Loss: 0.421 |  Val. Acc: 82.75%\n",
      "  F1 score: 0.752\n",
      "  Accuracy score: 0.833\n",
      "SAVING MODEL after \n",
      "Epoch Number  7\n",
      "Epoch: 08 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.437 | Train Acc: 81.37%\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 83.32%\n",
      "  F1 score: 0.745\n",
      "  Accuracy score: 0.838\n",
      "Epoch: 09 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.415 | Train Acc: 82.34%\n",
      "\t Val. Loss: 0.396 |  Val. Acc: 83.78%\n",
      "  F1 score: 0.768\n",
      "  Accuracy score: 0.834\n",
      "SAVING MODEL after \n",
      "Epoch Number  9\n",
      "Epoch: 10 | Epoch Time: 1m 18s\n",
      "\tTrain Loss: 0.401 | Train Acc: 83.20%\n",
      "\t Val. Loss: 0.408 |  Val. Acc: 83.41%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_f1=0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    #print(\"STOP\")\n",
    "    valid_loss, valid_acc,f1 = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertlstmoriginal.pth.tar')\n",
    "        print(\"SAVING MODEL after \")\n",
    "        print(\"Epoch Number \",epoch)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "ArsAZzlfo5XP",
    "outputId": "62e7a1d1-6895-4064-a06c-6ae42931ea68"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-3e5149046401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mGWRGN\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mPEQRJH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mP3H\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F;GWRGN;PEQRJH[P3H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWE0TNSzpLqM"
   },
   "outputs": [],
   "source": [
    "yres=[]\n",
    "finalTid=[]\n",
    "trueLabels=[]\n",
    "predictedLabels=[]\n",
    "def predict(model, iterator):\n",
    "    kmax=0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    nb_eval_steps=0\n",
    "    eval_acc=0\n",
    "    eval_f1=0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.tweet).squeeze(1)\n",
    "            trueLabels.append((batch.y_predicted).detach().cpu().numpy())\n",
    "            #finalTid.append(batch.id)\n",
    "            \n",
    "            predictedLabels.append(torch.round(torch.sigmoid(predictions)).detach().cpu().numpy())\n",
    "            tmpf1score,acc= binary_accuracy2(predictions, batch.y_predicted)\n",
    "            eval_f1 = eval_f1+tmpf1score\n",
    "            eval_acc=eval_acc+acc\n",
    "            nb_eval_steps += 1\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    return predictedLabels,trueLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj5AqFxtgeu-"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prediction_iterator = data.BucketIterator(\n",
    "    predict_data,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-IX1LLJscL2"
   },
   "source": [
    "We'll load up the parameters that gave us the best validation loss and try these on the test set - which gives us our best results so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4KhuQl0yscL3",
    "outputId": "9fb4ca03-53a2-4756-96bb-3b79cf283898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 257,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertlstmoriginal.pth.tar')\n",
    "'''\n",
    "\n",
    "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertlstmoriginal.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "d07vDgATvYuE",
    "outputId": "94dce5ea-864a-4e42-f622-d8c74843895e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1 score: 0.797\n",
      "  Accuracy score: 0.883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictedLabels,trueLabels = predict(model, prediction_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "np9y7yR__yEK",
    "outputId": "a71d39a0-49c2-43c2-d2d5-46687f1d4594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 259,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3FT5o1R1iNu"
   },
   "outputs": [],
   "source": [
    "finalTids=tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4dGp-Qw69LJ"
   },
   "outputs": [],
   "source": [
    "ytid=tid.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZWpiN9NxCRG"
   },
   "outputs": [],
   "source": [
    "yans=[predictedLabels[i].flatten().tolist() for i in range(len(predictedLabels))]\n",
    "ytrue=[trueLabels[i].flatten().tolist() for i in range(len(trueLabels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHVhZGoCAuuF"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "yans=list(chain.from_iterable(yans))\n",
    "\n",
    "ytrue=list(chain.from_iterable(ytrue))\n",
    "\n",
    "#ytid=list(chain.from_iterable(ytid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZE3WBT_7ooh"
   },
   "outputs": [],
   "source": [
    "yans1=[round(x) for x in yans]\n",
    "ytrue1=[round(x) for x in ytrue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWpQiosL7nH2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pA3TRQI9xOpe"
   },
   "outputs": [],
   "source": [
    "yans2=[\"NOT\" if yans1[i]==0 else \"OFF\" for i in range(len(yans1))]\n",
    "ytrue2=[\"NOT\" if ytrue1[i]==0 else \"OFF\" for i in range(len(ytrue1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TLtb99R1xWXL",
    "outputId": "b9cfb2c5-f930-4bd7-8df0-34671c6088ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695\n",
      "2393\n"
     ]
    }
   ],
   "source": [
    "print(yans2.count(\"OFF\"))\n",
    "print(yans2.count(\"NOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VfOyHOenxaiD",
    "outputId": "8c5425a1-1f50-4dfb-c9f8-f61da45e5a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "2604\n"
     ]
    }
   ],
   "source": [
    "print(ytrue2.count(\"OFF\"))\n",
    "print(ytrue2.count(\"NOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "3Lk1SK7RxdU6",
    "outputId": "635426ef-2ea3-40f9-a5d7-634dea28495a"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-1014aa215dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0;34m'given'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mytrue2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     }\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2707\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
    "#print(len(z))\n",
    "C = {\n",
    "        'predicted': yans2,\n",
    "     'given':ytrue2\n",
    "    }\n",
    "df = pd.DataFrame(C)\n",
    "\n",
    "export_csv = df.to_csv ('/content/drive/My Drive/GreekData/GreekAnswerBERTLSTMOriginal.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "pJ9m-WKt2IhR",
    "outputId": "b2663308-732e-40ec-ea5e-fb4de88b2946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 409   75]\n",
      " [ 286 2318]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf=confusion_matrix(ytrue2, yans2, labels=['OFF', 'NOT'])\n",
    "print(cnf)\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cnf,['OFF', 'NOT'], ['OFF', 'NOT'])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True,fmt='.2f') # font size\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ORIGINALBERTLSTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
