{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7r2vnhYQ94V",
    "outputId": "db1bee67-c874-4d0a-87fc-65a5beff8136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8744, 3)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas\n",
    "headers=['id','tweet','subtask_a']\n",
    "data = pandas.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ht7zcsgAQ94f",
    "outputId": "27bd9286-5a57-4c27-c32b-295be5e739f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              tweet subtask_a\n",
      "1  1172  @USER Οι μουσουλμάνες που τις βιάζουν έτσι κ α...       OFF\n",
      "2  4078  Η Κάτια προσπαθεί να πείσει οτι δεν είναι ελέφ...       NOT\n",
      "3   135  Καλά γιατί λες ότι, είσαι νέος αφού γεννήθηκες...       NOT\n",
      "4  9056          Με Φατσεα ξεκινησαμε...... #Kokkinopotami       NOT\n",
      "5  5344                  #gntmgr Κάτια πόσο γλυκιά, εμετός       NOT\n"
     ]
    }
   ],
   "source": [
    "data=data[1:]\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsY-bwwzQ94m",
    "outputId": "94d54358-3efa-4f8d-9017-f303ff17b19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8743, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIjBfJzKQ94r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfnumpy=data.to_numpy();\n",
    "x=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCfBlnlnQ94x",
    "outputId": "584f88f3-317f-4547-f479-3ee0dac2472a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8743, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahXTV2g3Q942"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TfB-GpmQ948",
    "outputId": "1997bee5-de93-4d38-ec11-0efadb27acd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5857, 1)\n",
      "(8743, 1)\n",
      "(5857, 1)\n",
      "(2886, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(x.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmxYUDWgQ95H"
   },
   "outputs": [],
   "source": [
    "arrt=x[:,0]\n",
    "#TOOD\n",
    "#arrt=[lamda m: for m in arrt re.sub(r' #', 'HASHTAG', arrt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ6thw5eQ95L",
    "outputId": "db67dc63-766a-4929-e980-968011eafd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8743,)\n"
     ]
    }
   ],
   "source": [
    "print(arrt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4P7OVGSfQ95Q"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "allTokens=[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1grAqrSIQ95U"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "#LEMMATIZATION\n",
    "import spacy\n",
    "import el_core_news_sm \n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp=el_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6OKdIJaQ95Y",
    "outputId": "a777e70e-49be-4d83-e965-84c9d3497385"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-93df5f904e73>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-93df5f904e73>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    allTokens.append(x2)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def preprocess(arrt):\n",
    "    allTokens=[]\n",
    "    noises = ['URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m',\"’\"]\n",
    "    stopwords =[]\n",
    "    for txt in arrt:\n",
    "        x1=tknzr.tokenize(txt)\n",
    "        x2=list(filter(lambda t: t not in string.punctuation and t not in noises ,x1)\n",
    "        #print(x1)\n",
    "        #if len(x2)!=0:dont remove 0 list as issue in svm training\n",
    "        allTokens.append(x2)\n",
    "    return allTokens\n",
    "\n",
    "allTokens=preprocess(arrt)\n",
    "print(arrt.shape)\n",
    "print(allTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMH-veCOQ95d"
   },
   "outputs": [],
   "source": [
    "def preprocess(arrt):\n",
    "    noises = ['tweet','URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m',\"’\"]\n",
    "    allTokens =[]\n",
    "    for txt in arrt:\n",
    "        x1=tknzr.tokenize(txt)\n",
    "        x2=[]\n",
    "        for t in x1:\n",
    "            if t not in string.punctuation and t not in noises:\n",
    "                x2.append(t)\n",
    "                #x2=list(filter(lambda t: t not in string.punctuation and t not in noises ,x1)\n",
    "                \n",
    "        #if len(x2)!=0 :removed as y needs x\n",
    "        allTokens.append(list(x2))\n",
    "               \n",
    "    return allTokens\n",
    "\n",
    "allTokens=preprocess(arrt)\n",
    "print(arrt.shape)\n",
    "print(len(allTokens))\n",
    "\n",
    "print(len(allTokens[0:8744]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DlP5VKrQ95g"
   },
   "outputs": [],
   "source": [
    "#TOKENIZATION USING SPACY \n",
    "# BUT NOT TWEET TOEKNIZED\n",
    "# too time consuming\n",
    "'''\n",
    "allTokens1=[]\n",
    "for token in x:\n",
    "    x2=[]\n",
    "    t=nlp(token[0])\n",
    "    for t2 in t:\n",
    "        t1=str(t2)\n",
    "        if t1 not in string.punctuation and t1 not in noises:\n",
    "            x2.append(t2.lemma_)\n",
    "    allTokens1.append(x2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXjd5r1gQ95k"
   },
   "outputs": [],
   "source": [
    "print(allTokens[0:4])\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "es9eQuVzQ95n"
   },
   "outputs": [],
   "source": [
    "#print(allTokens1[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXfT-srHQ95t"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cY9XMSL5Q951"
   },
   "outputs": [],
   "source": [
    "tfidf.fit(allTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXEC8vASQ954"
   },
   "outputs": [],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9aWDq5_Q957"
   },
   "outputs": [],
   "source": [
    "allTokenstrain=preprocess(X_train[:,0])\n",
    "allTokenstest=preprocess(X_test[:,0])\n",
    "\n",
    "Train_X_Tfidf = tfidf.transform(allTokenstrain)\n",
    "Test_X_Tfidf = tfidf.transform(allTokenstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72uf2MafQ95_"
   },
   "outputs": [],
   "source": [
    "print(Train_X_Tfidf.shape)\n",
    "print(Test_X_Tfidf.shape)\n",
    "print(len(allTokenstrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmjUxjLUQ96D"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#y_train1[y_train==\"OFF\" ] = 1 \n",
    "#y_train1[y_train==\"NOT\"]=0\n",
    "\n",
    "#y_test[y_test==\"OFF\" ] = 1 \n",
    "#y_test[y_test==\"NOT\"]=0\n",
    "#Y_train=y_train.flatten()\n",
    "#Y_test=y_test.flatten()\n",
    "#print(Train_X_Tfidf.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(Train_X_Tfidf.shape)\n",
    "yTrain=le.fit_transform(y_train.flatten())\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "yTest=le.fit_transform(y_test.flatten())\n",
    "\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKymidc_Sh7A"
   },
   "outputs": [],
   "source": [
    "#checking SVM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7KJCV46Q96G"
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "SVM = SVC(class_weight='balanced')\n",
    "SVM=GridSearchCV(SVM,parameters)\n",
    "SVM.fit(Train_X_Tfidf,yTrain)\n",
    "SVM=SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t91VTK77Q96K"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"SVM f1 score -> \",f1_score(predictions_SVM, yTest))\n",
    "print(\"SVM accuracy score\",accuracy_score(predictions_SVM,yTest )*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WX1mo6jgSH3Z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKmjJdlnSKoK"
   },
   "outputs": [],
   "source": [
    "#checking random forest classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZ1v0QdyQ96R"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier = RandomForestClassifier(max_depth=800, min_samples_split=5)\n",
    "params = {'n_estimators': [n for n in range(50,200,50)], 'criterion':['gini','entropy'], }\n",
    "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
    "classifier.fit(Train_X_Tfidf,yTrain)\n",
    "classifier = classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnfeGoqXQ96W"
   },
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Random Forest f1 score -> \",f1_score(test_predictions, yTest))\n",
    "print(\"Random Forest score>\",accuracy_score(test_predictions,yTest )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTjUqtKDQ96b"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.7)\n",
    "classifier.fit(Train_X_Tfidf,yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQAcIfkFQ96e"
   },
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Naive Bayes f1 score -> \",f1_score(test_predictions, yTest))\n",
    "print(\"Naive Bayes score>\",accuracy_score(test_predictions,yTest )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNRDwT9sQ96h"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clflr = LogisticRegression(multi_class='auto', solver='newton-cg',class_weight = 'balanced')\n",
    "classifier = GridSearchCV(classifier, {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}, cv=3, n_jobs=4)\n",
    "classifier.fit(Train_X_Tfidf,yTrain)\n",
    "classifier = classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AD3QLOFqQ96l"
   },
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"Logistic Regression f1 score -> \",f1_score(test_predictions, yTest))\n",
    "print(\"Logistic Regression score>\",accuracy_score(test_predictions,yTest )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYofW7BeQ96q"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_jobs=4)\n",
    "params = {'n_neighbors': [3,5,7,9], 'weights':['uniform', 'distance']}\n",
    "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
    "classifier.fit(Train_X_Tfidf,yTrain)\n",
    "classifier = classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dk5yeMWrQ96s"
   },
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"K nearest Neighbours f1 score -> \",f1_score(test_predictions, yTest))\n",
    "print(\"K nearest Neighbours score>\",accuracy_score(test_predictions,yTest )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhNqwJXnQ96v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Greekclassical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
