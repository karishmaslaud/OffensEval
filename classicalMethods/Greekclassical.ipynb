{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Greekclassical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7r2vnhYQ94V",
        "colab_type": "code",
        "colab": {},
        "outputId": "db1bee67-c874-4d0a-87fc-65a5beff8136"
      },
      "source": [
        "import csv\n",
        "import pandas\n",
        "headers=['id','tweet','subtask_a']\n",
        "data = pandas.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8744, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht7zcsgAQ94f",
        "colab_type": "code",
        "colab": {},
        "outputId": "27bd9286-5a57-4c27-c32b-295be5e739f5"
      },
      "source": [
        "data=data[1:]\n",
        "print(data.head())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id                                              tweet subtask_a\n",
            "1  1172  @USER Οι μουσουλμάνες που τις βιάζουν έτσι κ α...       OFF\n",
            "2  4078  Η Κάτια προσπαθεί να πείσει οτι δεν είναι ελέφ...       NOT\n",
            "3   135  Καλά γιατί λες ότι, είσαι νέος αφού γεννήθηκες...       NOT\n",
            "4  9056          Με Φατσεα ξεκινησαμε...... #Kokkinopotami       NOT\n",
            "5  5344                  #gntmgr Κάτια πόσο γλυκιά, εμετός       NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsY-bwwzQ94m",
        "colab_type": "code",
        "colab": {},
        "outputId": "94d54358-3efa-4f8d-9017-f303ff17b19c"
      },
      "source": [
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8743, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIjBfJzKQ94r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#https://towardsdatascience.com/linear-regression-in-6-lines-of-python-5e1d0cd05b8d\n",
        "#https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array\n",
        "dfnumpy=data.to_numpy();\n",
        "x=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y=dfnumpy[:, 2].reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCfBlnlnQ94x",
        "colab_type": "code",
        "colab": {},
        "outputId": "584f88f3-317f-4547-f479-3ee0dac2472a"
      },
      "source": [
        "print(y.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8743, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahXTV2g3Q942",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TfB-GpmQ948",
        "colab_type": "code",
        "colab": {},
        "outputId": "1997bee5-de93-4d38-ec11-0efadb27acd9"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(x.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5857, 1)\n",
            "(8743, 1)\n",
            "(5857, 1)\n",
            "(2886, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmxYUDWgQ95H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrt=x[:,0]\n",
        "#TOOD\n",
        "#arrt=[lamda m: for m in arrt re.sub(r' #', 'HASHTAG', arrt)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ6thw5eQ95L",
        "colab_type": "code",
        "colab": {},
        "outputId": "db67dc63-766a-4929-e980-968011eafd06"
      },
      "source": [
        "print(arrt.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8743,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P7OVGSfQ95Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "allTokens=[];"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1grAqrSIQ95U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "\n",
        "#LEMMATIZATION\n",
        "import spacy\n",
        "import el_core_news_sm \n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "nlp=el_core_news_sm.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6OKdIJaQ95Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "a777e70e-49be-4d83-e965-84c9d3497385"
      },
      "source": [
        "def preprocess(arrt):\n",
        "    allTokens=[]\n",
        "    noises = ['URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m',\"’\"]\n",
        "    stopwords =[]\n",
        "    for txt in arrt:\n",
        "        x1=tknzr.tokenize(txt)\n",
        "        x2=list(filter(lambda t: t not in string.punctuation and t not in noises ,x1)\n",
        "        #print(x1)\n",
        "        #if len(x2)!=0:dont remove 0 list as issue in svm training\n",
        "        allTokens.append(x2)\n",
        "    return allTokens\n",
        "\n",
        "allTokens=preprocess(arrt)\n",
        "print(arrt.shape)\n",
        "print(allTokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-13-93df5f904e73>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-93df5f904e73>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    allTokens.append(x2)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMH-veCOQ95d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(arrt):\n",
        "    noises = ['tweet','URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m',\"’\"]\n",
        "    allTokens =[]\n",
        "    for txt in arrt:\n",
        "        x1=tknzr.tokenize(txt)\n",
        "        x2=[]\n",
        "        for t in x1:\n",
        "            if t not in string.punctuation and t not in noises:\n",
        "                x2.append(t)\n",
        "                #x2=list(filter(lambda t: t not in string.punctuation and t not in noises ,x1)\n",
        "                \n",
        "        #if len(x2)!=0 :removed as y needs x\n",
        "        allTokens.append(list(x2))\n",
        "               \n",
        "    return allTokens\n",
        "\n",
        "allTokens=preprocess(arrt)\n",
        "print(arrt.shape)\n",
        "print(len(allTokens))\n",
        "\n",
        "print(len(allTokens[0:8744]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DlP5VKrQ95g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TOKENIZATION USING SPACY \n",
        "# BUT NOT TWEET TOEKNIZED\n",
        "# too time consuming\n",
        "'''\n",
        "allTokens1=[]\n",
        "for token in x:\n",
        "    x2=[]\n",
        "    t=nlp(token[0])\n",
        "    for t2 in t:\n",
        "        t1=str(t2)\n",
        "        if t1 not in string.punctuation and t1 not in noises:\n",
        "            x2.append(t2.lemma_)\n",
        "    allTokens1.append(x2)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXjd5r1gQ95k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(allTokens[0:4])\n",
        "print(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es9eQuVzQ95n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(allTokens1[0:4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXfT-srHQ95t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY9XMSL5Q951",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf.fit(allTokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXEC8vASQ954",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9aWDq5_Q957",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allTokenstrain=preprocess(X_train[:,0])\n",
        "allTokenstest=preprocess(X_test[:,0])\n",
        "\n",
        "Train_X_Tfidf = tfidf.transform(allTokenstrain)\n",
        "Test_X_Tfidf = tfidf.transform(allTokenstest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72uf2MafQ95_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(Train_X_Tfidf.shape)\n",
        "print(Test_X_Tfidf.shape)\n",
        "print(len(allTokenstrain))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmjUxjLUQ96D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "#y_train1[y_train==\"OFF\" ] = 1 \n",
        "#y_train1[y_train==\"NOT\"]=0\n",
        "\n",
        "#y_test[y_test==\"OFF\" ] = 1 \n",
        "#y_test[y_test==\"NOT\"]=0\n",
        "#Y_train=y_train.flatten()\n",
        "#Y_test=y_test.flatten()\n",
        "#print(Train_X_Tfidf.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(Train_X_Tfidf.shape)\n",
        "yTrain=le.fit_transform(y_train.flatten())\n",
        "print(yTrain.shape)\n",
        "print(le.classes_)\n",
        "yTest=le.fit_transform(y_test.flatten())\n",
        "\n",
        "print(le.classes_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKymidc_Sh7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking SVM \n",
        "#code has been inspired from \n",
        "#https://github.com/ahmedhammad97/Offensive-Language-Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7KJCV46Q96G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "SVM = SVC(class_weight='balanced')\n",
        "SVM=GridSearchCV(SVM,parameters)\n",
        "SVM.fit(Train_X_Tfidf,yTrain)\n",
        "SVM=SVM.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t91VTK77Q96K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "\n",
        "print(\"SVM f1 score -> \",f1_score(predictions_SVM, yTest))\n",
        "print(\"SVM accuracy score\",accuracy_score(predictions_SVM,yTest )*100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX1mo6jgSH3Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKmjJdlnSKoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking random forest classifier \n",
        "#code has been inspired from \n",
        "#https://github.com/ahmedhammad97/Offensive-Language-Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ1v0QdyQ96R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "classifier = RandomForestClassifier(max_depth=800, min_samples_split=5)\n",
        "params = {'n_estimators': [n for n in range(50,200,50)], 'criterion':['gini','entropy'], }\n",
        "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "classifier.fit(Train_X_Tfidf,yTrain)\n",
        "classifier = classifier.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnfeGoqXQ96W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = classifier.predict(Test_X_Tfidf)\n",
        "\n",
        "print(\"Random Forest f1 score -> \",f1_score(test_predictions, yTest))\n",
        "print(\"Random Forest score>\",accuracy_score(test_predictions,yTest )*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTjUqtKDQ96b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "classifier = MultinomialNB(alpha=0.7)\n",
        "classifier.fit(Train_X_Tfidf,yTrain)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQAcIfkFQ96e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = classifier.predict(Test_X_Tfidf)\n",
        "\n",
        "print(\"Naive Bayes f1 score -> \",f1_score(test_predictions, yTest))\n",
        "print(\"Naive Bayes score>\",accuracy_score(test_predictions,yTest )*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvuPQ9f5Sp47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking Logistic Regression \n",
        "#code has been inspired from \n",
        "#https://github.com/ahmedhammad97/Offensive-Language-Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNRDwT9sQ96h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clflr = LogisticRegression(multi_class='auto', solver='newton-cg',class_weight = 'balanced')\n",
        "classifier = GridSearchCV(classifier, {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}, cv=3, n_jobs=4)\n",
        "classifier.fit(Train_X_Tfidf,yTrain)\n",
        "classifier = classifier.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD3QLOFqQ96l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = classifier.predict(Test_X_Tfidf)\n",
        "\n",
        "print(\"Logistic Regression f1 score -> \",f1_score(test_predictions, yTest))\n",
        "print(\"Logistic Regression score>\",accuracy_score(test_predictions,yTest )*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDFi9jMAS6BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking Knearest Negihbours\n",
        "#code has been inspired from \n",
        "#https://github.com/ahmedhammad97/Offensive-Language-Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYofW7BeQ96q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_jobs=4)\n",
        "params = {'n_neighbors': [3,5,7,9], 'weights':['uniform', 'distance']}\n",
        "classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "classifier.fit(Train_X_Tfidf,yTrain)\n",
        "classifier = classifier.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk5yeMWrQ96s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = classifier.predict(Test_X_Tfidf)\n",
        "\n",
        "print(\"K nearest Neighbours f1 score -> \",f1_score(test_predictions, yTest))\n",
        "print(\"K nearest Neighbours score>\",accuracy_score(test_predictions,yTest )*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNqwJXnQ96v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}