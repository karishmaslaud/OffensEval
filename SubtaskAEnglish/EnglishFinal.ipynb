{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "68b745e8-a8d8-47ef-9b27-307ae34920bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "46Fpl7WYdNu0",
    "outputId": "2ca5b625-989a-4e3d-fbc2-81c6e3cf03a9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1nweMDxcWic"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "dc97db85-9567-4383-a1f2-f7e70468d51c"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  gpuname=\"\"\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  n_gpu=torch.cuda.device_count()\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "14716d6b-506e-4428-84d6-0faaae8b8ebc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0iCZDHmlWSjY",
    "outputId": "63a4c50c-e513-47d3-f7e5-82d96912cf65"
   },
   "outputs": [],
   "source": [
    "##NOT FOR SYSTEMS\n",
    "!unzip -P yourpassword -qq '/content/drive/My Drive/EnglishData/task_a_distant.zip' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#conversion to float code taken as it is from the answer https://stackoverflow.com/a/39298571 to https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ayt4_mQnr5n7"
   },
   "outputs": [],
   "source": [
    "def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "headers=['id','text','average','std']\n",
    "taska = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
    "taska=taska[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2uXSsl4DrvPa",
    "outputId": "179d7446-8df0-4953-be00-b88fa2e99860"
   },
   "outputs": [],
   "source": [
    "taska.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXDd24Fxry8c"
   },
   "outputs": [],
   "source": [
    "len(taska)\n",
    "#taska=taska[:1000000]\n",
    "#taska=taska[100000:4000000]\n",
    "#taska=taska[4000000:6000000]\n",
    "#taska=taska[6000000:]\n",
    "#taska=taska[:1000000]\n",
    "#taska=taska[1000000:1500000]\n",
    "#taska=taska[1500000:2500000]\n",
    "#taska=taska[3500000:4500000]\n",
    "taska=taska[6000000:7500000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
    "englishdata = pd.read_csv(\"olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
    "englishdata=englishdata[['id','tweet','subtask_a']]\n",
    "englishdata=englishdata[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "B9dY5nerCi3z",
    "outputId": "ea2a69c9-0166-4447-a2ef-6fd7272c0856"
   },
   "outputs": [],
   "source": [
    "englishdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn8dOMH10Cla"
   },
   "outputs": [],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "\n",
    "def giveIds(sentence):\n",
    "  maxlength=0\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "  return maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMeqzRH7LS5Q"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a40P-fEPNwSC",
    "outputId": "d6b0273a-aa1a-45f0-aab3-b24eca16dc9a"
   },
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmbrouMtLk4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def giveLabel(y):\n",
    "  i=0\n",
    "  y1=[]\n",
    "  for r in y:\n",
    "    if(y[i]>=0.5):\n",
    "      y1.append(1)\n",
    "    else:\n",
    "      y1.append(0)\n",
    "    i=i+1;\n",
    "  return y1\n",
    "\n",
    "headers=['id','text','average','std']\n",
    "\n",
    "dfnumpy=taska.to_numpy();\n",
    "x_train=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_train=dfnumpy[:, 2].reshape(-1, 1)\n",
    "y1=giveLabel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVBwzETtK9a-"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "x_test=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y_test=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_NKcxDqLOGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train,y_train=shuffle(x_train,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "_gpr92MXKnq1",
    "outputId": "ae86663d-b512-4495-fcde-526ce711aaa7"
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "7CXlx4H41X-0",
    "outputId": "0645326c-dd59-4ca6-9e9b-ea257d629b91"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "DXkHq0Q0K2Yk",
    "outputId": "9b9f24dc-3705-46a0-dc36-a58bd17002fe"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BSZGqjvlBIDa",
    "outputId": "910292f4-516c-4e98-cf09-f12ca175a08d"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_predict.shape)\n",
    "yTrain=le.fit_transform(y_train)\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "yTest=le.fit_transform(y_test.flatten())\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jMCPsKyZBK7f",
    "outputId": "b1d5205a-1427-480f-eccc-49fc7a7413fe"
   },
   "outputs": [],
   "source": [
    "set(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZbZxkgcBhfag",
    "outputId": "fa9b310f-01c7-49db-ae99-62d6ad7c2baf"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-uncased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZPr_Sj12LY-y",
    "outputId": "22ef4fb0-5135-4612-b55a-ffdf2706b617"
   },
   "outputs": [],
   "source": [
    "##ONLY FOR THE FIRST TIME SAVE ELSE LOAD\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertenglish1.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertenglish1.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDzvjKyWMio7"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQQ5__z5Mio-"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frZAYslgMipB"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSdEEzMJMipH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"Predictions Argmax\",predictionArgmax)\n",
    "  print(\"labels Flattened\",labelsFlattend)   \n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwqSDP2KL71z"
   },
   "outputs": [],
   "source": [
    "MAXLENGTH=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTurXRofNATj",
    "outputId": "49833a0e-c2a0-41fa-9a9a-91e8658a6d8c"
   },
   "outputs": [],
   "source": [
    "class EnglishTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U47_yavmOa7S"
   },
   "outputs": [],
   "source": [
    "class EnglishTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index].flatten()))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VObEL94h-bU8"
   },
   "outputs": [],
   "source": [
    "#xytrain=[x_train[:8000],y_train[:8000]]\\\n",
    "MAXLENGTH=64\n",
    "xytrain=[x_train,yTrain]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tdataset = EnglishTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjp1U9q9xaI"
   },
   "outputs": [],
   "source": [
    "\n",
    "#xytest=[x_test[:8000],y_test[:8000]]\n",
    "xytest=[x_test,yTest]\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tedataset = EnglishTestDataset(xytest) \n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
    "#trainData(tdataloader,tedataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rPrZ3_M-LZx"
   },
   "outputs": [],
   "source": [
    "epochs=2\n",
    "total_steps=len(tdataloader)*epochs\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cqmnbPGdMipR",
    "outputId": "bba42403-665b-471c-c726-74ffd27b7948"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=2\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    \n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    if device.type==\"cpu\":\n",
    "     model.to(device)\n",
    "     map_location='cpu'\n",
    "    else:\n",
    "      model.cuda()\n",
    "      map_location=lambda storage, loc: storage.cuda()\n",
    "    checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertenglish1.pth.tar',map_location=map_location)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()        \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "    \n",
    "    for batch_idx, data in enumerate(tedataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in data)            \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "           outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "    torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertenglish1.pth.tar')\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "      \n",
    "print(\"ALL DONE!!!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of FINALBERTEnglishFInalTosubmitWOPRE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
