{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codalab1Greek.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFcl1gBfU-",
        "colab_type": "code",
        "outputId": "69e13638-39c8-4fe2-e203-f9ce430b0896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#ALL INSTALLTIONS\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOBSnT8E5MEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xeyykf-V6je",
        "colab_type": "text"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "#Also based on the following tutorials\n",
        "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#Custom Data set and Data loader has been inspired from\n",
        "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3MK2sszwvbe",
        "colab_type": "code",
        "outputId": "721feb36-ca62-49db-a79e-0197382932c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cEeA5Ys-R2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpuname=\"\"\n",
        "device=\"\"\n",
        "y=\"\"\n",
        "preprocessedTweets=\"\"\n",
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaSv6PB4w1JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def initGpus1():\n",
        "  gpuname=tf.test.gpu_device_name()\n",
        "  if gpuname=='/device:GPU:0':\n",
        "    print('Found GPU at :{}'.format(gpuname))\n",
        "  else:\n",
        "    gpuname=\"\"\n",
        "  if torch.cuda.is_available():\n",
        "    device=torch.device(\"cuda\")\n",
        "    n_gpu=torch.cuda.device_count()\n",
        "    print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "  else:\n",
        "    print(\"No GPU available using only CPU instead\")\n",
        "    device=torch.device(\"cpu\")\n",
        "  return gpuname,device\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iALw8AQY7LkW",
        "colab_type": "code",
        "outputId": "7c08d3d5-0c15-47cb-efb6-d05b993533a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y80umnMLpR94",
        "colab_type": "code",
        "outputId": "acf4faa0-d632-4dd0-e1fa-abceba9498ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.tensor(2251).flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2251])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF7yUpej6ucO",
        "colab_type": "code",
        "outputId": "1e106b78-63a2-46b8-a175-b449dee3a885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/PredictFile.zip'\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/starting_k.zip'\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/offenseval2020-test-greek.zip'\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/Greek.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace PredictFile.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace task_a_baseline.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace readme-testsetA-v1.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace testset_taska.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Greek/offenseval-greek-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Greek/readme-trainingset-greek.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6-MHzMsBN0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLOJALxBqE4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ygiven=[]\n",
        "ypredicted=[]\n",
        "\n",
        "def convertToInt(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.int64(val)\n",
        "    except:        \n",
        "        return np.int64(0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8snG4esSjUF",
        "colab_type": "code",
        "outputId": "59f45de5-62e2-49ac-8d4e-8cc42d8e70f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "headers=['id','ypredicted']\n",
        "greekdataBaseline = pd.read_csv(\"task_a_baseline.csv\", delimiter=',',names=headers)\n",
        "#,converters={\"id\":convertToInt}       \n",
        "greekdataBaseline.iloc[0]                    \n",
        "print(greekdataBaseline.dtypes)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id             int64\n",
            "ypredicted    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdZ9YnVZHpSH",
        "colab_type": "code",
        "outputId": "c4d6d3d7-9444-4dab-dc4c-dca8e8fc322f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install tweet-preprocessor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3FxBjQrYHcb",
        "colab_type": "code",
        "outputId": "7b7e7495-2352-4296-a682-52e52c5016a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install emoji --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cbbpSiNHrJF",
        "colab_type": "code",
        "outputId": "c06df82e-58e5-4faf-e500-944b5d917fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"el_core_news_md\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('el_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK5_cgNCHr5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LEMMATIZATION\n",
        "import string\n",
        "import spacy\n",
        "#import el_core_news_sm \n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "import preprocessor as p2\n",
        "import emoji\n",
        "\n",
        "nlp =  spacy.load('el_core_news_md')\n",
        "#Preprocessing # to HASHTAG so that spacy can tokenize it properly\n",
        "p=re.compile(r\"(#)\",re.UNICODE)\n",
        "p1=re.compile(r\"\\.*\",re.UNICODE)\n",
        "##tokenization with NLTK and SPACY DIDNT WORK TOGETHER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgOyD-x_GyzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "          \n",
        "def preprocess1(arrt):\n",
        "    doc=[]\n",
        "    emojis={}\n",
        "    #noises = ['@USER','n\\'t', '\\'s', '\\'m',\"’\"]\n",
        "    allTokens =[]\n",
        "\n",
        "    for txt in arrt:\n",
        "        k=0\n",
        "        sentVect=[]\n",
        "        txt1=emoji.demojize(txt)\n",
        "        x1=nlp(txt1)\n",
        "        x2=[]\n",
        "        for t in x1:\n",
        "            z=str(t)\n",
        "            if z not in string.punctuation  and t.is_stop==False:\n",
        "                x2.append(z)\n",
        "                   \n",
        "        \n",
        "        sentence=' '.join((x2))         \n",
        "        allTokens.append(sentence)      \n",
        "    return allTokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RUoX4ag7a5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Use blob\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "def readData1():\n",
        "  headers=['id','ypredicted']\n",
        "  greekdataBaseline = pd.read_csv(\"task_a_baseline.csv\", delimiter=',',names=headers)\n",
        "  #,converters={\"id\":convertToInt}       \n",
        "  greekdataBaseline.id = greekdataBaseline.id.astype(int)\n",
        "  #greekdataBaseline=greekdataBaseline[1:]\n",
        "  print(greekdataBaseline.dtypes)\n",
        "  headers=['id','tweet']\n",
        "  greekDataTest = pd.read_csv(\"testset_taska.tsv\", delimiter='\\t',names=headers,\n",
        "                                converters={\"id\":convertToInt})\n",
        "  #greekDataTest=greekDataTest[1:]\n",
        "  print(greekDataTest.head())\n",
        "  print(greekDataTest.dtypes)\n",
        "  print(greekDataTest.shape)\n",
        "  result = pd.merge(greekDataTest, greekdataBaseline, on='id', how='inner')\n",
        "  print(result.head())\n",
        "  print(result.dtypes)\n",
        "  print(result.shape)\n",
        "\n",
        "  #result=\n",
        "  #result.sort_values(by=['id'], inplace=True)\n",
        "  print(result.head())\n",
        "  dfnumpy=result.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
        "  print(tid)\n",
        "  arrt=X[:,0]\n",
        "  allTokens=preprocess1(arrt)\n",
        "  preprocessedTweets=allTokens\n",
        "  return preprocessedTweets,y,tid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8YHxvD7SbCn",
        "colab_type": "code",
        "outputId": "41d32a83-3e48-4b94-c34a-d9ae4b4cdd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(preprocessedTweets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfE9PV0Vu08q",
        "colab_type": "code",
        "outputId": "a57b81df-5b41-4ca1-9a21-66af1cd8286c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "preprocessedTweets,y,tid=readData1()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id             int64\n",
            "ypredicted    object\n",
            "dtype: object\n",
            "     id                                              tweet\n",
            "0     0                                              tweet\n",
            "1  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...\n",
            "2  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...\n",
            "3  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...\n",
            "4  8949                   κατω τα χερια απο τον #κυρανακης\n",
            "id        int64\n",
            "tweet    object\n",
            "dtype: object\n",
            "(1545, 2)\n",
            "     id                                              tweet ypredicted\n",
            "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
            "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
            "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
            "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
            "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n",
            "id             int64\n",
            "tweet         object\n",
            "ypredicted    object\n",
            "dtype: object\n",
            "(1544, 3)\n",
            "     id                                              tweet ypredicted\n",
            "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
            "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
            "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
            "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
            "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n",
            "[[2707]\n",
            " [2251]\n",
            " [9814]\n",
            " ...\n",
            " [2679]\n",
            " [3801]\n",
            " [3868]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKg4VmbQSaAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzKVbjg9ST1_",
        "colab_type": "code",
        "outputId": "a7d60a14-95ad-4f4f-9af8-64c4721dd406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuLzvJ4msRLX",
        "colab_type": "code",
        "outputId": "63fd971c-dac6-4b0f-899c-c6ff9570d4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y.flatten().tolist(),tid"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  'OFF',\n",
              "  'NOT',\n",
              "  'NOT',\n",
              "  ...],\n",
              " array([[2707],\n",
              "        [2251],\n",
              "        [9814],\n",
              "        ...,\n",
              "        [2679],\n",
              "        [3801],\n",
              "        [3868]], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAPtgGcYVDjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekPredictDataset(Dataset):\n",
        "    def __init__(self,xypredict):\n",
        "        self.xypredict = xypredict\n",
        "        self.maxlength=128\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
        "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
        "        tid_predict_pytorch=torch.tensor(self.xypredict[2][index])\n",
        "        \n",
        "        return x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch,tid_predict_pytorch\n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.xypredict[0])\n",
        " \n",
        " \n",
        " \n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fF2D1hIsObn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ZLONeR9I4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZsgnMAssDmy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYZP78bKr4Sa",
        "colab_type": "code",
        "outputId": "940bef57-0728-4660-d5f0-1bfa5d2875fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device==\"cpu\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqN01x9LqjLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#xpredict,xpredictmask=giveIds(preprocessedTweets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6_3fz3pruOD",
        "colab_type": "code",
        "outputId": "fd713a57-ae82-477e-da85-3a2475161a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ids_of_sentence_words\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv0Z1IwUyNGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  yres.append(predictionArgmax.flatten())\n",
        "  print(\"predictionArgmax\",predictionArgmax)\n",
        "  print(\"labelsFlattend\",labelsFlattend)\n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFA8ZOCI1HIw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfGhfzZ2bXtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JabVn1MiAzH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PWVtOQCOTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CuUWCG2Ezvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3Gp5gPddxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yres=[]\n",
        "finalTid=[]\n",
        "def predictingData(pTweets,ypred,tid):\n",
        "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
        "  ids_of_sentence=[]\n",
        "  predictedLabels,trueLabels=[],[]\n",
        "  \n",
        "  le = preprocessing.LabelEncoder()\n",
        "  ypredict=le.fit_transform(ypred.flatten())\n",
        "  map_location=\"\"\n",
        "  xypredict=[pTweets,ypredict,tid.flatten()]\n",
        "  \n",
        "  tdataset = GreekPredictDataset(xypredict)\n",
        "  tsampler=RandomSampler(tdataset)\n",
        "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "  print(device.type)\n",
        "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "  if device.type==\"cpu\":\n",
        "    model.to(device)\n",
        "    map_location='cpu'\n",
        "  else:\n",
        "    model.cuda()\n",
        "    map_location=lambda storage, loc: storage.cuda()\n",
        "  params=list(model.named_parameters())\n",
        "  eval_f1=0\n",
        "  eval_acc=0\n",
        "  nb_eval_steps=0\n",
        "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar',map_location=map_location)\n",
        "  print(\"Hello\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  model.eval()\n",
        "  i=0\n",
        "  for batch in predictdataloader:\n",
        "      print(i)\n",
        "      i=i+1\n",
        "      batch = tuple(t.to(device) for t in batch)        \n",
        "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2],\"tids\":batch[3]}\n",
        "      \n",
        "      with torch.no_grad():       \n",
        "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "      predictedLabels.append(logits)\n",
        "      trueLabels.append(label_ids)\n",
        "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
        "      finalTid.append(tidl)\n",
        "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "      eval_f1 = eval_f1+tmpf1score\n",
        "      eval_acc=eval_acc+tmpaccscore\n",
        "      nb_eval_steps += 1\n",
        "      \n",
        "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "  return predictedLabels,trueLabels,finalTid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4_io1hTVQfS",
        "colab_type": "code",
        "outputId": "54dc46c2-8d4d-4f11-9e1c-2f61d5f06d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "gpuname,device=initGpus1()  \n",
        "preprocessedTweets,y,tid=readData1()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available using only CPU instead\n",
            "id             int64\n",
            "ypredicted    object\n",
            "dtype: object\n",
            "     id                                              tweet\n",
            "0     0                                              tweet\n",
            "1  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...\n",
            "2  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...\n",
            "3  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...\n",
            "4  8949                   κατω τα χερια απο τον #κυρανακης\n",
            "id        int64\n",
            "tweet    object\n",
            "dtype: object\n",
            "(1545, 2)\n",
            "     id                                              tweet ypredicted\n",
            "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
            "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
            "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
            "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
            "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n",
            "id             int64\n",
            "tweet         object\n",
            "ypredicted    object\n",
            "dtype: object\n",
            "(1544, 3)\n",
            "     id                                              tweet ypredicted\n",
            "0  2707  @USER Θέλω να των δω από εδώ και εμπρός αν δεν...        NOT\n",
            "1  2251  #survivorgr Α Και 60 φορές και με διαφορετικού...        NOT\n",
            "2  9814  Και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...        NOT\n",
            "3  8949                   κατω τα χερια απο τον #κυρανακης        NOT\n",
            "4  6913  @USER μην μας το παιζεις πονοψυχη,κρυφορατσιστ...        NOT\n",
            "[[2707]\n",
            " [2251]\n",
            " [9814]\n",
            " ...\n",
            " [2679]\n",
            " [3801]\n",
            " [3868]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxsiW800L5FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhOXHNfM9QA4",
        "colab_type": "code",
        "outputId": "642b1a21-a03a-455e-92a5-302c681d3e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictedLabels,trueLabels,finalTid=predictingData(preprocessedTweets,y,tid)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Hello\n",
            "0\n",
            "predictionArgmax [0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "1\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "2\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "3\n",
            "predictionArgmax [0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1]\n",
            "labelsFlattend [0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "4\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "5\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
            "6\n",
            "predictionArgmax [0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "7\n",
            "predictionArgmax [0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
            "8\n",
            "predictionArgmax [0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "9\n",
            "predictionArgmax [0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "10\n",
            "predictionArgmax [1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "11\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
            "12\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
            "13\n",
            "predictionArgmax [1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "14\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "15\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1]\n",
            "16\n",
            "predictionArgmax [0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "17\n",
            "predictionArgmax [0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1]\n",
            "labelsFlattend [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
            "18\n",
            "predictionArgmax [0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "19\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            "20\n",
            "predictionArgmax [1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "21\n",
            "predictionArgmax [0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0]\n",
            "22\n",
            "predictionArgmax [0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "23\n",
            "predictionArgmax [1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0]\n",
            "24\n",
            "predictionArgmax [0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "25\n",
            "predictionArgmax [0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "26\n",
            "predictionArgmax [0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            "27\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "28\n",
            "predictionArgmax [0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "29\n",
            "predictionArgmax [1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "30\n",
            "predictionArgmax [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "31\n",
            "predictionArgmax [0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "32\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0]\n",
            "33\n",
            "predictionArgmax [1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "34\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
            "35\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "36\n",
            "predictionArgmax [0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0]\n",
            "labelsFlattend [0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
            "37\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "38\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
            "39\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "40\n",
            "predictionArgmax [0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "41\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "42\n",
            "predictionArgmax [0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0]\n",
            "43\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "44\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "45\n",
            "predictionArgmax [0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "46\n",
            "predictionArgmax [1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0]\n",
            "labelsFlattend [1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "47\n",
            "predictionArgmax [0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0]\n",
            "48\n",
            "predictionArgmax [0 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0]\n",
            "  F1 score: 0.792\n",
            "  Accuracy score: 0.868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCzkkNBCHOD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
        "ytrue=[trueLabels[i].flatten().tolist() for i in range(len(trueLabels))]\n",
        "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmKzCBIKKxSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "yans=list(chain.from_iterable(yans))\n",
        "\n",
        "ytrue=list(chain.from_iterable(ytrue))\n",
        "\n",
        "ytid=list(chain.from_iterable(ytid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf1PIY9GX1jn",
        "colab_type": "code",
        "outputId": "c17a85ae-3128-4704-f3cf-6d45cb24f754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(yans)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBpyaj-qR6O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans1=[\"NOT\" if yans[i]==0 else \"OFF\" for i in range(len(yans))]\n",
        "ytrue1=[\"NOT\" if ytrue[i]==0 else \"OFF\" for i in range(len(ytrue))]\n",
        "ytid1=[\"NOT\" if ytid[i]==0 else \"OFF\" for i in range(len(ytid))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mElmcTp4Ra4I",
        "colab_type": "code",
        "outputId": "f39678e5-c8af-478e-e5b9-691624458d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "2707 in ytid"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7QU2mfXwtS",
        "colab_type": "code",
        "outputId": "4f7e9f0d-fcc7-4880-aafa-2afb941d1f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(yans1.count(\"OFF\"))\n",
        "print(yans1.count(\"NOT\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "417\n",
            "1127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4njKKBAB2iY",
        "colab_type": "code",
        "outputId": "0ddffbaa-a47f-4ccd-d267-1ae7cc643f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(ytrue1.count(\"OFF\"))\n",
        "print(ytrue1.count(\"NOT\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "242\n",
            "1302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QqLKnX38zqX",
        "colab_type": "code",
        "outputId": "610f1de7-3fff-45c8-8c56-fc60434fa603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
        "#print(len(z))\n",
        "C = {'id': ytid,\n",
        "        'predicted': yans1,\n",
        "     'given':ytrue1\n",
        "    }\n",
        "df = pd.DataFrame(C)\n",
        "print (df[df['id'] == 2707] )\n",
        "\n",
        "export_csv = df.to_csv ('/content/drive/My Drive/GreekData/Answer.csv', index = None, header=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id predicted given\n",
            "4  2707       NOT   NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhVk6f6y8jbZ",
        "colab_type": "code",
        "outputId": "89ecad6c-85ac-4825-9089-aaa68f5a20dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "predictionArgmax=np.argmax(predictedLabels,axis=1).flatten()\n",
        "labelsFlattend=labels.flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f2a2c737ba15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictionArgmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictedLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabelsFlattend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \"\"\"\n\u001b[0;32m-> 1153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NKLFr52PRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k12mW9ezUUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z=[tids.flatten(),predictedLabels,trueLabels,x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBxBKJFVaFjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main():\n",
        "  gpuname,device=initGpus1()  \n",
        "  preprocessedTweets,y,tid=readData1()\n",
        "  predictedLabels,trueLabels=predictingData(preprocessedTweets,y)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey3iQErEVmuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}