{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTCodalabestingAndTrainGreekFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0-z91UlfiRk",
        "colab_type": "code",
        "outputId": "67358d0a-44d1-499a-8158-ed89872f9cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "#all imports\n",
        "import tensorflow as tf\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsZ4bSdhBEP",
        "colab_type": "code",
        "outputId": "7378e41d-b8d6-41ea-eb49-d674cbe35c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "gpuname=tf.test.gpu_device_name()\n",
        "if gpuname=='/device:GPU:0':\n",
        "  print('Found GPU at :{}'.format(gpuname))\n",
        "else:\n",
        "  raise(SystemError('GPU device not found'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at :/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3ZtD-zg4k1",
        "colab_type": "code",
        "outputId": "fabe35fd-188f-458d-85f4-011e717fa95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
        "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available using only CPU instead\")\n",
        "  device=torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU DEVICES available \n",
            "The device name is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buldkQJQiKYI",
        "colab_type": "code",
        "outputId": "addde389-c32f-4816-c975-c62965c920a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKdaEMufiiAu",
        "colab_type": "code",
        "outputId": "46b6c5eb-8d3c-49fa-9fe9-e6b3a6137530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_byFfpTf1D9",
        "colab_type": "text"
      },
      "source": [
        "#Custom Data set and Data loader has been inspired from \n",
        "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZDHmlWSjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c75be55b-2c04-4e81-ef48-8bd6d0f64024"
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/GreekData/Greek.zip'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace Greek/offenseval-greek-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Greek/readme-trainingset-greek.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr20Wv8gpF9w",
        "colab_type": "code",
        "outputId": "76deb494-d47b-41b2-dbaf-05dde6a7ed49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Hello\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cx_z-bmJsVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHoGZVoSCPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAFIEswSPcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a']\n",
        "greekdata = pd.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
        "data=greekdata[1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "406PO3ujeLdy",
        "outputId": "ffe262e3-0da8-4856-f453-edf2b1b3a57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''dataOffensive1=data[data.subtask_a==\"OFF\"]\n",
        "dataNOTOffensive=data[data.subtask_a==\"NOT\"]\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataOffensive1=data[data.subtask_a==\"OFF\"]\\ndataNOTOffensive=data[data.subtask_a==\"NOT\"]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpynLG3NYR5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataOffensive1=dataOffensive1.append(dataOffensive1, ignore_index=True)\n",
        "#dataOffensive=dataOffensive1.append(dataOffensive1.iloc[0:1000], ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHclFDnUSh9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(dataOffensive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETu9KrsbSph_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(dataNOTOffensive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLPDEHelTmgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dc110HdTtF1",
        "colab_type": "code",
        "outputId": "27195325-1c01-43af-c999-0b7bb0d9c534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnhbuYtZL0zO",
        "colab_type": "code",
        "outputId": "d371cf77-2332-4f7e-e002-6d915c4f0f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.to_numpy()[:,2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OFF', 'NOT', 'NOT', ..., 'NOT', 'NOT', 'NOT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNuys5ZaNOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dfnumpy=data.to_numpy();\n",
        "x=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y=dfnumpy[:, 2].reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoqOUnmNZO07",
        "colab_type": "code",
        "outputId": "9ffb2f2e-df13-48bd-b850-96b9868a8a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pip install tweet-preprocessor"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5y2jzz7MSlw",
        "colab_type": "code",
        "outputId": "e23dbd7a-0feb-4666-bb5d-312dc7600383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pip install emoji --upgrade"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_EeiRfIib-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U89nu4PBSSZD",
        "colab_type": "code",
        "outputId": "89e3d0af-013d-4c87-e279-4eec24e460db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"el_core_news_md\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('el_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5vGRQYdq5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LEMMATIZATION\n",
        "import string\n",
        "import spacy\n",
        "#import el_core_news_sm \n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "import preprocessor as p2\n",
        "import emoji\n",
        "\n",
        "nlp =  spacy.load('el_core_news_md')\n",
        "#Preprocessing # to HASHTAG so that spacy can tokenize it properly\n",
        "p=re.compile(r\"(#)\",re.UNICODE)\n",
        "p1=re.compile(r\"\\.*\",re.UNICODE)\n",
        "##tokenization with NLTK and SPACY DIDNT WORK TOGETHER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOEIfAgyr83C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1M-zbEcXXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "          \n",
        "def preprocess1(arrt):\n",
        "    doc=[]\n",
        "    emojis={}\n",
        "    #noises = ['@USER','n\\'t', '\\'s', '\\'m',\"’\"]\n",
        "    allTokens =[]\n",
        "\n",
        "    for txt in arrt:\n",
        "        k=0\n",
        "        sentVect=[]\n",
        "        txt1=emoji.demojize(txt)\n",
        "        x1=nlp(txt1)\n",
        "        x2=[]\n",
        "        for t in x1:\n",
        "            z=str(t)\n",
        "            if z not in string.punctuation  and t.is_stop==False:\n",
        "                x2.append(z)\n",
        "                   \n",
        "        \n",
        "        sentence=' '.join((x2))         \n",
        "        allTokens.append(sentence)      \n",
        "    return allTokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chD2GSH5dHb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arrt=x[:,0]\n",
        "allTokens=preprocess1(arrt)\n",
        "#allTokens=arrt\n",
        "#allTokenstrain, allTokenstest, y_train, y_test = train_test_split(allTokens,y, test_size=0.2, random_state=42)\n",
        "#allTokensPredict, _, y_predict, _ = train_test_split(allTokenstest,y_test, test_size=0.5, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZALP47hKO4HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X-eKHng4jUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=allTokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZLNpEq1VVUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.utils import shuffle\n",
        "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7m4cgbJLwXW",
        "colab_type": "code",
        "outputId": "4e3754a8-8e20-49c0-cf0b-be5e3a65e9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ...,\n",
              "       ['NOT'],\n",
              "       ['NOT'],\n",
              "       ['NOT']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzyloI-QNt2a",
        "colab_type": "code",
        "outputId": "a02d2b18-b556-4eb6-f005-6db8bfd54185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\n",
        "  f.write(str(x))'''\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\\n  f.write(str(x))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TImBZYl4wih",
        "colab_type": "code",
        "outputId": "b15ed995-12bd-4efe-9c61-08ef63030e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(preprocessedTweets[0:5])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['γλυκούλα φτυστοί ... υπέροχος Μπρατούλη gntmgr', 'ξαπλωμένος σκέφτομαι τραβήξω κορδόνι λαιμού τής Λίλιαν φέρουν πορτοκαλάδα GynaikaXwrisOnoma', '@USER Θεία Φιονα πόλη κούκλα χρειάζεται καν φωτογράφος σηκώνεις κινητό τραβάς δεύτερο αγαπημένο μερος πλανητη ευχαριστιεμαι μπορώ', '@USER γιατι γατος ειναι αιμοβορο πλασμα ... Ρε σιχτιρ ολους ηλιθιους ....', '@USER οσους βριζουν αναιτιως μαλωνουμε Ειδικα οσους βριζουν γυναικες']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufM4upXK2UOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSxRGBU-jXr",
        "colab_type": "code",
        "outputId": "dfe422c5-714c-4c0e-d3d1-f365f54b8847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvnzPv3Ar4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch6CWnxu5TG3",
        "colab_type": "code",
        "outputId": "e6041565-d028-41df-adad-e74268c1d0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "'''\n",
        "ids_of_sentence=[]\n",
        "maxlength=0\n",
        "for t in preprocessedTweets:\n",
        "      #token ids\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      #for t in tokenized_sentence_id:\n",
        "      #Checking max length\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      \n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "\n",
        "ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\n",
        "'''\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nids_of_sentence=[]\\nmaxlength=0\\nfor t in preprocessedTweets:\\n      #token ids\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      #for t in tokenized_sentence_id:\\n      #Checking max length\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n      \\n      ids_of_sentence.append(tokenized_sentence_id)\\n\\nids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnIbY9ING13E",
        "colab_type": "code",
        "outputId": "aa92c61b-1a25-479f-b144-5d5068cc8493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''attention_masks = []\n",
        "for inds in ids_of_sentence_words:\n",
        "    att_mask = [int(t_id > 0) for t_id in inds]  \n",
        "    attention_masks.append(att_mask)'''"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'attention_masks = []\\nfor inds in ids_of_sentence_words:\\n    att_mask = [int(t_id > 0) for t_id in inds]  \\n    attention_masks.append(att_mask)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsBprzLM6iuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s47V63nd6u1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpdgDWB7-ja",
        "colab_type": "code",
        "outputId": "8c58912d-a635-4c3b-d409-4f0ff33712fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "\n",
        "def giveIds(sentence,y_):\n",
        "  ids_of_sentence=[]\n",
        "  ids_of_sentence_words=[]\n",
        "  attention_masks=[]\n",
        "  maxlength=0\n",
        "  averageLength=0\n",
        "  allLens=[]\n",
        "  totalLen=len(sentence)\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      len1=len(tokenized_sentence_id)\n",
        "      if(maxlength<len1):\n",
        "          maxlength=len1\n",
        "          allLens.append(len1*1.0)/totalLen)\n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "  averageLength=[for s in allLens] \n",
        "  print(maxlength)\n",
        "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
        "  #print(len(attention_masks))\n",
        "  #print(len(ids_of_sentence_words))\n",
        "  return ids_of_sentence_words,attention_masks"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-5a83c8f8cb78>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    allLens.append(len1*1.0)/totalLen)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHXiPB_-jRhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yavg=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2S1fYRTXYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "MAXLENGTH=\"\"\n",
        "def giveIds(sentence,y_):\n",
        "  ids_of_sentence=[]\n",
        "  ids_of_sentence_words=[]\n",
        "  attention_masks=[]\n",
        "  maxlength=0\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "      ids_of_sentence.append(tokenized_sentence_id)\n",
        "      yavg.append(len(tokenized_sentence_id))\n",
        "  print(maxlength)\n",
        "  MAXLENGTH=maxlength\n",
        "  return MAXLENGTH,yavg\n",
        "  #ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
        "  #attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
        "  #print(len(attention_masks))\n",
        "  #print(len(ids_of_sentence_words))\n",
        "  #return ids_of_sentence_words,attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIn1L3EaG_Ts",
        "colab_type": "code",
        "outputId": "614b5ddd-13f5-4314-9f32-043915484d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#sentence_train, sentence_test, y_train, y_test= train_test_split(preprocessedTweets,y, test_size=0.1, random_state=42)\n",
        "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
        "MAXLENGTH,yavg=giveIds(preprocessedTweets,y)\n",
        "print(\"Average length is \",sum(yavg)/len(yavg))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147\n",
            "Average length is  41.29715200732014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQDZFAOzcNYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##do this at the time of training only \n",
        "sentence_train, sentence_test, y_train, y_test = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42) \n",
        "#sentence_test,sentence_predict, y_test,y_predict = train_test_split(sentence_test1,y_test1, test_size=0.5, random_state=42)\n",
        "#x_predict_mask,_,_,_=train_test_split(x_test_mask,y_test, test_size=0.5, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBt1IAUnLZYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_predict.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Z4zlYAJRCb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_qRN1yU04y",
        "colab_type": "code",
        "outputId": "00ad23cf-1689-45d2-e8c3-9f37c0fa92bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
        "#print(len(z))\n",
        "'''C = {'tweet': sentence_predict,\n",
        "        'subtask_a': y_predict.flatten(),\n",
        "    }\n",
        "df = pd.DataFrame(C, columns=['tweet', 'subtask_a'])\n",
        "export_csv = df.to_csv ('/content/drive/My Drive/GreekData/PredictFile.csv', index = None, header=True)\n",
        "print (df)\n",
        "'''\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"C = {'tweet': sentence_predict,\\n        'subtask_a': y_predict.flatten(),\\n    }\\ndf = pd.DataFrame(C, columns=['tweet', 'subtask_a'])\\nexport_csv = df.to_csv ('/content/drive/My Drive/GreekData/PredictFile.csv', index = None, header=True)\\nprint (df)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CYsPFfkdWL9",
        "colab_type": "code",
        "outputId": "43635e74-b38f-4c2e-dbf7-f7535b9283f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#print(y_predict.shape)\n",
        "yTrain=le.fit_transform(y_train.flatten())\n",
        "print(yTrain.shape)\n",
        "print(le.classes_)\n",
        "yTest=le.fit_transform(y_test.flatten())\n",
        "print(le.classes_)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6994, 1)\n",
            "(1749, 1)\n",
            "(6994,)\n",
            "['NOT' 'OFF']\n",
            "['NOT' 'OFF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFcDGmeNVbKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekTrainDataset(Dataset):\n",
        "    def __init__(self,xytrain):\n",
        "        self.xytrain = xytrain\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
        "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytrain[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MRzkZ70fqRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.utils.data import Dataset\n",
        "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekTestDataset(Dataset):\n",
        "    def __init__(self,xytest):\n",
        "        self.xytest = xytest\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
        "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytest[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt6HvS5-dpok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xytrain=[sentence_train,yTrain]\n",
        "tdataset = GreekTrainDataset(xytrain)\n",
        "tsampler=RandomSampler(tdataset)\n",
        "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGJiYjC1fb1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xytest=[sentence_test,yTest]\n",
        "tedataset = GreekTestDataset(xytest)\n",
        "tesampler=RandomSampler(tedataset)\n",
        "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5P3gOrQP_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bOBLycdL0lc",
        "colab_type": "code",
        "outputId": "889af482-38d9-4bc6-e6cb-f65daf71c34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=True)\n",
        "#for name, param in model.named_parameters():\n",
        "#\tif 'classifier' not in name: # classifier layer\n",
        "#\t\tparam.requires_grad = False\n",
        "model.cuda()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN6AiIzoQVpu",
        "colab_type": "code",
        "outputId": "253b892c-3c74-40e7-92d5-89944bf44843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False'''"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor param in model.bert.parameters():\\n    param.requires_grad = False'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyH9yvdIO208",
        "colab_type": "code",
        "outputId": "411ebdc4-a7e3-4d64-ddb5-3d2a2c3dd060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4guWRdOTS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params=list(model.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKOeqrn-jopN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "{\n",
        "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "\"weight_decay\": 0.01,\n",
        "},\n",
        "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RlThDORmMrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(optimizer_grouped_parameters,lr=2e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FRiX25tlMdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs=4\n",
        "total_steps=len(tdataloader)*epochs\n",
        "\n",
        "sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6LNSaNZpKVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  print(\"predictionArgmax\",predictionArgmax)\n",
        "  print(\"labelsFlattend\",labelsFlattend)\n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKBAgRkViOV",
        "colab_type": "text"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "#Also based on the following tutorials\n",
        "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brS_TJmHJs0I",
        "colab_type": "code",
        "outputId": "3a7b72dc-deb2-4c0d-9e6b-54c45c78c8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import time \n",
        "\n",
        "def set_seed(seed,ngpu):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if ngpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "      \n",
        "set_seed(42,torch.cuda.device_count())\n",
        "#remove later\n",
        "\n",
        "lossList=[]\n",
        "max_grad_norm=1.0\n",
        "for e in range(0, epochs):\n",
        "    print(\"Start Epoch Number\",(e + 1))\n",
        "    print(\"Start Training\")\n",
        "    \n",
        "    #Amount of time taken for training\n",
        "    t1 = time.time()\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.train()\n",
        "    tsteps=0\n",
        "    for step, batch in enumerate(tdataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        model.zero_grad()        \n",
        "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
        "        #print (\"Number of layers:\", len(outputs))\n",
        "        #print (\"Number of layers:\", len(outputs[0]))\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        tsteps+=1\n",
        "        optimizer.step()\n",
        "        sch.step()\n",
        "\n",
        "    a_tr_loss = tr_loss /(tsteps)               \n",
        "    lossList.append(a_tr_loss)\n",
        "    \n",
        "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
        "    t2=time.time()\n",
        "    print(\"  Training one epoch time taken\",t2-t1)\n",
        "    print(\" Validation starts here \")\n",
        "   \n",
        "    t1 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_f1=0\n",
        "    eval_acc=0\n",
        "\n",
        "    for batch in tedataloader:       \n",
        "        batch = tuple(t.to(device) for t in batch)        \n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "        eval_f1 = eval_f1+tmpf1score\n",
        "        eval_acc=eval_acc+tmpaccscore\n",
        "        nb_eval_steps += 1\n",
        "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
        "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
        "    #torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n",
        "    \n",
        "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "    \n",
        "    t2=time.time()\n",
        "    print(\"  Validating one epoch time taken \",t2-t1)\n",
        "    \n",
        "print(\"ALL DONE!!!\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Epoch Number 1\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  22.5319766998291\n",
            "Batch Completed  100  of  219.    Elapsed time is  44.987176179885864\n",
            "Batch Completed  150  of  219.    Elapsed time is  67.4045078754425\n",
            "Batch Completed  200  of  219.    Elapsed time is  89.82197189331055\n",
            " The training loss incured is  0.556\n",
            "  Training one epoch time taken 98.2496497631073\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0]\n",
            "predictionArgmax [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0]\n",
            "labelsFlattend [1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
            "predictionArgmax [0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1]\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0]\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1]\n",
            "predictionArgmax [0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0]\n",
            "predictionArgmax [1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
            "predictionArgmax [1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "labelsFlattend [1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1]\n",
            "labelsFlattend [0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0]\n",
            "labelsFlattend [1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0]\n",
            "labelsFlattend [0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1]\n",
            "predictionArgmax [0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0]\n",
            "labelsFlattend [0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0]\n",
            "predictionArgmax [1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0]\n",
            "predictionArgmax [1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1]\n",
            "labelsFlattend [0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1]\n",
            "labelsFlattend [1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1]\n",
            "predictionArgmax [0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0]\n",
            "predictionArgmax [1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0]\n",
            "  F1 score: 0.717\n",
            "  Accuracy score: 0.787\n",
            "  Validating one epoch time taken  7.50124979019165\n",
            "Start Epoch Number 2\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  22.506409406661987\n",
            "Batch Completed  100  of  219.    Elapsed time is  44.91325616836548\n",
            "Batch Completed  150  of  219.    Elapsed time is  67.344975233078\n",
            "Batch Completed  200  of  219.    Elapsed time is  89.8359887599945\n",
            " The training loss incured is  0.427\n",
            "  Training one epoch time taken 98.28095078468323\n",
            " Validation starts here \n",
            "predictionArgmax [0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            "labelsFlattend [1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1]\n",
            "labelsFlattend [1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
            "labelsFlattend [1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "predictionArgmax [0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0]\n",
            "predictionArgmax [1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1]\n",
            "predictionArgmax [0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1]\n",
            "labelsFlattend [0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0]\n",
            "predictionArgmax [1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0]\n",
            "predictionArgmax [0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0]\n",
            "predictionArgmax [1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1]\n",
            "labelsFlattend [1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "predictionArgmax [1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "labelsFlattend [1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0]\n",
            "predictionArgmax [0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "labelsFlattend [1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "predictionArgmax [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0]\n",
            "labelsFlattend [0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "  F1 score: 0.785\n",
            "  Accuracy score: 0.843\n",
            "  Validating one epoch time taken  7.558385133743286\n",
            "Start Epoch Number 3\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  22.504456520080566\n",
            "Batch Completed  100  of  219.    Elapsed time is  44.91984438896179\n",
            "Batch Completed  150  of  219.    Elapsed time is  67.34330654144287\n",
            "Batch Completed  200  of  219.    Elapsed time is  89.73322200775146\n",
            " The training loss incured is  0.354\n",
            "  Training one epoch time taken 98.18748450279236\n",
            " Validation starts here \n",
            "predictionArgmax [0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1]\n",
            "predictionArgmax [0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "labelsFlattend [1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0]\n",
            "predictionArgmax [0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1]\n",
            "labelsFlattend [0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1]\n",
            "predictionArgmax [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            "labelsFlattend [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1]\n",
            "labelsFlattend [0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            "predictionArgmax [0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0]\n",
            "predictionArgmax [1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1]\n",
            "labelsFlattend [0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1]\n",
            "predictionArgmax [1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1]\n",
            "labelsFlattend [1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1]\n",
            "predictionArgmax [1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0]\n",
            "labelsFlattend [1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0]\n",
            "predictionArgmax [1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
            "labelsFlattend [1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1]\n",
            "predictionArgmax [1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0]\n",
            "labelsFlattend [1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0]\n",
            "predictionArgmax [1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1]\n",
            "labelsFlattend [0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0]\n",
            "labelsFlattend [1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            "labelsFlattend [0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0]\n",
            "predictionArgmax [0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
            "predictionArgmax [1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0]\n",
            "labelsFlattend [1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
            "predictionArgmax [0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0]\n",
            "predictionArgmax [1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
            "predictionArgmax [1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1]\n",
            "labelsFlattend [1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1]\n",
            "predictionArgmax [0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0]\n",
            "labelsFlattend [0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0]\n",
            "predictionArgmax [1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0]\n",
            "predictionArgmax [0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]\n",
            "predictionArgmax [0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0]\n",
            "labelsFlattend [1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0]\n",
            "predictionArgmax [1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0]\n",
            "labelsFlattend [0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0]\n",
            "predictionArgmax [0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1]\n",
            "  F1 score: 0.794\n",
            "  Accuracy score: 0.838\n",
            "  Validating one epoch time taken  7.520506381988525\n",
            "Start Epoch Number 4\n",
            "Start Training\n",
            "Batch Completed  50  of  219.    Elapsed time is  22.49782657623291\n",
            "Batch Completed  100  of  219.    Elapsed time is  44.91229438781738\n",
            "Batch Completed  150  of  219.    Elapsed time is  67.3288893699646\n",
            "Batch Completed  200  of  219.    Elapsed time is  89.72155809402466\n",
            " The training loss incured is  0.309\n",
            "  Training one epoch time taken 98.14574885368347\n",
            " Validation starts here \n",
            "predictionArgmax [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
            "labelsFlattend [1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1]\n",
            "predictionArgmax [0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0]\n",
            "labelsFlattend [0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0]\n",
            "labelsFlattend [0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
            "predictionArgmax [1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0]\n",
            "labelsFlattend [1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0]\n",
            "predictionArgmax [1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
            "predictionArgmax [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0]\n",
            "predictionArgmax [1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1]\n",
            "labelsFlattend [0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1]\n",
            "predictionArgmax [1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1]\n",
            "labelsFlattend [1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1]\n",
            "predictionArgmax [0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1]\n",
            "labelsFlattend [0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0]\n",
            "predictionArgmax [1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labelsFlattend [1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1]\n",
            "labelsFlattend [1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "predictionArgmax [0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0]\n",
            "predictionArgmax [0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "predictionArgmax [1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "labelsFlattend [0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "predictionArgmax [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labelsFlattend [0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1]\n",
            "predictionArgmax [0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "predictionArgmax [1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
            "labelsFlattend [1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0]\n",
            "predictionArgmax [0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0]\n",
            "predictionArgmax [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1]\n",
            "labelsFlattend [0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "labelsFlattend [1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1]\n",
            "predictionArgmax [0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0]\n",
            "labelsFlattend [1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1]\n",
            "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0]\n",
            "labelsFlattend [0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0]\n",
            "predictionArgmax [0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1]\n",
            "labelsFlattend [0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1]\n",
            "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0]\n",
            "labelsFlattend [0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0]\n",
            "predictionArgmax [0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0]\n",
            "labelsFlattend [0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0]\n",
            "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0]\n",
            "labelsFlattend [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0]\n",
            "predictionArgmax [0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0]\n",
            "labelsFlattend [0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1 1 0]\n",
            "predictionArgmax [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0]\n",
            "predictionArgmax [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0]\n",
            "labelsFlattend [0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0]\n",
            "predictionArgmax [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labelsFlattend [1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0]\n",
            "labelsFlattend [0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0]\n",
            "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0]\n",
            "labelsFlattend [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0]\n",
            "predictionArgmax [0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0]\n",
            "labelsFlattend [0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0]\n",
            "predictionArgmax [0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0]\n",
            "labelsFlattend [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0]\n",
            "  F1 score: 0.797\n",
            "  Accuracy score: 0.844\n",
            "  Validating one epoch time taken  7.472885608673096\n",
            "ALL DONE!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2aELLrRYC-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjYyizvHYEid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "284943ba-86c1-4055-fe2e-98abecbba420"
      },
      "source": [
        "XXXX"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ce6a3706bd25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXXXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'XXXX' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyvwAKwrQVD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
        "print (\"Number of layers:\", len(outputs))\n",
        "print (\"Number of layers:\", len(outputs[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-oJKkuabfDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek2.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgfUDkkvNnTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs{}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rWdrUSxJIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##WITH AND WITHOUT PREPROCESSING F1 and accuracy score stuck at 0.755"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFcl1gBfU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWKfHXfplWQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
        "class GreekPredictDataset(Dataset):\n",
        "    def __init__(self,xypredict):\n",
        "        self.xypredict = xypredict\n",
        "        self.maxlength=128\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
        "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch\n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.xypredict[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3Gp5gPddxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictingData(pTweets,ypred):\n",
        "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
        "  ids_of_sentence=[]\n",
        "  predictedLabels,trueLabels=[],[]\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  ypredict=le.fit_transform(ypred.flatten())\n",
        "  map_location=\"\"\n",
        "  xypredict=[pTweets,ypredict]\n",
        "  tdataset = GreekPredictDataset(xypredict)\n",
        "  tsampler=RandomSampler(tdataset)\n",
        "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "  print(device.type)\n",
        "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "  if device.type==\"cpu\":\n",
        "    model.to(device)\n",
        "    map_location='cpu'\n",
        "  else:\n",
        "    model.cuda()\n",
        "    map_location=lambda storage, loc: storage.cuda()\n",
        "  params=list(model.named_parameters())\n",
        "  eval_f1=0\n",
        "  eval_acc=0\n",
        "  nb_eval_steps=0\n",
        "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek1.pth.tar',map_location=map_location)\n",
        "  print(\"Hello\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  model.eval()\n",
        "  i=0\n",
        "  for batch in predictdataloader:\n",
        "      #print(i)\n",
        "      i=i+1\n",
        "      batch = tuple(t.to(device) for t in batch)        \n",
        "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "      \n",
        "      with torch.no_grad():       \n",
        "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "      predictedLabels.append(logits)\n",
        "      trueLabels.append(label_ids)\n",
        "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "      eval_f1 = eval_f1+tmpf1score\n",
        "      eval_acc=eval_acc+tmpaccscore\n",
        "      nb_eval_steps += 1\n",
        "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "  return predictedLabels,trueLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3ajuk04jw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ-v9vkBMEZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelInitialize tokenizer and sequence classification\n",
        "predictedLabels,trueLabels=predictingData(sentence_predict,y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBxBKJFVaFjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3_AaAvxliJm",
        "colab_type": "text"
      },
      "source": [
        "from 80 ,10 ,10 split getting  # F1 score: 0.836 Accuracy score: 0.867\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}