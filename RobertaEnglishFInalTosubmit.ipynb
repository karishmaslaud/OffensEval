{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RobertaEnglishFInalTosubmit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsZ4bSdhBEP",
        "colab_type": "code",
        "outputId": "c165845e-d321-4b98-ccf8-a1758c0b3e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej4Vt62W39qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "#Also based on the following tutorials\n",
        "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Fpl7WYdNu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import random\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "\n",
        "from transformers import AdamW#, WarmupLinearSchedule\n",
        "\n",
        "#from utils import (convert_examples_to_features,\n",
        "                        #output_modes, processors)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1nweMDxcWic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpuname=\"\"\n",
        "device=\"\"\n",
        "y=\"\"\n",
        "preprocessedTweets=\"\"\n",
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3ZtD-zg4k1",
        "colab_type": "code",
        "outputId": "97d0b361-7c43-4dc1-80b0-e87a6d135efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "gpuname=tf.test.gpu_device_name()\n",
        "if gpuname=='/device:GPU:0':\n",
        "  print('Found GPU at :{}'.format(gpuname))\n",
        "else:\n",
        "  gpuname=\"\"\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  n_gpu=torch.cuda.device_count()\n",
        "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available using only CPU instead\")\n",
        "  device=torch.device(\"cpu\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at :/device:GPU:0\n",
            "The device name is Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKdaEMufiiAu",
        "colab_type": "code",
        "outputId": "e0f8149f-e74c-4cdf-d7fd-791682817be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZDHmlWSjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##NOT FOR SYSTEMS\n",
        "#!unzip -P ****** -qq '/content/drive/My Drive/EnglishData/task_a_distant.zip' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0snaWdyArgIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -P ****** -qq '/content/drive/My Drive/EnglishData/task_b_distant.zip' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bLBKEKprjzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "30f3689f-50b9-4c47-fadf-1bc8172d7215"
      },
      "source": [
        "'''def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "\n",
        "headers=['id','text','average','std']\n",
        "englishdata1 = pd.read_csv(\"task_b_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "englishdata1=englishdata1'''"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata1 = pd.read_csv(\"task_b_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata1=englishdata1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayt4_mQnr5n7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e4135206-5104-4df3-8d38-51a5eb0d4b28"
      },
      "source": [
        "'''def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "\n",
        "headers=['id','text','average','std']\n",
        "englishdata2 = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "englishdata2=englishdata2'''"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata2 = pd.read_csv(\"task_a_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata2=englishdata2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uXSsl4DrvPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(englishdata1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXDd24Fxry8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(englishdata2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHoGZVoSCPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
        "englishdata = pd.read_csv(\"olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
        "englishdata=englishdata[['id','tweet','subtask_a']]\n",
        "englishdata=englishdata[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKDwFMQdrusQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAFIEswSPcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aa90e025-8c75-480f-cd13-fafbeada59b5"
      },
      "source": [
        "'''# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
        "def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','text','average','std']\n",
        "englishdata = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "englishdata=englishdata[:100]\n",
        "'''"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\\ndef convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\n#GET THE DATA FROM THE PANDAS FRAME\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata = pd.read_csv(\"task_a_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata=englishdata[:100]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leV4AIvO56Jp",
        "colab_type": "code",
        "outputId": "9a3f3ec7-efe6-40df-979b-065d8354adf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(englishdata)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p43UBV5YZLjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9dY5nerCi3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "61f76a62-42a9-452f-f13a-6f85fe126353"
      },
      "source": [
        "englishdata.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet subtask_a\n",
              "1  86426  @USER She should ask a few native Americans wh...       OFF\n",
              "2  90194  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...       OFF\n",
              "3  16820  Amazon is investigating Chinese employees who ...       NOT\n",
              "4  62688  @USER Someone should'veTaken\" this piece of sh...       OFF\n",
              "5  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85xVmaYRHFab",
        "colab_type": "code",
        "outputId": "49f71248-2ef0-49f5-f52c-ea01023c5ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "'''englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\n",
        "export_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\n",
        "print (englishtrain.head())\n",
        "#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\n",
        "export_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\n",
        "print (englishtest.head())'''\n",
        "#export_csv = englishpredict.to_csv ('/content/drive/My Drive/EnglishData/predictFileEnglish.csv', index = None, header=True)\n",
        "#print (englishpredict.head())"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id                                              tweet subtask_a\n",
            "11461  51336                        @USER She is not leaving BB       NOT\n",
            "7946   78922  @USER @USER Ford and the conservatives hates t...       NOT\n",
            "9186   10317                         @USER God is good to us üôèüëç       NOT\n",
            "1057   14809  @USER woman accusing Supreme Court nominee #Ka...       NOT\n",
            "1147   34120  @USER CORRECTION: The Liberals won a false-maj...       NOT\n",
            "          id                                              tweet subtask_a\n",
            "12388  27650  @USER @USER Why is John Kerry running his mout...       NOT\n",
            "386    52965        @USER @USER Gun control anyone? #DisarmHate       NOT\n",
            "4897   87438                      @USER What manga you reading?       NOT\n",
            "3972   67140  @USER You are right. Victoria is on the revers...       NOT\n",
            "10395  43102  @USER @USER Thank you @USER . America is respe...       NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayHNHPM56TTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLXURnA5UefR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWe6eF21Ue-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn8dOMH10Cla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "758b65f6-88dc-4437-8e5a-9d51ee05126a"
      },
      "source": [
        "'''ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "\n",
        "def giveIds(sentence):\n",
        "  maxlength=0\n",
        "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "  return maxlength'''"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ids_of_sentence=[]\\nids_of_sentence_words=[]\\nattention_masks=[]\\n\\ndef giveIds(sentence):\\n  maxlength=0\\n  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\\n  for t in sentence:\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n  return maxlength\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUxfcUCbNGXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#max_length="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qZWdmK_CMiop",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7422db18-96d0-40e4-c7b3-224b441902e7"
      },
      "source": [
        "set(y)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9PP1a7RMioz",
        "colab": {}
      },
      "source": [
        "'''\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
        "def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "def readDataTrain():\n",
        "  headers=['id','tweet','subtask_a']\n",
        "  edata = pd.read_csv(\"/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv\", delimiter=',',names=headers,low_memory=False)\n",
        "  edata=edata[1:]\n",
        "  dfnumpy=edata.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  y1=le.fit_transform(y.flatten())\n",
        "  print(set(y1))\n",
        "  print(le.classes_)\n",
        "  return X,y1\n",
        "\n",
        "def readDataTest():\n",
        "  headers=['id','tweet','subtask_a']\n",
        "  edata = pd.read_csv(\"/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv\", delimiter=',',names=headers,low_memory=False)\n",
        "  edata=edata[1:]\n",
        "  dfnumpy=edata.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  y1=le.fit_transform(y.flatten())\n",
        "\n",
        "  return X,y1'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMeqzRH7LS5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfnumpy=englishdata.to_numpy()\n",
        "X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y=dfnumpy[:, 2].reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew7u6ptZMJZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a178dc14-3474-4e5a-cc46-77b4ae7a5861"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NOT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzsKG85LBeb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=X[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_NKcxDqLOGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "preprocessedTweets,y=shuffle(preprocessedTweets,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_KQpestKlz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test= train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gpr92MXKnq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "149522fd-685d-4e9d-e4d0-24865042e33e"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@USER @USER @USER @USER I never said no one died in Sa Juan..I said she is only in charge of one town out of 78...don‚Äôt get me wrong many people to blame...in the case of Ricardo Rosello he is terrified of Trump and wants to please him at all cause.  Im sure Rosell√≥ and trump knew the count was higher',\n",
              "       '@USER @USER @USER @USER @USER Now they have really sunk to a new low !! Hope the show BOMBS ! The entire thing a set up by libs just like everything else they are doing !! Roseanne üåπ; was the show !! MAGA üá∫üá∏',\n",
              "       '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Same here. You got a follow. Great talk on my way home from work. Time to be the vampire and sleep during the day',\n",
              "       ...,\n",
              "       '@USER He is like a cheap plastic version of a real president.',\n",
              "       '@USER @USER @USER Totally. Just shown herself up to be a spoilt narcissist. The comment to the umpire that he will never be at her matches for as long as he lives? Just who does she think she is?? Not gracious in defeat. A disgrace to the sport.',\n",
              "       '@USER I call her the Negative Nellie who lives in my brain. I constantly battle with her. She is a creep.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CXlx4H41X-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "913758f4-216a-42db-fd86-3ca540851969"
      },
      "source": [
        "'''x_train,y_train=readDataTrain()\n",
        "x_test,y_test=readDataTest()\n",
        "'''"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1}\n",
            "['NOT' 'OFF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXkHq0Q0K2Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0c015a3f-f247-4176-be43-de3b0b0d88c2"
      },
      "source": [
        "print(preprocessedTweets[0:5])"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@USER @USER @USER @USER Becca. She is too much work.'\n",
            " \"@USER Disagree; he was chosen explicitly to make the President immune to the rule of law. All of his heinous beliefs on women's rights and gun control are just the frosting to make the GOP confirm him.\"\n",
            " '@USER That shit weird! Lol'\n",
            " '#WebberForCongress #NJ11 #MAGA we cannot allow #Liberals to #Impeach #POTUS #Trump URL'\n",
            " '@USER I‚Äôm sorry you are going through this.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSZGqjvlBIDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ff4c0c6f-4442-4125-abe5-4c4c27d6f6fa"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#print(y_predict.shape)\n",
        "yTrain=le.fit_transform(y_train.flatten())\n",
        "print(yTrain.shape)\n",
        "print(le.classes_)\n",
        "yTest=le.fit_transform(y_test.flatten())\n",
        "print(le.classes_)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10592, 1)\n",
            "(2648, 1)\n",
            "(10592,)\n",
            "['NOT' 'OFF']\n",
            "['NOT' 'OFF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMCPsKyZBK7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "031d74d7-5630-4ed4-d143-1d4926c89271"
      },
      "source": [
        "set(y_test)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmG6tesd1euz",
        "colab_type": "code",
        "outputId": "105fc64d-0cd4-425d-8d27-c088abd4ebb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###IMPORTANT\n",
        "'''xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
        "x_test_pytorch=torch.tensor(xtest)\n",
        "y_test_pytorch=torch.tensor(y_test)\n",
        "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
        "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
        "tesampler=RandomSampler(tedata)\n",
        "bsize=64\n",
        "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
        "print(len(xtest))\n",
        "print(len(y_test))\n",
        "len(x_train)\n",
        "'''"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbZxkgcBhfag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edbee08c-5800-440e-97b6-ec0e6f3cfcb3"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification as bfsc,AdamW,RobertaConfig\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "config = RobertaConfig.from_pretrained('roberta-base',output_attentions=False,output_hidden_states=False,num_labels=2)\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification(config)\n",
        "model.cuda()"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
            "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPr_Sj12LY-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7e79f0b-609c-437c-bcd2-7887ff1d89b8"
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "  "
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDzvjKyWMio7",
        "colab": {}
      },
      "source": [
        "params=list(model.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQQ5__z5Mio-",
        "colab": {}
      },
      "source": [
        "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
        "optimizer_grouped_parameters = [\n",
        "{\n",
        "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "\"weight_decay\": 0.01,\n",
        "},\n",
        "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "frZAYslgMipB",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(model.parameters(),lr=3e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "au4tTkrfMipE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xSdEEzMJMipH",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  print(\"Predictions Argmax\",predictionArgmax)\n",
        "  print(\"labels Flattened\",labelsFlattend)   \n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cu3euWbs9MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owfS8MEZ-oJf",
        "colab_type": "code",
        "outputId": "2e32d98b-6c49-4b23-e84e-90874096ac45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###IMPORTANT\n",
        "'''\n",
        "xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
        "x_test_pytorch=torch.tensor(xtest)\n",
        "y_test_pytorch=torch.tensor(y_test)\n",
        "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
        "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
        "tesampler=RandomSampler(tedata)\n",
        "bsize=64\n",
        "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
        "print(len(xtest))\n",
        "print(len(y_test))\n",
        "len(x_train)\n",
        "'''"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nxtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTEaGYn-AIWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z=len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJLwApO5CCNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FOvU_KsCYid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a dataset inspired from \n",
        "#https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSEGSScdGllP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#xytest[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAS3e4gNHI44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORB6e8-JnoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the customdataset section has been inspired from \n",
        "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBcEMw2SRV_7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwqSDP2KL71z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAXLENGTH=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTurXRofNATj",
        "colab_type": "code",
        "outputId": "5686e0d2-1aa1-46bb-a1f5-998e9542249a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class EnglishTrainDataset(Dataset):\n",
        "    def __init__(self,xytrain):\n",
        "        self.xytrain = xytrain\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(self.xytrain[0][index])\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        #attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
        "        \n",
        "        return x_train_pytorch,y_train_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytrain[0])\n",
        " \n",
        "\n",
        "'''\n",
        "z=0;\n",
        "for batch_idx, data in enumerate(tdataloader): \n",
        "  if z==100:\n",
        "    break;\n",
        "  z=z+1;'''"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nz=0;\\nfor batch_idx, data in enumerate(tdataloader): \\n  if z==100:\\n    break;\\n  z=z+1;'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47_yavmOa7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnglishTestDataset(Dataset):\n",
        "    def __init__(self,xytest):\n",
        "        self.xytest = xytest\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(self.xytest[0][index])\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        #assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        #attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
        "        #x_test_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_test_pytorch,y_test_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytest[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VObEL94h-bU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#xytrain=[x_train[:8000],y_train[:8000]]\\\n",
        "#MAXLENGTH=giveIds(x_train[0])\n",
        "xytrain=[x_train,yTrain]\n",
        "#tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "tdataset = EnglishTrainDataset(xytrain)\n",
        "tsampler=RandomSampler(tdataset)\n",
        "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t753LP5zOq44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "71d13c11-35b2-4abc-995a-459b5c47e99c"
      },
      "source": [
        "#tokenized_review = tokenizer.tokenize(str(xytest[0][0].flatten()))\n",
        " #y_test_pytorch=torch.tensor(y_test[0])\n",
        " #y_test[0]\n",
        " xytrain[0][1]"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@USER @USER @USER @USER @USER Now they have really sunk to a new low !! Hope the show BOMBS ! The entire thing a set up by libs just like everything else they are doing !! Roseanne üåπ; was the show !! MAGA üá∫üá∏'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_J0p88PWuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenized_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udjp1U9q9xaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#xytest=[x_test[:8000],y_test[:8000]]\n",
        "xytest=[x_test,yTest]\n",
        "#tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "tedataset = EnglishTestDataset(xytest) \n",
        "tesampler=RandomSampler(tedataset)\n",
        "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
        "#trainData(tdataloader,tedataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rPrZ3_M-LZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "epochs=4\n",
        "total_steps=len(tdataloader)*epochs\n",
        "sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp-PmVUP9N9c",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cqmnbPGdMipR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5e9545b-d4df-45ca-dec5-1a66710bcf76"
      },
      "source": [
        "import random\n",
        "import time \n",
        "\n",
        "def set_seed(seed,ngpu):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if ngpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "      \n",
        "set_seed(42,torch.cuda.device_count())\n",
        "#remove later\n",
        "\n",
        "epochs=4\n",
        "lossList=[]\n",
        "max_grad_norm=1.0\n",
        "for e in range(0, epochs):\n",
        "    print(\"Start Epoch Number\",(e + 1))\n",
        "    print(\"Start Training\")\n",
        "    \n",
        "\n",
        "    #Amount of time taken for training\n",
        "    t1 = time.time()\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.train()\n",
        "    tsteps=0\n",
        "    for step, batch in enumerate(tdataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"labels\": batch[1]}\n",
        "        model.zero_grad()     \n",
        "        outputs = model(inputs[\"input_ids\"],token_type_ids=None, labels=inputs[\"labels\"])\n",
        "        #print(type(outputs))\n",
        "        loss, prediction_scores = outputs[:2]\n",
        "        #print(loss)\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        tsteps+=1\n",
        "        optimizer.step()\n",
        "        sch.step()\n",
        "    a_tr_loss = tr_loss /(tsteps)               \n",
        "    lossList.append(a_tr_loss)\n",
        "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
        "    t2=time.time()\n",
        "    print(\"  Training one epoch time taken\",t2-t1)\n",
        "    print(\" Validation starts here \")\n",
        "    t1 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_f1=0\n",
        "    eval_acc=0\n",
        "    \n",
        "    for batch_idx, data in enumerate(tedataloader):\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in data)            \n",
        "        inputs = {\"input_ids\": batch[0], \"labels\": batch[1]}\n",
        "        with torch.no_grad():        \n",
        "           outputs = model(inputs[\"input_ids\"],token_type_ids=None)\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "        eval_f1 = eval_f1+tmpf1score\n",
        "        eval_acc=eval_acc+tmpaccscore\n",
        "        nb_eval_steps += 1\n",
        "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
        "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
        "    #torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
        "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "    t2=time.time()\n",
        "    print(\"  Validating one epoch time taken \",t2-t1)\n",
        "      \n",
        "    \n",
        "print(\"ALL DONE!!!\")"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Epoch Number 1\n",
            "Start Training\n",
            "Batch Completed  50  of  331.    Elapsed time is  11.876701593399048\n",
            "Batch Completed  100  of  331.    Elapsed time is  23.65893268585205\n",
            "Batch Completed  150  of  331.    Elapsed time is  35.394779920578\n",
            "Batch Completed  200  of  331.    Elapsed time is  47.17995762825012\n",
            "Batch Completed  250  of  331.    Elapsed time is  59.05367064476013\n",
            "Batch Completed  300  of  331.    Elapsed time is  70.75678062438965\n",
            " The training loss incured is  0.652\n",
            "  Training one epoch time taken 78.07373690605164\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0]\n",
            "  F1 score: 0.404\n",
            "  Accuracy score: 0.682\n",
            "  Validating one epoch time taken  5.578825950622559\n",
            "Start Epoch Number 2\n",
            "Start Training\n",
            "Batch Completed  50  of  331.    Elapsed time is  11.89433217048645\n",
            "Batch Completed  100  of  331.    Elapsed time is  23.727855682373047\n",
            "Batch Completed  150  of  331.    Elapsed time is  35.49505615234375\n",
            "Batch Completed  200  of  331.    Elapsed time is  47.3277223110199\n",
            "Batch Completed  250  of  331.    Elapsed time is  59.11989736557007\n",
            "Batch Completed  300  of  331.    Elapsed time is  70.83286952972412\n",
            " The training loss incured is  0.614\n",
            "  Training one epoch time taken 78.23880648612976\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1]\n",
            "labels Flattened [0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0]\n",
            "labels Flattened [1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0]\n",
            "Predictions Argmax [1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "labels Flattened [1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0]\n",
            "labels Flattened [1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1]\n",
            "labels Flattened [0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0]\n",
            "Predictions Argmax [0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1]\n",
            "labels Flattened [0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1]\n",
            "labels Flattened [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1]\n",
            "labels Flattened [1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1]\n",
            "labels Flattened [1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1]\n",
            "labels Flattened [0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0]\n",
            "Predictions Argmax [1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1]\n",
            "labels Flattened [1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0]\n",
            "labels Flattened [1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1]\n",
            "labels Flattened [0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0]\n",
            "Predictions Argmax [1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1]\n",
            "Predictions Argmax [1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1]\n",
            "labels Flattened [1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1]\n",
            "Predictions Argmax [1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1]\n",
            "labels Flattened [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0]\n",
            "labels Flattened [1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0]\n",
            "labels Flattened [0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0]\n",
            "labels Flattened [0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [1 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1]\n",
            "labels Flattened [0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1]\n",
            "labels Flattened [1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1]\n",
            "labels Flattened [1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0]\n",
            "Predictions Argmax [1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1]\n",
            "labels Flattened [1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0]\n",
            "Predictions Argmax [1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1]\n",
            "labels Flattened [0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0]\n",
            "Predictions Argmax [1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1]\n",
            "labels Flattened [0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0]\n",
            "Predictions Argmax [1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0]\n",
            "Predictions Argmax [1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1]\n",
            "labels Flattened [0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0]\n",
            "Predictions Argmax [0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1]\n",
            "labels Flattened [1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1]\n",
            "labels Flattened [0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "Predictions Argmax [1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0]\n",
            "labels Flattened [0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1]\n",
            "labels Flattened [1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0]\n",
            "labels Flattened [0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0]\n",
            "labels Flattened [0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1]\n",
            "labels Flattened [0 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1]\n",
            "labels Flattened [0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1]\n",
            "Predictions Argmax [0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0]\n",
            "labels Flattened [0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1]\n",
            "labels Flattened [1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1]\n",
            "Predictions Argmax [1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0]\n",
            "labels Flattened [1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1]\n",
            "labels Flattened [0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1]\n",
            "labels Flattened [1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 1]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0]\n",
            "labels Flattened [1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "Predictions Argmax [1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 1]\n",
            "labels Flattened [0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1]\n",
            "labels Flattened [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1]\n",
            "labels Flattened [0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1]\n",
            "labels Flattened [0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1]\n",
            "labels Flattened [0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1]\n",
            "Predictions Argmax [0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1]\n",
            "labels Flattened [0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0]\n",
            "  F1 score: 0.598\n",
            "  Accuracy score: 0.615\n",
            "  Validating one epoch time taken  5.5736000537872314\n",
            "Start Epoch Number 3\n",
            "Start Training\n",
            "Batch Completed  50  of  331.    Elapsed time is  11.939412117004395\n",
            "Batch Completed  100  of  331.    Elapsed time is  23.76896595954895\n",
            "Batch Completed  150  of  331.    Elapsed time is  35.57639265060425\n",
            "Batch Completed  200  of  331.    Elapsed time is  47.377532958984375\n",
            "Batch Completed  250  of  331.    Elapsed time is  59.139485359191895\n",
            "Batch Completed  300  of  331.    Elapsed time is  70.95595693588257\n",
            " The training loss incured is  0.497\n",
            "  Training one epoch time taken 78.32652354240417\n",
            " Validation starts here \n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            "labels Flattened [0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
            "labels Flattened [0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1]\n",
            "labels Flattened [1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0]\n",
            "labels Flattened [0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1]\n",
            "Predictions Argmax [1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "labels Flattened [0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "labels Flattened [1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1]\n",
            "labels Flattened [0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1]\n",
            "labels Flattened [0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0]\n",
            "labels Flattened [0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0]\n",
            "labels Flattened [1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0]\n",
            "Predictions Argmax [0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
            "labels Flattened [0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            "labels Flattened [1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            "labels Flattened [1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1]\n",
            "Predictions Argmax [1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
            "labels Flattened [1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
            "labels Flattened [1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "Predictions Argmax [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [0 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1]\n",
            "labels Flattened [0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0]\n",
            "Predictions Argmax [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "labels Flattened [1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
            "labels Flattened [0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
            "  F1 score: 0.660\n",
            "  Accuracy score: 0.752\n",
            "  Validating one epoch time taken  5.545400857925415\n",
            "Start Epoch Number 4\n",
            "Start Training\n",
            "Batch Completed  50  of  331.    Elapsed time is  11.924359560012817\n",
            "Batch Completed  100  of  331.    Elapsed time is  23.674651384353638\n",
            "Batch Completed  150  of  331.    Elapsed time is  35.51570200920105\n",
            "Batch Completed  200  of  331.    Elapsed time is  47.16890358924866\n",
            "Batch Completed  250  of  331.    Elapsed time is  58.92648005485535\n",
            "Batch Completed  300  of  331.    Elapsed time is  70.69097685813904\n",
            " The training loss incured is  0.410\n",
            "  Training one epoch time taken 77.98472166061401\n",
            " Validation starts here \n",
            "Predictions Argmax [0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0]\n",
            "labels Flattened [0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0]\n",
            "labels Flattened [0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "labels Flattened [1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 1]\n",
            "labels Flattened [0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1]\n",
            "labels Flattened [1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
            "labels Flattened [0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0]\n",
            "Predictions Argmax [1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1]\n",
            "labels Flattened [1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1]\n",
            "labels Flattened [0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1]\n",
            "labels Flattened [1 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1]\n",
            "labels Flattened [1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1]\n",
            "labels Flattened [1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0]\n",
            "Predictions Argmax [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0]\n",
            "Predictions Argmax [0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0]\n",
            "labels Flattened [1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0]\n",
            "Predictions Argmax [0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1]\n",
            "labels Flattened [0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0]\n",
            "labels Flattened [1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
            "labels Flattened [0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0]\n",
            "Predictions Argmax [1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0]\n",
            "Predictions Argmax [0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
            "labels Flattened [0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0]\n",
            "Predictions Argmax [0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0]\n",
            "labels Flattened [0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1 1]\n",
            "labels Flattened [0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0]\n",
            "labels Flattened [0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1]\n",
            "labels Flattened [0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
            "Predictions Argmax [1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
            "labels Flattened [1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1]\n",
            "labels Flattened [1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1]\n",
            "labels Flattened [0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0]\n",
            "labels Flattened [1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0]\n",
            "Predictions Argmax [0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0]\n",
            "labels Flattened [0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1]\n",
            "Predictions Argmax [0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            "labels Flattened [0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0]\n",
            "labels Flattened [0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "labels Flattened [1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1]\n",
            "labels Flattened [1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0]\n",
            "Predictions Argmax [0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0]\n",
            "labels Flattened [1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1]\n",
            "Predictions Argmax [1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0]\n",
            "labels Flattened [0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1]\n",
            "labels Flattened [1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1]\n",
            "Predictions Argmax [0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
            "labels Flattened [0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1]\n",
            "Predictions Argmax [0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0]\n",
            "labels Flattened [1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0]\n",
            "labels Flattened [0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0]\n",
            "Predictions Argmax [1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1]\n",
            "labels Flattened [1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1]\n",
            "labels Flattened [0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0]\n",
            "Predictions Argmax [0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
            "Predictions Argmax [1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            "labels Flattened [1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1]\n",
            "Predictions Argmax [1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0]\n",
            "Predictions Argmax [0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "labels Flattened [1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
            "Predictions Argmax [1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
            "labels Flattened [0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0]\n",
            "labels Flattened [1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
            "Predictions Argmax [1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0]\n",
            "labels Flattened [1 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0]\n",
            "Predictions Argmax [1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1]\n",
            "labels Flattened [0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1]\n",
            "Predictions Argmax [0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0]\n",
            "Predictions Argmax [0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0]\n",
            "labels Flattened [0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1]\n",
            "Predictions Argmax [1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0]\n",
            "labels Flattened [0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            "  F1 score: 0.672\n",
            "  Accuracy score: 0.718\n",
            "  Validating one epoch time taken  5.54428768157959\n",
            "ALL DONE!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0CcvhMPDUy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81095cbc-5b3c-471d-b131-98d8a274856b"
      },
      "source": [
        "print(type(outputs))"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVLBZueyOjA_",
        "colab_type": "code",
        "outputId": "51396da5-49ed-4b8a-ed03-e8addf6703b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print(outputs[1])"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-302-d679f0e0964f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlwyxaioYiGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''nlists=2\n",
        "last=16000\n",
        "size_of_itertrain=8000//nlists\n",
        "size_of_itertest=8000//nlists\n",
        "#print(size_of_itertrain)\n",
        "for  i in range(nlists+1):\n",
        "      \n",
        "      end=(i+1)*size_of_itertrain\n",
        "      if(last<end):\n",
        "        end=last\n",
        "      xytrain=[x_train[i*size_of_itertrain:end],y_train[i*size_of_itertrain:end]]\n",
        "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "      tdataset = EnglishTrainDataset(xytrain)\n",
        "      tsampler=RandomSampler(tdataset)\n",
        "      tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "      \n",
        "      epochs=2\n",
        "      total_steps=len(tdataloader)*epochs\n",
        "      sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
        "\n",
        "      end=(i+1)*size_of_itertest\n",
        "      if(last<end):\n",
        "        end=last \n",
        "    \n",
        "      xytest=[x_test[i*size_of_itertest:end],y_test[i*size_of_itertest:end]]\n",
        "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "      tedataset = EnglishTestDataset(xytest)  \n",
        "      tesampler=RandomSampler(tedataset)\n",
        "      tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
        "\n",
        "      trainData(tdataloader,tedataloader)\n",
        "\n",
        "      \n",
        "y_test_pytorch=torch.tensor(xytest[1][index])'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPhVU_w-iZmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_test_pytorch=torch.tensor(xytest[1][40])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QXQMvZxpzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(xytest[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0WX9KRpvDvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(xytest[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rWdrUSxJIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(xytrain[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVU_iFtVa42a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MAXLENGTH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-upACWh-MuWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"MAXLENGTH\",MAXLENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWgpgNrIOAnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}