{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RobertaEnglishFInalTosubmit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f9c1c221d1b4bc19336c7e9414a4097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78f185168ed0470dbaa2f1b125a14e43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_193e474067514c5bae93a7371a103c81",
              "IPY_MODEL_168ca0cb962244389e78aae36291f925"
            ]
          }
        },
        "78f185168ed0470dbaa2f1b125a14e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "193e474067514c5bae93a7371a103c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bba74634022d4fa2bf30dc0afdfaefa3",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8dd0861a1ca44069b8101def3c83a59"
          }
        },
        "168ca0cb962244389e78aae36291f925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_426fa98f0b9f4a4f9be92479f7117a2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 15.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_741bc44b7bf84328a25165bbbc01023c"
          }
        },
        "bba74634022d4fa2bf30dc0afdfaefa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8dd0861a1ca44069b8101def3c83a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "426fa98f0b9f4a4f9be92479f7117a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "741bc44b7bf84328a25165bbbc01023c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64d03b5842d6499083b1cc9705b861a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65822bd4be834c388913312f7436da89",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a453c36b07b1431e935d0a68316d4090",
              "IPY_MODEL_770d495a41894b91b47afb8508fee6b1"
            ]
          }
        },
        "65822bd4be834c388913312f7436da89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a453c36b07b1431e935d0a68316d4090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3419721977544c91b163232d55555d4d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45655c8e94e44ff4a57c3366f6a2a2be"
          }
        },
        "770d495a41894b91b47afb8508fee6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02dc640addb24521a615e27ab2a6d319",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:37&lt;00:00, 11.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f1fa17b825c4fc587bd2fdd291270d9"
          }
        },
        "3419721977544c91b163232d55555d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45655c8e94e44ff4a57c3366f6a2a2be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02dc640addb24521a615e27ab2a6d319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f1fa17b825c4fc587bd2fdd291270d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2e828c9e86c443bbd4564fc4d733b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f70718dcad60489eb4cb61565a556a15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff88f159ed694502bb21fcd7a830240e",
              "IPY_MODEL_8882de0fe4884f929e2c9fb6c70ddc86"
            ]
          }
        },
        "f70718dcad60489eb4cb61565a556a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff88f159ed694502bb21fcd7a830240e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48f15496d6164a06bd41dee4d9872b85",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_519178e4085f4a01ae154338b39dcb57"
          }
        },
        "8882de0fe4884f929e2c9fb6c70ddc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_488a63449bff4e4ba2ed61765e784165",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 419kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3af5dde91e754186a1bfaa1a5ca628ab"
          }
        },
        "48f15496d6164a06bd41dee4d9872b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "519178e4085f4a01ae154338b39dcb57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "488a63449bff4e4ba2ed61765e784165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3af5dde91e754186a1bfaa1a5ca628ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsZ4bSdhBEP",
        "colab_type": "code",
        "outputId": "6655bb16-4e01-4aa6-c9a3-ff995b8b0519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 4.9MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 16.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=c4c97a1ccb61f2fdba714419773bc4ec578e005a95fa6effbcbe6e0c0da12e5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej4Vt62W39qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "#Also based on the following tutorials\n",
        "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Fpl7WYdNu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer as bertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import random\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "\n",
        "from transformers import AdamW#, WarmupLinearSchedule\n",
        "\n",
        "#from utils import (convert_examples_to_features,\n",
        "                        #output_modes, processors)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1nweMDxcWic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpuname=\"\"\n",
        "device=\"\"\n",
        "y=\"\"\n",
        "preprocessedTweets=\"\"\n",
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3ZtD-zg4k1",
        "colab_type": "code",
        "outputId": "4c932232-4d27-4448-a203-68c130f4678a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "gpuname=tf.test.gpu_device_name()\n",
        "if gpuname=='/device:GPU:0':\n",
        "  print('Found GPU at :{}'.format(gpuname))\n",
        "else:\n",
        "  gpuname=\"\"\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  n_gpu=torch.cuda.device_count()\n",
        "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available using only CPU instead\")\n",
        "  device=torch.device(\"cpu\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at :/device:GPU:0\n",
            "The device name is Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxQyW-Phb3lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
        "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
        "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "}\n",
        "\n",
        "#config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES['roberta']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKdaEMufiiAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZDHmlWSjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##NOT FOR SYSTEMS\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/EnglishData/task_a_distant.zip' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bHoGZVoSCPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
        "englishdata = pd.read_csv(\"olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
        "englishdata=englishdata[['id','tweet','subtask_a']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAFIEswSPcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
        "def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','text','average','std']\n",
        "englishdata = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "englishdata=englishdata[:100]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leV4AIvO56Jp",
        "colab_type": "code",
        "outputId": "2b4f4753-4b58-489e-e20f-d50900faf870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(englishdata)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p43UBV5YZLjE",
        "colab_type": "code",
        "outputId": "3b95289c-342f-4cdc-a362-55f33253a855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "englishdata.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>tweet</td>\n",
              "      <td>subtask_a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  subtask_a\n",
              "0     id                                              tweet  subtask_a\n",
              "1  86426  @USER She should ask a few native Americans wh...        OFF\n",
              "2  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...        OFF\n",
              "3  16820  Amazon is investigating Chinese employees who ...        NOT\n",
              "4  62688  @USER Someone should'veTaken\" this piece of sh...        OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85xVmaYRHFab",
        "colab_type": "code",
        "outputId": "5fe764ba-8f31-4dc1-cf1d-24f89bd936da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\n",
        "export_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\n",
        "print (englishtrain.head())\n",
        "#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\n",
        "export_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\n",
        "print (englishtest.head())\n",
        "#export_csv = englishpredict.to_csv ('/content/drive/My Drive/EnglishData/predictFileEnglish.csv', index = None, header=True)\n",
        "#print (englishpredict.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         id                                              tweet subtask_a\n",
            "7945  95036                 @USER @USER Mehn you are too sweet       NOT\n",
            "9185  98619  @USER Not if you are polling mexicans!!! #taco...       NOT\n",
            "1056  96330  @USER @USER then you are not equipped to adopt...       NOT\n",
            "1146  33064  @USER @USER @USER We've had a good conversatio...       NOT\n",
            "3827  20123  @USER @USER We all know this is another Libera...       OFF\n",
            "          id                                              tweet subtask_a\n",
            "12388  27650  @USER @USER Why is John Kerry running his mout...       NOT\n",
            "385    53995  @USER We shouldn’t be surprised. These same pi...       OFF\n",
            "4896   72139  @USER You are so right on this issue and Democ...       OFF\n",
            "3971   95266  @USER @USER But it’s so cute when conservative...       NOT\n",
            "11895  32891  @USER @USER @USER @USER @USER @USER @USER @USE...       NOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayHNHPM56TTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLXURnA5UefR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWe6eF21Ue-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn8dOMH10Cla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_of_sentence=[]\n",
        "ids_of_sentence_words=[]\n",
        "attention_masks=[]\n",
        "\n",
        "def giveIds(sentence):\n",
        "  maxlength=0\n",
        "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "  for t in sentence:\n",
        "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
        "      if(maxlength<len(tokenized_sentence_id)):\n",
        "          maxlength=len(tokenized_sentence_id)\n",
        "  return maxlength"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUxfcUCbNGXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qZWdmK_CMiop",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9PP1a7RMioz",
        "colab": {}
      },
      "source": [
        "\n",
        "# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
        "def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "def giveLabel(y):\n",
        "  i=0\n",
        "  y1=[]\n",
        "  for r in y:\n",
        "    if(y[i]>=0.5):\n",
        "      y1.append(1)\n",
        "    else:\n",
        "      y1.append(0)\n",
        "    i=i+1;\n",
        "  return y1\n",
        "\n",
        "def readDataTrain():\n",
        "  headers=['id','text','average','std']\n",
        "  edata = pd.read_csv(\"/content/drive/My Drive/EnglishData/TrainFileEnglish.csv\", delimiter=',',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "  edata=edata[1:]\n",
        "  dfnumpy=edata.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  y1=giveLabel(y)\n",
        "  return X,y1\n",
        "\n",
        "def readDataTest():\n",
        "  headers=['id','text','average','std']\n",
        "  edata = pd.read_csv(\"/content/drive/My Drive/EnglishData/TestFileEnglish.csv\", delimiter=',',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
        "  edata=edata[1:]\n",
        "  dfnumpy=edata.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  y1=giveLabel(y)\n",
        "  return X,y1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMeqzRH7LS5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CXlx4H41X-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train=readDataTrain()\n",
        "x_test,y_test=readDataTrain()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmG6tesd1euz",
        "colab_type": "code",
        "outputId": "c0f91166-0660-4847-b4fa-6c1774a4c8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###IMPORTANT\n",
        "'''xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
        "x_test_pytorch=torch.tensor(xtest)\n",
        "y_test_pytorch=torch.tensor(y_test)\n",
        "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
        "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
        "tesampler=RandomSampler(tedata)\n",
        "bsize=64\n",
        "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
        "print(len(xtest))\n",
        "print(len(y_test))\n",
        "len(x_train)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6MCKd-3pMio3",
        "outputId": "659a2d92-3b95-4979-da6f-890ebe7d6192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4f9c1c221d1b4bc19336c7e9414a4097",
            "78f185168ed0470dbaa2f1b125a14e43",
            "193e474067514c5bae93a7371a103c81",
            "168ca0cb962244389e78aae36291f925",
            "bba74634022d4fa2bf30dc0afdfaefa3",
            "c8dd0861a1ca44069b8101def3c83a59",
            "426fa98f0b9f4a4f9be92479f7117a2a",
            "741bc44b7bf84328a25165bbbc01023c",
            "64d03b5842d6499083b1cc9705b861a1",
            "65822bd4be834c388913312f7436da89",
            "a453c36b07b1431e935d0a68316d4090",
            "770d495a41894b91b47afb8508fee6b1",
            "3419721977544c91b163232d55555d4d",
            "45655c8e94e44ff4a57c3366f6a2a2be",
            "02dc640addb24521a615e27ab2a6d319",
            "4f1fa17b825c4fc587bd2fdd291270d9"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
        "model=bfsc.from_pretrained('bert-base-uncased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f9c1c221d1b4bc19336c7e9414a4097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d03b5842d6499083b1cc9705b861a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPr_Sj12LY-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDzvjKyWMio7",
        "colab": {}
      },
      "source": [
        "params=list(model.named_parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQQ5__z5Mio-",
        "colab": {}
      },
      "source": [
        "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
        "optimizer_grouped_parameters = [\n",
        "{\n",
        "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "\"weight_decay\": 0.01,\n",
        "},\n",
        "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "frZAYslgMipB",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "au4tTkrfMipE",
        "outputId": "492bab05-6339-45b2-a764-3615ea1b0f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertenglish.pth.tar')\n",
        "checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertenglish.pth.tar')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xSdEEzMJMipH",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  print(\"Predictions Argmax\",predictionArgmax)\n",
        "  print(\"labels Flattened\",labelsFlattend)   \n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cu3euWbs9MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owfS8MEZ-oJf",
        "colab_type": "code",
        "outputId": "4b11ae9f-826e-42a3-815f-c3720b412a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###IMPORTANT\n",
        "'''\n",
        "xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
        "x_test_pytorch=torch.tensor(xtest)\n",
        "y_test_pytorch=torch.tensor(y_test)\n",
        "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
        "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
        "tesampler=RandomSampler(tedata)\n",
        "bsize=64\n",
        "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
        "print(len(xtest))\n",
        "print(len(y_test))\n",
        "len(x_train)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nxtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTEaGYn-AIWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z=len(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJLwApO5CCNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FOvU_KsCYid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a dataset inspired from \n",
        "#https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSEGSScdGllP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#xytest[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAS3e4gNHI44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORB6e8-JnoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the customdataset section has been inspired from \n",
        "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBcEMw2SRV_7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwqSDP2KL71z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTurXRofNATj",
        "colab_type": "code",
        "outputId": "2ba41162-df35-4537-e4cd-58c75271cb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class EnglishTrainDataset(Dataset):\n",
        "    def __init__(self,xytrain):\n",
        "        self.xytrain = xytrain\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index].flatten()))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
        "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytrain[0])\n",
        " \n",
        "\n",
        "'''\n",
        "z=0;\n",
        "for batch_idx, data in enumerate(tdataloader): \n",
        "  if z==100:\n",
        "    break;\n",
        "  z=z+1;'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nz=0;\\nfor batch_idx, data in enumerate(tdataloader): \\n  if z==100:\\n    break;\\n  z=z+1;'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47_yavmOa7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnglishTestDataset(Dataset):\n",
        "    def __init__(self,xytest):\n",
        "        self.xytest = xytest\n",
        "        self.maxlength=MAXLENGTH\n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index].flatten()))\n",
        "        if len(tokenized_review) > self.maxlength:\n",
        "            #print(tokenized_review)\n",
        "            tokenized_review = tokenized_review[:self.maxlength]\n",
        "        \n",
        "        \n",
        "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
        "        ids_of_sentence_word += padding\n",
        "        assert len(ids_of_sentence_word) == self.maxlength\n",
        "        #print(ids_of_sentence_word)\n",
        "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
        "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
        "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
        "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
        "        \n",
        "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
        "        #return [1,2,3]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.xytest[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VObEL94h-bU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t753LP5zOq44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenized_review = tokenizer.tokenize(str(xytest[0][0].flatten()))\n",
        " #y_test_pytorch=torch.tensor(y_test[0])\n",
        " #y_test[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_J0p88PWuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenized_review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udjp1U9q9xaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "englishdata=\"\"\n",
        "englishtest=\"\"\n",
        "englishtrain=\"\"\n",
        "X=\"\"\n",
        "y=\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp-PmVUP9N9c",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cqmnbPGdMipR",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import time \n",
        "\n",
        "def set_seed(seed,ngpu):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if ngpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "      \n",
        "set_seed(42,torch.cuda.device_count())\n",
        "#remove later\n",
        "\n",
        "def trainData(tdataloader,tedataloader):\n",
        "  epochs=4\n",
        "  lossList=[]\n",
        "  max_grad_norm=1.0\n",
        "  for e in range(0, epochs):\n",
        "      print(\"Start Epoch Number\",(e + 1))\n",
        "      print(\"Start Training\")\n",
        "      if device.type==\"cpu\":\n",
        "       model.to(device)\n",
        "       map_location='cpu'\n",
        "      else:\n",
        "        model.cuda()\n",
        "        map_location=lambda storage, loc: storage.cuda()\n",
        "      checkpoint = torch.load('/content/drive/My Drive/EnglishData/bertenglish.pth.tar',map_location=map_location)\n",
        "      model.load_state_dict(checkpoint['state_dict'])\n",
        "  \n",
        "      #Amount of time taken for training\n",
        "      t1 = time.time()\n",
        "      tr_loss, logging_loss = 0.0, 0.0\n",
        "      model.train()\n",
        "      tsteps=0\n",
        "      for step, batch in enumerate(tdataloader):\n",
        "          if step % 50 == 0 and not step == 0:\n",
        "              print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "          model.zero_grad()        \n",
        "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
        "          loss = outputs[0]\n",
        "          loss.backward()\n",
        "          tr_loss += loss.item()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "          tsteps+=1\n",
        "          optimizer.step()\n",
        "          sch.step()\n",
        "      a_tr_loss = tr_loss /(tsteps)               \n",
        "      lossList.append(a_tr_loss)\n",
        "      print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
        "      t2=time.time()\n",
        "      print(\"  Training one epoch time taken\",t2-t1)\n",
        "      print(\" Validation starts here \")\n",
        "      t1 = time.time()\n",
        "      model.eval()\n",
        "      eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "      eval_f1=0\n",
        "      eval_acc=0\n",
        "      \n",
        "      for batch_idx, data in enumerate(tedataloader):\n",
        "          \n",
        "          batch = tuple(t.to(device) for t in data)            \n",
        "          inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "          with torch.no_grad():        \n",
        "             outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
        "          logits = outputs[0]\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
        "          tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
        "          eval_f1 = eval_f1+tmpf1score\n",
        "          eval_acc=eval_acc+tmpaccscore\n",
        "          nb_eval_steps += 1\n",
        "          #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
        "          #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
        "      torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/bertenglish.pth.tar')\n",
        "\n",
        "      print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
        "      print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
        "      t2=time.time()\n",
        "      print(\"  Validating one epoch time taken \",t2-t1)\n",
        "      \n",
        "    \n",
        "  print(\"ALL DONE!!!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVLBZueyOjA_",
        "colab_type": "code",
        "outputId": "4d666e8b-b203-46dd-eb6f-2442425e6337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d2e828c9e86c443bbd4564fc4d733b70",
            "f70718dcad60489eb4cb61565a556a15",
            "ff88f159ed694502bb21fcd7a830240e",
            "8882de0fe4884f929e2c9fb6c70ddc86",
            "48f15496d6164a06bd41dee4d9872b85",
            "519178e4085f4a01ae154338b39dcb57",
            "488a63449bff4e4ba2ed61765e784165",
            "3af5dde91e754186a1bfaa1a5ca628ab"
          ]
        }
      },
      "source": [
        "#xytrain=[x_train[:8000],y_train[:8000]]\\\n",
        "MAXLENGTH=giveIds(x_train[0])\n",
        "xytrain=[x_train,y_train]\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "tdataset = EnglishTrainDataset(xytrain)\n",
        "tsampler=RandomSampler(tdataset)\n",
        "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "      \n",
        "epochs=4\n",
        "total_steps=len(tdataloader)*epochs\n",
        "sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
        "\n",
        "#xytest=[x_test[:8000],y_test[:8000]]\n",
        "xytest=[x_test,y_test]\n",
        "tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "tedataset = EnglishTestDataset(xytest) \n",
        "tesampler=RandomSampler(tedataset)\n",
        "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
        "trainData(tdataloader,tedataloader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2e828c9e86c443bbd4564fc4d733b70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start Epoch Number 1\n",
            "Start Training\n",
            " The training loss incured is  0.661\n",
            "  Training one epoch time taken 0.7199721336364746\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0]\n",
            "  F1 score: 0.421\n",
            "  Accuracy score: 0.740\n",
            "  Validating one epoch time taken  1.3960075378417969\n",
            "Start Epoch Number 2\n",
            "Start Training\n",
            " The training loss incured is  0.537\n",
            "  Training one epoch time taken 0.4642632007598877\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            "  F1 score: 0.438\n",
            "  Accuracy score: 0.781\n",
            "  Validating one epoch time taken  1.4376983642578125\n",
            "Start Epoch Number 3\n",
            "Start Training\n",
            " The training loss incured is  0.543\n",
            "  Training one epoch time taken 0.47426581382751465\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  F1 score: 0.443\n",
            "  Accuracy score: 0.802\n",
            "  Validating one epoch time taken  4.482619524002075\n",
            "Start Epoch Number 4\n",
            "Start Training\n",
            " The training loss incured is  0.525\n",
            "  Training one epoch time taken 0.47497034072875977\n",
            " Validation starts here \n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "labels Flattened [0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1]\n",
            "  F1 score: 0.435\n",
            "  Accuracy score: 0.771\n",
            "  Validating one epoch time taken  9.03171443939209\n",
            "ALL DONE!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlwyxaioYiGr",
        "colab_type": "code",
        "outputId": "c8e89cce-67f5-4873-ab3e-35432cc84f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''nlists=2\n",
        "last=16000\n",
        "size_of_itertrain=8000//nlists\n",
        "size_of_itertest=8000//nlists\n",
        "#print(size_of_itertrain)\n",
        "for  i in range(nlists+1):\n",
        "      \n",
        "      end=(i+1)*size_of_itertrain\n",
        "      if(last<end):\n",
        "        end=last\n",
        "      xytrain=[x_train[i*size_of_itertrain:end],y_train[i*size_of_itertrain:end]]\n",
        "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "      tdataset = EnglishTrainDataset(xytrain)\n",
        "      tsampler=RandomSampler(tdataset)\n",
        "      tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
        "      \n",
        "      epochs=2\n",
        "      total_steps=len(tdataloader)*epochs\n",
        "      sch=get_linear_schedule_with_warmup(optimizer,\n",
        "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
        "\n",
        "      end=(i+1)*size_of_itertest\n",
        "      if(last<end):\n",
        "        end=last \n",
        "    \n",
        "      xytest=[x_test[i*size_of_itertest:end],y_test[i*size_of_itertest:end]]\n",
        "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "      tedataset = EnglishTestDataset(xytest)  \n",
        "      tesampler=RandomSampler(tedataset)\n",
        "      tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
        "\n",
        "      trainData(tdataloader,tedataloader)\n",
        "\n",
        "      \n",
        "y_test_pytorch=torch.tensor(xytest[1][index])'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"nlists=2\\nlast=16000\\nsize_of_itertrain=8000//nlists\\nsize_of_itertest=8000//nlists\\n#print(size_of_itertrain)\\nfor  i in range(nlists+1):\\n      \\n      end=(i+1)*size_of_itertrain\\n      if(last<end):\\n        end=last\\n      xytrain=[x_train[i*size_of_itertrain:end],y_train[i*size_of_itertrain:end]]\\n      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\\n      tdataset = EnglishTrainDataset(xytrain)\\n      tsampler=RandomSampler(tdataset)\\n      tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\\n      \\n      epochs=2\\n      total_steps=len(tdataloader)*epochs\\n      sch=get_linear_schedule_with_warmup(optimizer,\\n                                    num_warmup_steps=0,num_training_steps=total_steps)\\n\\n      end=(i+1)*size_of_itertest\\n      if(last<end):\\n        end=last \\n    \\n      xytest=[x_test[i*size_of_itertest:end],y_test[i*size_of_itertest:end]]\\n      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\\n      tedataset = EnglishTestDataset(xytest)  \\n      tesampler=RandomSampler(tedataset)\\n      tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\\n\\n      trainData(tdataloader,tedataloader)\\n\\n      \\ny_test_pytorch=torch.tensor(xytest[1][index])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPhVU_w-iZmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_test_pytorch=torch.tensor(xytest[1][40])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QXQMvZxpzC",
        "colab_type": "code",
        "outputId": "23f0dd9b-a472-4e88-9500-18f47165437e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#len(xytest[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0WX9KRpvDvR",
        "colab_type": "code",
        "outputId": "fe468f59-b3d6-4d19-995e-545b30d5bd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#len(xytest[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rWdrUSxJIV",
        "colab_type": "code",
        "outputId": "b81ddd54-3424-465a-f4b0-e2697dd0eb25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#len(xytrain[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVU_iFtVa42a",
        "colab_type": "code",
        "outputId": "0ad4946d-4edc-46c3-e2dc-6075fea79f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "MAXLENGTH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-upACWh-MuWi",
        "colab_type": "code",
        "outputId": "3876eaed-ee36-4c7a-b9c9-d6f69a121680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "print(\"MAXLENGTH\",MAXLENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAXLENGTH 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWgpgNrIOAnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}