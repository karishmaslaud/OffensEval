{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "609cfb6f-cbec-4fb1-8ef9-b28301f90016"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ej4Vt62W39qJ"
   },
   "outputs": [],
   "source": [
    "#Custom Data set and Data loader has  been adapted and inspired from \n",
    "#Michael Sugimura,Github Repository:https://github.com/sugi-chan/custom_bert_pipeline\n",
    "#Roberta based fine tuning adapted and inspired from:Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning Tutorial with PyTorch. Retrieved from http://www.mccormickml.com\n",
    "#for all references refer README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "46Fpl7WYdNu0",
    "outputId": "ea82f607-c979-4e79-bd87-1428541a7c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "\n",
    "from transformers import AdamW#, WarmupLinearSchedule\n",
    "\n",
    "#from utils import (convert_examples_to_features,\n",
    "                        #output_modes, processors)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1nweMDxcWic"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "8ca2b39d-7216-4dac-8a77-221864ce2811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  gpuname=\"\"\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  n_gpu=torch.cuda.device_count()\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "a99bf5f0-7529-4c3a-9af0-22be3829a373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#conversion to float code taken as it is from the answer https://stackoverflow.com/a/39298571 to https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "8bLBKEKprjzq",
    "outputId": "8d3c7766-b48d-48aa-f382-e3de6ae8118d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata1 = pd.read_csv(\"task_b_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata1=englishdata1'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "headers=['id','text','average','std']\n",
    "englishdata1 = pd.read_csv(\"task_b_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
    "englishdata1=englishdata1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ayt4_mQnr5n7",
    "outputId": "193505c8-bd7d-4e80-c828-52d4af99527f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata2 = pd.read_csv(\"task_a_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata2=englishdata2'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "headers=['id','text','average','std']\n",
    "englishdata2 = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
    "englishdata2=englishdata2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uXSsl4DrvPa"
   },
   "outputs": [],
   "source": [
    "#len(englishdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXDd24Fxry8c"
   },
   "outputs": [],
   "source": [
    "#len(englishdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
    "englishdata = pd.read_csv(\"olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
    "englishdata=englishdata[['id','tweet','subtask_a']]\n",
    "englishdata=englishdata[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKDwFMQdrusQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ucAFIEswSPcQ",
    "outputId": "21c0eed8-78d8-4f1a-8ece-e15c684db65f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\\ndef convertToFloat(val):\\n    if not val:\\n        return 0    \\n    try:\\n        return np.float64(val)\\n    except:        \\n        return np.float64(0)\\n\\n\\n#GET THE DATA FROM THE PANDAS FRAME\\nheaders=[\\'id\\',\\'text\\',\\'average\\',\\'std\\']\\nenglishdata = pd.read_csv(\"task_a_distant.tsv\", delimiter=\\'\\t\\',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\\nenglishdata=englishdata[:100]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# conversion to float taken from https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
    "def convertToFloat(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.float64(val)\n",
    "    except:        \n",
    "        return np.float64(0)\n",
    "\n",
    "\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','text','average','std']\n",
    "englishdata = pd.read_csv(\"task_a_distant.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average\":convertToFloat,\"std\":convertToFloat})\n",
    "englishdata=englishdata[:100]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "leV4AIvO56Jp",
    "outputId": "68d8d3f1-889d-4e6c-ed68-5277c9f1a008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13240"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(englishdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p43UBV5YZLjE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "B9dY5nerCi3z",
    "outputId": "3584bb33-5ca8-4436-a5ea-132df4b29bc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a\n",
       "1  86426  @USER She should ask a few native Americans wh...       OFF\n",
       "2  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF\n",
       "3  16820  Amazon is investigating Chinese employees who ...       NOT\n",
       "4  62688  @USER Someone should'veTaken\" this piece of sh...       OFF\n",
       "5  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "85xVmaYRHFab",
    "outputId": "97779691-dc23-4dc7-b8ca-1bd3b374ab68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\\nexport_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\\nprint (englishtrain.head())\\n#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\\nexport_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\\nprint (englishtest.head())\""
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''englishtrain,englishtest= train_test_split(englishdata, test_size=0.2, random_state=42)\n",
    "export_csv = englishtrain.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TrainFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtrain.head())\n",
    "#englishtest,englishpredict= train_test_split(englishtemp, test_size=0.5, random_state=42)\n",
    "export_csv = englishtest.to_csv ('/content/drive/My Drive/EnglishData/olidlearn/TestFileEnglish.tsv', index = None, header=True)\n",
    "print (englishtest.head())'''\n",
    "#export_csv = englishpredict.to_csv ('/content/drive/My Drive/EnglishData/predictFileEnglish.csv', index = None, header=True)\n",
    "#print (englishpredict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayHNHPM56TTg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLXURnA5UefR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWe6eF21Ue-9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zn8dOMH10Cla",
    "outputId": "fa97d17c-f392-46f9-d6af-73726676a27e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ids_of_sentence=[]\\nids_of_sentence_words=[]\\nattention_masks=[]\\n\\ndef giveIds(sentence):\\n  maxlength=0\\n  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\\n  for t in sentence:\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n  return maxlength\""
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "\n",
    "def giveIds(sentence):\n",
    "  maxlength=0\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "  return maxlength'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUxfcUCbNGXS"
   },
   "outputs": [],
   "source": [
    "#max_length="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qZWdmK_CMiop",
    "outputId": "a3936337-d98d-4903-c1cb-8bfd84eb288b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMeqzRH7LS5Q"
   },
   "outputs": [],
   "source": [
    "dfnumpy=englishdata.to_numpy()\n",
    "X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ad-sjNy_ZuDS",
    "outputId": "efe71b27-e9da-478e-9d57-c566bcd2470c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OEIjuTJkZklF",
    "outputId": "c3f359a2-1344-4cc9-cc91-8a8a0f3830e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "zlITxE9CZwns",
    "outputId": "b2bbddfa-795c-469c-fe40-783b46f11715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Removing consecutive duplicate words code taken as it is from the answer https://stackoverflow.com/a/57424859 to https://stackoverflow.com/questions/57424661/how-to-efficiently-remove-consecutive-duplicate-words-or-phrases-in-a-string/<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DirGcyCdZzhW"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "stopwords=set(stopwords.words('english'))\n",
    "def preprocessinglib(arrt):\n",
    "    ans =[]\n",
    "    for txt in arrt:\n",
    "        txt1=emoji.demojize(txt)\n",
    "        tokens=tknzr.tokenize(txt1)\n",
    "        ctokens=[]\n",
    "        for t in tokens:\n",
    "          if  t not in stopwords and t not in string.punctuation :\n",
    "            ctokens.append(t)\n",
    "        clean_s = ' '.join(ctokens)\n",
    "        ans.append(clean_s)\n",
    "               \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgcU1eFjbHDk"
   },
   "outputs": [],
   "source": [
    "preprocessedTweets=preprocessinglib(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzsKG85LBeb-"
   },
   "outputs": [],
   "source": [
    "#preprocessedTweets=X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwiry_2MeRzI"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/preprocess.txt', 'w') as f:\n",
    "  f.write(str(preprocessedTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_NKcxDqLOGX"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "preprocessedTweets,y=shuffle(preprocessedTweets,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_KQpestKlz4"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_gpr92MXKnq1",
    "outputId": "ca380716-84af-4c4b-952c-a259f6ff3370"
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7CXlx4H41X-0",
    "outputId": "a7d7ae39-abdd-47f6-d929-45e657340aea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train,y_train=readDataTrain()\\nx_test,y_test=readDataTest()\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_train,y_train=readDataTrain()\n",
    "x_test,y_test=readDataTest()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DXkHq0Q0K2Yk",
    "outputId": "b642dc1d-644a-4ae4-f530-9611ee2508bd"
   },
   "outputs": [],
   "source": [
    "print(preprocessedTweets[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "BSZGqjvlBIDa",
    "outputId": "041cb777-ec65-4669-dfca-a93aae2a1456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592, 1)\n",
      "(2648, 1)\n",
      "(10592,)\n",
      "['NOT' 'OFF']\n",
      "['NOT' 'OFF']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_predict.shape)\n",
    "yTrain=le.fit_transform(y_train.flatten())\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "yTest=le.fit_transform(y_test.flatten())\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "jMCPsKyZBK7f",
    "outputId": "bd5fd940-b54d-4b71-d9fb-9213c5f632f8"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-cdebe1299bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmG6tesd1euz"
   },
   "outputs": [],
   "source": [
    "###IMPORTANT\n",
    "'''xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
    "x_test_pytorch=torch.tensor(xtest)\n",
    "y_test_pytorch=torch.tensor(y_test)\n",
    "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
    "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
    "tesampler=RandomSampler(tedata)\n",
    "bsize=64\n",
    "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
    "print(len(xtest))\n",
    "print(len(y_test))\n",
    "len(x_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZbZxkgcBhfag",
    "outputId": "33c42819-6f62-4344-ba42-c9dabcbae3d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification as bfsc,AdamW,RobertaConfig\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "\n",
    "config = RobertaConfig.from_pretrained('roberta-base',output_attentions=False,output_hidden_states=False,num_labels=2)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification(config)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPr_Sj12LY-y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDzvjKyWMio7"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQQ5__z5Mio-"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"beta\",\"LayerNorm.weight\",\"gamma\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frZAYslgMipB"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=3e-5,eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "au4tTkrfMipE",
    "outputId": "3cabf033-141c-40c5-c5b6-3e94e830b873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSdEEzMJMipH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"Predictions Argmax\",predictionArgmax)\n",
    "  print(\"labels Flattened\",labelsFlattend)   \n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cu3euWbs9MM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "owfS8MEZ-oJf",
    "outputId": "33d113fe-9354-4aee-d390-650b36bc010c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxtest,x_test_mask=giveIds(x_test.flatten(),y_test)\\nx_test_pytorch=torch.tensor(xtest)\\ny_test_pytorch=torch.tensor(y_test)\\nx_test_mask_pytorch=torch.tensor(x_test_mask)\\ntedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\\ntesampler=RandomSampler(tedata)\\nbsize=64\\ntedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\\nprint(len(xtest))\\nprint(len(y_test))\\nlen(x_train)\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###IMPORTANT\n",
    "'''\n",
    "xtest,x_test_mask=giveIds(x_test.flatten(),y_test)\n",
    "x_test_pytorch=torch.tensor(xtest)\n",
    "y_test_pytorch=torch.tensor(y_test)\n",
    "x_test_mask_pytorch=torch.tensor(x_test_mask)\n",
    "tedata=TensorDataset(x_test_pytorch,x_test_mask_pytorch,y_test_pytorch)\n",
    "tesampler=RandomSampler(tedata)\n",
    "bsize=64\n",
    "tedataloader=DataLoader(tedata,sampler=tesampler,batch_size=bsize)\n",
    "print(len(xtest))\n",
    "print(len(y_test))\n",
    "len(x_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTEaGYn-AIWQ"
   },
   "outputs": [],
   "source": [
    "#z=len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBcEMw2SRV_7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwqSDP2KL71z"
   },
   "outputs": [],
   "source": [
    "MAXLENGTH=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTurXRofNATj",
    "outputId": "bb793eb1-7627-4881-d205-97dc06899d3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nz=0;\\nfor batch_idx, data in enumerate(tdataloader): \\n  if z==100:\\n    break;\\n  z=z+1;'"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnglishTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(self.xytrain[0][index])\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        #attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        \n",
    "        return x_train_pytorch,y_train_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])\n",
    " \n",
    "\n",
    "'''\n",
    "z=0;\n",
    "for batch_idx, data in enumerate(tdataloader): \n",
    "  if z==100:\n",
    "    break;\n",
    "  z=z+1;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U47_yavmOa7S"
   },
   "outputs": [],
   "source": [
    "class EnglishTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=MAXLENGTH\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(self.xytest[0][index])\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        #assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        #attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        #x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VObEL94h-bU8"
   },
   "outputs": [],
   "source": [
    "#xytrain=[x_train[:8000],y_train[:8000]]\\\n",
    "#MAXLENGTH=giveIds(x_train[0])\n",
    "xytrain=[x_train,yTrain]\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tdataset = EnglishTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t753LP5zOq44"
   },
   "outputs": [],
   "source": [
    "\n",
    "#xytest=[x_test[:8000],y_test[:8000]]\n",
    "xytest=[x_test,yTest]\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tedataset = EnglishTestDataset(xytest) \n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
    "#trainData(tdataloader,tedataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH_J0p88PWuk"
   },
   "outputs": [],
   "source": [
    "#tokenized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udjp1U9q9xaI"
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs=4\n",
    "total_steps=len(tdataloader)*epochs\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rPrZ3_M-LZx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kp-PmVUP9N9c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "cqmnbPGdMipR",
    "outputId": "5ccf7c75-3abd-46aa-d5b5-2589f53b4b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch Number 1\n",
      "Start Training\n",
      "Batch Completed  50  of  331.    Elapsed time is  11.926927328109741\n",
      "Batch Completed  100  of  331.    Elapsed time is  23.670315742492676\n",
      "Batch Completed  150  of  331.    Elapsed time is  35.37080717086792\n",
      "Batch Completed  200  of  331.    Elapsed time is  47.216551303863525\n",
      "Batch Completed  250  of  331.    Elapsed time is  59.03331995010376\n",
      "Batch Completed  300  of  331.    Elapsed time is  70.74726557731628\n",
      " The training loss incured is  0.652\n",
      "  Training one epoch time taken 78.01407885551453\n",
      " Validation starts here \n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0]\n",
      "Predictions Argmax [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "labels Flattened [0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=4\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    \n",
    "\n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"labels\": batch[1]}\n",
    "        model.zero_grad()     \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None, labels=inputs[\"labels\"])\n",
    "        #print(type(outputs))\n",
    "        loss, prediction_scores = outputs[:2]\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "    \n",
    "    for batch_idx, data in enumerate(tedataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in data)            \n",
    "        inputs = {\"input_ids\": batch[0], \"labels\": batch[1]}\n",
    "        with torch.no_grad():        \n",
    "           outputs = model(inputs[\"input_ids\"],token_type_ids=None)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "    #torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/EnglishData/robertaenglish.pth.tar')\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "      \n",
    "    \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0CcvhMPDUy6"
   },
   "outputs": [],
   "source": [
    "print(type(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVLBZueyOjA_"
   },
   "outputs": [],
   "source": [
    "print(outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlwyxaioYiGr"
   },
   "outputs": [],
   "source": [
    "'''nlists=2\n",
    "last=16000\n",
    "size_of_itertrain=8000//nlists\n",
    "size_of_itertest=8000//nlists\n",
    "#print(size_of_itertrain)\n",
    "for  i in range(nlists+1):\n",
    "      \n",
    "      end=(i+1)*size_of_itertrain\n",
    "      if(last<end):\n",
    "        end=last\n",
    "      xytrain=[x_train[i*size_of_itertrain:end],y_train[i*size_of_itertrain:end]]\n",
    "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "      tdataset = EnglishTrainDataset(xytrain)\n",
    "      tsampler=RandomSampler(tdataset)\n",
    "      tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "      \n",
    "      epochs=2\n",
    "      total_steps=len(tdataloader)*epochs\n",
    "      sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)\n",
    "\n",
    "      end=(i+1)*size_of_itertest\n",
    "      if(last<end):\n",
    "        end=last \n",
    "    \n",
    "      xytest=[x_test[i*size_of_itertest:end],y_test[i*size_of_itertest:end]]\n",
    "      tokenizer=bertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "      tedataset = EnglishTestDataset(xytest)  \n",
    "      tesampler=RandomSampler(tedataset)\n",
    "      tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)\n",
    "\n",
    "      trainData(tdataloader,tedataloader)\n",
    "\n",
    "      \n",
    "y_test_pytorch=torch.tensor(xytest[1][index])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPhVU_w-iZmB"
   },
   "outputs": [],
   "source": [
    "#y_test_pytorch=torch.tensor(xytest[1][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7QXQMvZxpzC"
   },
   "outputs": [],
   "source": [
    "#len(xytest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0WX9KRpvDvR"
   },
   "outputs": [],
   "source": [
    "#len(xytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4rWdrUSxJIV"
   },
   "outputs": [],
   "source": [
    "#len(xytrain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVU_iFtVa42a"
   },
   "outputs": [],
   "source": [
    "\n",
    "MAXLENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-upACWh-MuWi"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"MAXLENGTH\",MAXLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWgpgNrIOAnX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "RobertaEnglishFInalTosubmit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
