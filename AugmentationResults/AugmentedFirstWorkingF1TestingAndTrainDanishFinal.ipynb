{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0-z91UlfiRk"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "a209a832-fc3d-4c7f-b3f4-40285a48dea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  raise(SystemError('GPU device not found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "ea036ebd-4531-4cfb-efb8-6f01ac877e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU DEVICES available \n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "buldkQJQiKYI",
    "outputId": "48b5e932-bd05-46cd-ad8f-20035b0df477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 26.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 20kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 30kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 61kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 71kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 81kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 92kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 102kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 112kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 122kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 133kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 143kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 153kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 163kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 174kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 184kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 194kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 204kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 215kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 225kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 235kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 245kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 256kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 266kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 276kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 286kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 296kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 307kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 317kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 327kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 337kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 348kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 358kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 368kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 378kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 389kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 399kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 409kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 419kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 430kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 440kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 450kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 460kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 471kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 481kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 491kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 501kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 512kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 522kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 532kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 542kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 552kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 563kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 573kB 5.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 26.3MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 20kB 33.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 30kB 39.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 40kB 44.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 51kB 47.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 61kB 50.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 71kB 52.9MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 81kB 54.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 92kB 56.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 102kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 112kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 122kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 133kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 143kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 153kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 163kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 174kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 184kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 194kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 204kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 215kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 225kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 235kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 245kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 256kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 266kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 276kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 286kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 296kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 307kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 317kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 327kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 337kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 348kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 358kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 368kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 378kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 389kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 399kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 409kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 419kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 430kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 440kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 450kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 460kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 471kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 481kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 491kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 501kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 512kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 522kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 532kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 542kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 552kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 563kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 573kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 583kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 593kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 604kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 614kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 624kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 634kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 645kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 655kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 665kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 675kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 686kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 696kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 706kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 716kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 727kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 737kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 747kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 757kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 768kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 778kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 788kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 798kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 808kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 819kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 829kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 839kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 849kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 860kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 870kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 880kB 58.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 890kB 58.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 60.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 51.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=0d17ae07f23b4b057520df799906f90cbcbe1d30142fffd4658fb68482ffdace\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "c4c31187-8dc8-4c1a-e7de-807d6efd4920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_byFfpTf1D9"
   },
   "source": [
    "#Custom Data set and Data loader has been inspired from \n",
    "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0iCZDHmlWSjY"
   },
   "outputs": [],
   "source": [
    "!unzip -P yourpassword -qq '/content/drive/My Drive/DanishData/Danish.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rXVZz7uUsAg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "ucAFIEswSPcQ",
    "outputId": "df2f7b7d-1f57-48e8-e8e9-0ca5b7f33bbc"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-124-8365b84a2416>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    data=greekdata[1:]/\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a']\n",
    "greekdata = pd.read_csv(\"Danish/offenseval-da-training-v1.tsv\", delimiter='\\t',names=headers)\n",
    "data=greekdata[1:]/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "YzBkRhE7Lx9H",
    "outputId": "dac22629-f8e0-49cb-a78f-0d52b60876b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  ... Unnamed: 0\n",
      "0  3131  ...        NaN\n",
      "1   711  ...        NaN\n",
      "2  2500  ...        NaN\n",
      "3  2678  ...        NaN\n",
      "4   784  ...        NaN\n",
      "\n",
      "[5 rows x 4 columns]\n",
      "2960\n"
     ]
    }
   ],
   "source": [
    "data=data[:2960]\n",
    "print(data.head())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "hXEB_OzuL4xU",
    "outputId": "8f9ad613-2df0-434a-8285-257c35a97f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       OFF\n",
      "1       OFF\n",
      "2       OFF\n",
      "3       OFF\n",
      "4       OFF\n",
      "       ... \n",
      "1489    OFF\n",
      "1490    OFF\n",
      "1491    OFF\n",
      "1492    OFF\n",
      "1493    OFF\n",
      "Name: subtask_a, Length: 1494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "gOFFdata = pd.read_csv(\"/content/drive/My Drive/translated/TranslatedToDanishFinal.csv\", delimiter=',')\n",
    "print(gOFFdata['subtask_a'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "n9k-_jD86ok4",
    "outputId": "203fad6a-f21a-4ad5-e0db-5b65ab6c8d88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER @USER Gå hjem, du er fuld !!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER En person burde have taget &amp;quot;dette s...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER @USER Åh nej! Hård lort.</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Canada har ikke brug for endnu et CUCK! ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>77444</td>\n",
       "      <td>@USER du er en liggende korrupt forræder !!! I...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>4377</td>\n",
       "      <td>4378</td>\n",
       "      <td>86690</td>\n",
       "      <td>@USER Gå til Iran, hvor du hører til dum idiot.</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>4379</td>\n",
       "      <td>4380</td>\n",
       "      <td>58201</td>\n",
       "      <td>@USER @USER @USER @USER Du skal vide bedre at ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>4381</td>\n",
       "      <td>4382</td>\n",
       "      <td>12178</td>\n",
       "      <td>@USER denne jag off ref Tony Corrente har brug...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>4395</td>\n",
       "      <td>4396</td>\n",
       "      <td>96924</td>\n",
       "      <td>@USER @USER @USER @USER Løgnere som Antifa-tvi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>4397</td>\n",
       "      <td>4398</td>\n",
       "      <td>49763</td>\n",
       "      <td>@USER Og hvorfor rapportere dette affald. Vi g...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ...  subtask_a\n",
       "0              0  ...        OFF\n",
       "1              1  ...        OFF\n",
       "2              3  ...        OFF\n",
       "3              5  ...        OFF\n",
       "4              6  ...        OFF\n",
       "...          ...  ...        ...\n",
       "1489        4377  ...        OFF\n",
       "1490        4379  ...        OFF\n",
       "1491        4381  ...        OFF\n",
       "1492        4395  ...        OFF\n",
       "1493        4397  ...        OFF\n",
       "\n",
       "[1494 rows x 5 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gOFFdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fslJMKOWPSnW"
   },
   "outputs": [],
   "source": [
    "data=pd.concat([data, gOFFdata], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bnhbuYtZL0zO",
    "outputId": "60c56c96-dae5-4cce-86bd-66ff41aafd2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT', 'NOT', 'OFF', ..., 'OFF', 'OFF', 'OFF'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_numpy()[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXNuys5ZaNOQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "dfnumpy=data.to_numpy();\n",
    "x=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3z7Ias8STXAt",
    "outputId": "7193a02b-e366-40a4-8c20-26d62d76e044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4454\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U89nu4PBSSZD",
    "outputId": "eecd1a3c-03c8-4b81-c0d0-84a45071cbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY5vGRQYdq5F"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ft1(l):\n",
    "    a = re.split('|\\]|\\[|\\)|\\(|; |,|\\*|\\n',l)\n",
    "    li = []\n",
    "    for t in a:\n",
    "        li.append(t.strip(' ,')) \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjuO50YSOZ0q"
   },
   "outputs": [],
   "source": [
    "#Removing duplicate words inspired from https://stackoverflow.com/questions/57424661/how-to-efficiently-remove-consecutive-duplicate-words-or-phrases-in-a-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d_p-6MzMclO"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import emoji\n",
    "import string\n",
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "def preprocessinglib(arrt):\n",
    "    ans =[]\n",
    "    for txt in arrt:\n",
    "        txt1=emoji.demojize(txt)\n",
    "        unique_words = dict.fromkeys(txt1.split(\" \"))\n",
    "        txt2=' '.join(unique_words)\n",
    "        ans.append(ft1(txt2))\n",
    "               \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XyUqBmmpNAXp"
   },
   "outputs": [],
   "source": [
    "arrt=x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ERQ4T8MgNDjn",
    "outputId": "c5e752ec-2013-4590-c21c-d98904c3c4db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "allTokens=preprocessinglib(arrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2X-eKHng4jUh"
   },
   "outputs": [],
   "source": [
    "#len(allTokens)\n",
    "preprocessedTweets=allTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZLNpEq1VVUH"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3TImBZYl4wih",
    "outputId": "14cf883a-890d-4b2d-8985-e355855ecb50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@USER Hun siger, at hun er dybt religiøs &quot;... sagde ikke&quot; hvilken &quot;religion ... satanister meget religiøse Fred&quot;'], ['Prol'], ['Lel hvor har du fundet den? Det er vidst det jeg ville kalde et tamt meme.'], ['@USER du er en beskidt cum dumpster'], ['@USER Åh herregud. De er så skide søde.']]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessedTweets[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iFSxRGBU-jXr",
    "outputId": "0a36310b-9999-4ed0-cabf-bc798fd184f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "00411c590e2d40d6abe14497d6e9246e",
      "23a6e3182e504edcbaaca49f599ed41a",
      "6638a4c105d44e6898cc39018fbe0e4c",
      "ab4da3fbeec84b23a7d204191e9f077b",
      "7fb9a96f16c34ac8a56d25e00073f167",
      "d54f1b884b314107b066cd3fd2349980",
      "a5844159318b43799bc49ed6311e1087",
      "9d2fec9666d34df081e6877bfc380687"
     ]
    },
    "colab_type": "code",
    "id": "utvnzPv3Ar4O",
    "outputId": "ae40092c-b9a6-4972-c534-a694ecf7438d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00411c590e2d40d6abe14497d6e9246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f2S1fYRTXYi"
   },
   "outputs": [],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "def giveIds(sentence,y_):\n",
    "  ids_of_sentence=[]\n",
    "  ids_of_sentence_words=[]\n",
    "  attention_masks=[]\n",
    "  maxlength=0\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "  print(maxlength)\n",
    "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
    "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
    "  #print(len(attention_masks))\n",
    "  #print(len(ids_of_sentence_words))\n",
    "  return ids_of_sentence_words,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fh02lGbz79_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIn1L3EaG_Ts"
   },
   "outputs": [],
   "source": [
    "sentence_train, sentence_test, y_train, y_test = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42)\n",
    "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQDZFAOzcNYX"
   },
   "outputs": [],
   "source": [
    "##do this at the time of training only \n",
    "#sentence_train, sentence_test1, y_train, y_test1 = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42) only this for code submission\n",
    "#sentence_test,sentence_predict, y_test,y_predict = train_test_split(sentence_test1,y_test1, test_size=0.5, random_state=42)\n",
    "#x_predict_mask,_,_,_=train_test_split(x_test_mask,y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1Z4zlYAJRCb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xA_qRN1yU04y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "v3cQT-_ejd9R",
    "outputId": "c193fb6a-8a92-4748-f8d3-761e2e2fe449"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NOT'],\n",
       "       ['OFF'],\n",
       "       ['NOT'],\n",
       "       ...,\n",
       "       ['OFF'],\n",
       "       ['OFF'],\n",
       "       ['NOT']], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "7CYsPFfkdWL9",
    "outputId": "9fa12352-a6f5-4c9e-9ff2-ffeb877717a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4758, 1)\n",
      "(1190, 1)\n",
      "(4758,)\n",
      "['NOT' 'OFF']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "yTrain=le.fit_transform(y_train.flatten())\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwrbFDiqjh1K"
   },
   "outputs": [],
   "source": [
    "yTest=le.transform(y_test.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "17cc-80ujmKS",
    "outputId": "71459a63-5f88-4739-91ad-03349c7e7075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOT', 'OFF'}"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4cVrhEIdd2FL",
    "outputId": "6d596610-7055-4447-a867-259c3a31ac3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFcDGmeNVbKd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=64\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MRzkZ70fqRJ"
   },
   "outputs": [],
   "source": [
    "#from torch.utils.data import Dataset\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=64\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength-2]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt6HvS5-dpok"
   },
   "outputs": [],
   "source": [
    "xytrain=[sentence_train,yTrain]\n",
    "tdataset = GreekTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGJiYjC1fb1V"
   },
   "outputs": [],
   "source": [
    "xytest=[sentence_test,yTest]\n",
    "tedataset = GreekTestDataset(xytest)\n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1194a37289a24b7dba376496287be4e9",
      "444f9cf820d840cfb8c204141a10ae9e",
      "ca711bd515db4b4ab2243dd2be1bb37d",
      "883a63f02c114754b9e6476824f344ff",
      "edd5e4f623d44694beb7384a0b6aabef",
      "c5163060de664a2aa519d7faa6f17b3c",
      "b62eec3e85c24e7698e0533c57e95e5f",
      "8e2346647aa7463ca0e624b8d975cd67",
      "4778600e3d45425d917b7fcefb413fe8",
      "a0f4f685c7e54a2694ccd8342899740d",
      "29bafd2f260c405187ecbda0c8dbed27",
      "c31fb1d3edbd441ba045513bc5529908",
      "ef615d79414e4f208f7c5f5e7ec8f0b2",
      "9aad37766c0b4a08b5d3e1a6cdfd27b0",
      "81c4ad4dbdd342c0bc7f9cd5bbb7126c",
      "fba02d25bbff4b539f78bb7038f2b218"
     ]
    },
    "colab_type": "code",
    "id": "2bOBLycdL0lc",
    "outputId": "87d580b3-6da5-4f13-f7c8-4c0ae390c015"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1194a37289a24b7dba376496287be4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=625, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4778600e3d45425d917b7fcefb413fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JyH9yvdIO208",
    "outputId": "8af406c9-a6ff-4f36-cb01-804716f1813c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 168,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/DanishData/augdanish.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/DanishData/augdanish.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iF4guWRdOTS4"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKOeqrn-jopN"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RlThDORmMrf"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)\n",
    "#############CAN CHANGE LEARNING RATE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FRiX25tlMdG"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs=4\n",
    "total_steps=len(tdataloader)*epochs\n",
    "\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6LNSaNZpKVT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    "  print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksKBAgRkViOV"
   },
   "source": [
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "#Also based on the following tutorials\n",
    "#https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "brS_TJmHJs0I",
    "outputId": "c91ee4fc-146d-4f66-c4d7-ee147f7b1448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch Number 1\n",
      "Start Training\n",
      "Batch Completed  50  of  149.    Elapsed time is  11.724251508712769\n",
      "Batch Completed  100  of  149.    Elapsed time is  23.150556802749634\n",
      " The training loss incured is  0.293\n",
      "  Training one epoch time taken 34.294397592544556\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1]\n",
      "labelsFlattend [1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1]\n",
      "predictionArgmax [1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0]\n",
      "labelsFlattend [1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "predictionArgmax [0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1]\n",
      "labelsFlattend [0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1]\n",
      "predictionArgmax [0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0]\n",
      "labelsFlattend [1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1]\n",
      "labelsFlattend [0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1]\n",
      "predictionArgmax [0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 1]\n",
      "labelsFlattend [0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1]\n",
      "predictionArgmax [1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      "labelsFlattend [1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 1]\n",
      "labelsFlattend [1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1]\n",
      "predictionArgmax [0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1]\n",
      "labelsFlattend [0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1]\n",
      "predictionArgmax [0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0]\n",
      "predictionArgmax [1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0]\n",
      "labelsFlattend [1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1]\n",
      "labelsFlattend [1 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1]\n",
      "predictionArgmax [1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1]\n",
      "labelsFlattend [1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1]\n",
      "predictionArgmax [1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0]\n",
      "labelsFlattend [1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0]\n",
      "predictionArgmax [0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0]\n",
      "labelsFlattend [0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1]\n",
      "predictionArgmax [1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0]\n",
      "labelsFlattend [1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0]\n",
      "predictionArgmax [1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0]\n",
      "labelsFlattend [1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0]\n",
      "predictionArgmax [1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1]\n",
      "predictionArgmax [0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1]\n",
      "labelsFlattend [0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1]\n",
      "predictionArgmax [1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1]\n",
      "labelsFlattend [1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 0]\n",
      "labelsFlattend [1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0]\n",
      "labelsFlattend [1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0]\n",
      "predictionArgmax [1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "labelsFlattend [1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0]\n",
      "predictionArgmax [0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0]\n",
      "predictionArgmax [1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1]\n",
      "labelsFlattend [1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0]\n",
      "labelsFlattend [1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0]\n",
      "predictionArgmax [0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0]\n",
      "labelsFlattend [0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1]\n",
      "predictionArgmax [1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0]\n",
      "labelsFlattend [1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1]\n",
      "labelsFlattend [1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1]\n",
      "predictionArgmax [0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1]\n",
      "labelsFlattend [0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1]\n",
      "labelsFlattend [1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1]\n",
      "predictionArgmax [0 1 0 1 1 1]\n",
      "labelsFlattend [1 1 0 1 1 1]\n",
      "  F1 score: 0.920\n",
      "  Accuracy score: 0.923\n",
      "  Validating one epoch time taken  4.709387540817261\n",
      "Start Epoch Number 2\n",
      "Start Training\n",
      "Batch Completed  50  of  149.    Elapsed time is  11.47944164276123\n",
      "Batch Completed  100  of  149.    Elapsed time is  22.909343957901\n",
      " The training loss incured is  0.189\n",
      "  Training one epoch time taken 34.087883949279785\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1]\n",
      "labelsFlattend [0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1]\n",
      "predictionArgmax [0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0]\n",
      "labelsFlattend [0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0]\n",
      "predictionArgmax [1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0]\n",
      "predictionArgmax [1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0]\n",
      "labelsFlattend [1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0]\n",
      "predictionArgmax [1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0]\n",
      "labelsFlattend [1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0]\n",
      "predictionArgmax [0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0]\n",
      "labelsFlattend [1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0]\n",
      "predictionArgmax [1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0]\n",
      "labelsFlattend [1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0]\n",
      "predictionArgmax [0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1]\n",
      "labelsFlattend [0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1]\n",
      "predictionArgmax [1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1]\n",
      "labelsFlattend [1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1]\n",
      "predictionArgmax [1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1]\n",
      "predictionArgmax [1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0]\n",
      "labelsFlattend [1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0]\n",
      "predictionArgmax [0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1]\n",
      "labelsFlattend [1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1]\n",
      "predictionArgmax [0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1]\n",
      "predictionArgmax [0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0]\n",
      "labelsFlattend [0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0]\n",
      "labelsFlattend [1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1]\n",
      "labelsFlattend [1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1]\n",
      "predictionArgmax [1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0]\n",
      "predictionArgmax [0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1]\n",
      "labelsFlattend [0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1]\n",
      "predictionArgmax [1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0]\n",
      "labelsFlattend [1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1]\n",
      "labelsFlattend [1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1]\n",
      "predictionArgmax [1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1]\n",
      "labelsFlattend [1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1]\n",
      "predictionArgmax [0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0]\n",
      "labelsFlattend [1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1]\n",
      "labelsFlattend [0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0]\n",
      "labelsFlattend [1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1]\n",
      "labelsFlattend [1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1]\n",
      "labelsFlattend [1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1]\n",
      "predictionArgmax [0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1]\n",
      "labelsFlattend [0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1]\n",
      "predictionArgmax [0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0]\n",
      "labelsFlattend [0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0]\n",
      "predictionArgmax [1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1]\n",
      "labelsFlattend [1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1]\n",
      "predictionArgmax [1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1]\n",
      "labelsFlattend [1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1]\n",
      "predictionArgmax [1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1]\n",
      "labelsFlattend [1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0]\n",
      "labelsFlattend [0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0]\n",
      "predictionArgmax [0 0 1 1 0 1]\n",
      "labelsFlattend [0 0 1 1 0 1]\n",
      "  F1 score: 0.943\n",
      "  Accuracy score: 0.944\n",
      "  Validating one epoch time taken  4.762000322341919\n",
      "Start Epoch Number 3\n",
      "Start Training\n",
      "Batch Completed  50  of  149.    Elapsed time is  11.48734164237976\n",
      "Batch Completed  100  of  149.    Elapsed time is  22.89177966117859\n",
      " The training loss incured is  0.126\n",
      "  Training one epoch time taken 34.025530099868774\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1]\n",
      "labelsFlattend [1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1]\n",
      "predictionArgmax [0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0]\n",
      "predictionArgmax [1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1]\n",
      "labelsFlattend [1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1]\n",
      "predictionArgmax [1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1]\n",
      "labelsFlattend [0 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0]\n",
      "labelsFlattend [1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0]\n",
      "predictionArgmax [1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
      "labelsFlattend [0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1]\n",
      "predictionArgmax [1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0]\n",
      "labelsFlattend [1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0]\n",
      "predictionArgmax [0 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 1]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1]\n",
      "labelsFlattend [0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0]\n",
      "predictionArgmax [1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0]\n",
      "labelsFlattend [1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0]\n",
      "labelsFlattend [0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "predictionArgmax [1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0]\n",
      "labelsFlattend [1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1]\n",
      "predictionArgmax [1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1]\n",
      "labelsFlattend [1 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1]\n",
      "predictionArgmax [1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0]\n",
      "labelsFlattend [0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "labelsFlattend [0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "predictionArgmax [1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "labelsFlattend [1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "predictionArgmax [1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0]\n",
      "labelsFlattend [1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1]\n",
      "labelsFlattend [0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0]\n",
      "labelsFlattend [1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0]\n",
      "predictionArgmax [0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1]\n",
      "labelsFlattend [0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0]\n",
      "labelsFlattend [1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1]\n",
      "predictionArgmax [1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0]\n",
      "predictionArgmax [0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0]\n",
      "labelsFlattend [1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0]\n",
      "predictionArgmax [0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1]\n",
      "labelsFlattend [0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0]\n",
      "labelsFlattend [1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1]\n",
      "labelsFlattend [1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1]\n",
      "predictionArgmax [0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0]\n",
      "predictionArgmax [1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1]\n",
      "predictionArgmax [1 1 0 0 1 1]\n",
      "labelsFlattend [1 1 0 1 1 1]\n",
      "  F1 score: 0.936\n",
      "  Accuracy score: 0.941\n",
      "  Validating one epoch time taken  4.824276924133301\n",
      "Start Epoch Number 4\n",
      "Start Training\n",
      "Batch Completed  50  of  149.    Elapsed time is  11.490112543106079\n",
      "Batch Completed  100  of  149.    Elapsed time is  22.851974964141846\n",
      " The training loss incured is  0.090\n",
      "  Training one epoch time taken 33.99013614654541\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0]\n",
      "predictionArgmax [1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1]\n",
      "labelsFlattend [1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1]\n",
      "predictionArgmax [0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "labelsFlattend [0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "predictionArgmax [0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0]\n",
      "predictionArgmax [1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1]\n",
      "labelsFlattend [1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1]\n",
      "predictionArgmax [0 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1]\n",
      "labelsFlattend [0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1]\n",
      "labelsFlattend [0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1]\n",
      "predictionArgmax [1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1]\n",
      "labelsFlattend [1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1]\n",
      "labelsFlattend [0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1]\n",
      "predictionArgmax [1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1]\n",
      "predictionArgmax [0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1]\n",
      "labelsFlattend [0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1]\n",
      "predictionArgmax [0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0]\n",
      "labelsFlattend [0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0]\n",
      "predictionArgmax [0 1 1 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0]\n",
      "labelsFlattend [0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1]\n",
      "labelsFlattend [1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0]\n",
      "labelsFlattend [1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0]\n",
      "predictionArgmax [0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1]\n",
      "labelsFlattend [0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1]\n",
      "predictionArgmax [1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0]\n",
      "labelsFlattend [1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0]\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0]\n",
      "labelsFlattend [1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1]\n",
      "labelsFlattend [0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1]\n",
      "labelsFlattend [0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1]\n",
      "predictionArgmax [0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0]\n",
      "labelsFlattend [1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0]\n",
      "predictionArgmax [1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1]\n",
      "labelsFlattend [1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1]\n",
      "predictionArgmax [1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1]\n",
      "labelsFlattend [1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1]\n",
      "labelsFlattend [1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1]\n",
      "predictionArgmax [1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      "labelsFlattend [1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "predictionArgmax [1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1]\n",
      "predictionArgmax [1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1]\n",
      "labelsFlattend [1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0]\n",
      "labelsFlattend [0 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0]\n",
      "predictionArgmax [1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0]\n",
      "predictionArgmax [1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0]\n",
      "labelsFlattend [1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1]\n",
      "predictionArgmax [0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1]\n",
      "labelsFlattend [0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1]\n",
      "predictionArgmax [1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1]\n",
      "predictionArgmax [0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      "labelsFlattend [0 1 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 1]\n",
      "labelsFlattend [1 1 1 0 0 1]\n",
      "  F1 score: 0.939\n",
      "  Accuracy score: 0.942\n",
      "  Validating one epoch time taken  4.805988073348999\n",
      "ALL DONE!!!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "epochs=4\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    \n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()        \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    \n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "   \n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "\n",
    "    for batch in tedataloader:       \n",
    "        batch = tuple(t.to(device) for t in batch)        \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "\n",
    "    torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/DanishData/augdanish.pth.tar')\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    \n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "    \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4rWdrUSxJIV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8VFcl1gBfU-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ojs4mzqQhkR4",
    "outputId": "04e6de33-0544-4955-9560-9a88055e74f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace Danish/offenseval-da-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace Danish/readme-trainingset-da.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
     ]
    }
   ],
   "source": [
    "!unzip -P yourpassword -qq '/content/drive/My Drive/DanishData/DanishPredict.zip'\n",
    "!unzip -P yourpassword -qq '/content/drive/My Drive/DanishData/Danish.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19c06d4ChmVm"
   },
   "outputs": [],
   "source": [
    "ygiven=[]\n",
    "ypredicted=[]\n",
    "\n",
    "def convertToInt(val):\n",
    "    if not val:\n",
    "        return 0    \n",
    "    try:\n",
    "        return np.int64(val)\n",
    "    except:        \n",
    "        return np.int64(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRhcqakGho3E"
   },
   "outputs": [],
   "source": [
    "##Use blob\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['id','tweet']\n",
    "  greekDataTest = pd.read_csv(\"offenseval-da-test-v1-nolabels.tsv\", delimiter='\\t',names=headers,quoting=csv.QUOTE_NONE,\n",
    "                                converters={\"id\":convertToInt})\n",
    "  greekDataTest=greekDataTest[1:]\n",
    "  print(greekDataTest.head())\n",
    "  print(greekDataTest.dtypes)\n",
    "  print(greekDataTest.shape)\n",
    "  \n",
    "  dfnumpy=greekDataTest.to_numpy();\n",
    "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  print(tid)\n",
    "  arrt=X[:,0]\n",
    "  #allTokens=preprocess1(arrt)\n",
    "  preprocessedTweets=arrt\n",
    "  return preprocessedTweets,tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-CgDHQVwhsFY",
    "outputId": "d3f53ec2-5fc2-4b38-b7bf-bda23f6065f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              tweet\n",
      "1  1382  Der er syriske \"flygtninge\" som rejser til Ira...\n",
      "2  1384                             Danmark = Vitryssland?\n",
      "3   547  Ja tvangsfjernelser af børn på urigtige oplysn...\n",
      "4  1269  Han kan ikke Svensk og forventer et job. Hvis ...\n",
      "5  1695                                  NED MED SVENSKEN!\n",
      "id        int64\n",
      "tweet    object\n",
      "dtype: object\n",
      "(329, 2)\n",
      "[[1382]\n",
      " [1384]\n",
      " [547]\n",
      " [1269]\n",
      " [1695]\n",
      " [2320]\n",
      " [990]\n",
      " [2665]\n",
      " [1414]\n",
      " [262]\n",
      " [1459]\n",
      " [3375]\n",
      " [1431]\n",
      " [137]\n",
      " [8]\n",
      " [2964]\n",
      " [2542]\n",
      " [1375]\n",
      " [1458]\n",
      " [799]\n",
      " [976]\n",
      " [305]\n",
      " [2643]\n",
      " [386]\n",
      " [715]\n",
      " [2041]\n",
      " [2194]\n",
      " [60]\n",
      " [2181]\n",
      " [720]\n",
      " [552]\n",
      " [2560]\n",
      " [775]\n",
      " [848]\n",
      " [1754]\n",
      " [2363]\n",
      " [1330]\n",
      " [885]\n",
      " [974]\n",
      " [1205]\n",
      " [2589]\n",
      " [2172]\n",
      " [159]\n",
      " [3425]\n",
      " [544]\n",
      " [1371]\n",
      " [30]\n",
      " [1973]\n",
      " [22]\n",
      " [1813]\n",
      " [1379]\n",
      " [99]\n",
      " [1614]\n",
      " [1038]\n",
      " [633]\n",
      " [1275]\n",
      " [924]\n",
      " [962]\n",
      " [1314]\n",
      " [926]\n",
      " [33]\n",
      " [2627]\n",
      " [3396]\n",
      " [1321]\n",
      " [2321]\n",
      " [391]\n",
      " [1143]\n",
      " [1596]\n",
      " [3222]\n",
      " [3122]\n",
      " [716]\n",
      " [173]\n",
      " [2382]\n",
      " [3560]\n",
      " [2046]\n",
      " [1291]\n",
      " [2858]\n",
      " [102]\n",
      " [2577]\n",
      " [1507]\n",
      " [987]\n",
      " [2639]\n",
      " [1505]\n",
      " [3499]\n",
      " [325]\n",
      " [3482]\n",
      " [2068]\n",
      " [1497]\n",
      " [647]\n",
      " [2674]\n",
      " [632]\n",
      " [3522]\n",
      " [133]\n",
      " [3163]\n",
      " [142]\n",
      " [1893]\n",
      " [513]\n",
      " [1487]\n",
      " [883]\n",
      " [219]\n",
      " [1919]\n",
      " [777]\n",
      " [972]\n",
      " [2131]\n",
      " [570]\n",
      " [371]\n",
      " [1344]\n",
      " [3406]\n",
      " [1816]\n",
      " [1469]\n",
      " [3165]\n",
      " [2832]\n",
      " [964]\n",
      " [3150]\n",
      " [1886]\n",
      " [1766]\n",
      " [1599]\n",
      " [224]\n",
      " [2932]\n",
      " [1520]\n",
      " [757]\n",
      " [1315]\n",
      " [3316]\n",
      " [709]\n",
      " [3562]\n",
      " [2192]\n",
      " [3117]\n",
      " [2196]\n",
      " [485]\n",
      " [2076]\n",
      " [1148]\n",
      " [108]\n",
      " [73]\n",
      " [852]\n",
      " [2925]\n",
      " [1455]\n",
      " [1946]\n",
      " [3114]\n",
      " [927]\n",
      " [526]\n",
      " [1189]\n",
      " [3437]\n",
      " [1738]\n",
      " [1659]\n",
      " [678]\n",
      " [2389]\n",
      " [1923]\n",
      " [3012]\n",
      " [850]\n",
      " [218]\n",
      " [753]\n",
      " [1940]\n",
      " [736]\n",
      " [3240]\n",
      " [1545]\n",
      " [3571]\n",
      " [995]\n",
      " [2380]\n",
      " [3398]\n",
      " [85]\n",
      " [2291]\n",
      " [2167]\n",
      " [860]\n",
      " [2502]\n",
      " [3245]\n",
      " [727]\n",
      " [3400]\n",
      " [413]\n",
      " [2204]\n",
      " [1082]\n",
      " [1220]\n",
      " [1546]\n",
      " [712]\n",
      " [646]\n",
      " [2493]\n",
      " [2075]\n",
      " [28]\n",
      " [379]\n",
      " [1928]\n",
      " [2626]\n",
      " [2506]\n",
      " [2245]\n",
      " [2746]\n",
      " [104]\n",
      " [23]\n",
      " [3211]\n",
      " [705]\n",
      " [2137]\n",
      " [774]\n",
      " [2895]\n",
      " [1593]\n",
      " [975]\n",
      " [1534]\n",
      " [1818]\n",
      " [3299]\n",
      " [1809]\n",
      " [2256]\n",
      " [246]\n",
      " [3492]\n",
      " [2085]\n",
      " [1139]\n",
      " [1907]\n",
      " [1285]\n",
      " [380]\n",
      " [1698]\n",
      " [3545]\n",
      " [2725]\n",
      " [3323]\n",
      " [4]\n",
      " [699]\n",
      " [1251]\n",
      " [966]\n",
      " [2153]\n",
      " [1439]\n",
      " [3108]\n",
      " [1558]\n",
      " [209]\n",
      " [3494]\n",
      " [2934]\n",
      " [1064]\n",
      " [1942]\n",
      " [492]\n",
      " [1089]\n",
      " [621]\n",
      " [940]\n",
      " [1188]\n",
      " [3143]\n",
      " [2049]\n",
      " [2066]\n",
      " [763]\n",
      " [579]\n",
      " [2449]\n",
      " [375]\n",
      " [2063]\n",
      " [2155]\n",
      " [261]\n",
      " [859]\n",
      " [1292]\n",
      " [1105]\n",
      " [3397]\n",
      " [3431]\n",
      " [2532]\n",
      " [3524]\n",
      " [2111]\n",
      " [2191]\n",
      " [2907]\n",
      " [1167]\n",
      " [1164]\n",
      " [3084]\n",
      " [1200]\n",
      " [534]\n",
      " [2299]\n",
      " [3069]\n",
      " [1103]\n",
      " [3177]\n",
      " [1889]\n",
      " [3424]\n",
      " [2373]\n",
      " [341]\n",
      " [658]\n",
      " [651]\n",
      " [442]\n",
      " [2677]\n",
      " [1944]\n",
      " [1311]\n",
      " [430]\n",
      " [2040]\n",
      " [1096]\n",
      " [581]\n",
      " [2683]\n",
      " [2540]\n",
      " [2414]\n",
      " [701]\n",
      " [1095]\n",
      " [2959]\n",
      " [769]\n",
      " [2836]\n",
      " [274]\n",
      " [1846]\n",
      " [94]\n",
      " [1044]\n",
      " [1791]\n",
      " [890]\n",
      " [26]\n",
      " [79]\n",
      " [2080]\n",
      " [1131]\n",
      " [798]\n",
      " [2048]\n",
      " [620]\n",
      " [404]\n",
      " [1427]\n",
      " [519]\n",
      " [2864]\n",
      " [3304]\n",
      " [3166]\n",
      " [546]\n",
      " [459]\n",
      " [2050]\n",
      " [880]\n",
      " [1123]\n",
      " [138]\n",
      " [1425]\n",
      " [1996]\n",
      " [2036]\n",
      " [1568]\n",
      " [1303]\n",
      " [1917]\n",
      " [734]\n",
      " [641]\n",
      " [2412]\n",
      " [2928]\n",
      " [9]\n",
      " [2799]\n",
      " [3062]\n",
      " [1106]\n",
      " [184]\n",
      " [3534]\n",
      " [3512]\n",
      " [2634]\n",
      " [1338]\n",
      " [2238]\n",
      " [3326]\n",
      " [3567]\n",
      " [1591]\n",
      " [1769]\n",
      " [2443]\n",
      " [3221]\n",
      " [400]]\n"
     ]
    }
   ],
   "source": [
    "preprocessedTweets,tid=readData1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AukQQ0jWhxTm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekPredictDataset(Dataset):\n",
    "    def __init__(self,xypredict):\n",
    "        self.xypredict = xypredict\n",
    "        self.maxlength=128\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
    "        tid_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
    "        \n",
    "        return x_predict_pytorch,x_predict_mask_pytorch,tid_predict_pytorch\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.xypredict[0])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf_TvSaYn1AJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def calculateScore(predictions):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  yres.append(predictionArgmax.flatten())\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWKfHXfplWQ_"
   },
   "outputs": [],
   "source": [
    "yres=[]\n",
    "finalTid=[]\n",
    "def predictingData(pTweets,tid):\n",
    "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  map_location=\"\"\n",
    "  xypredict=[pTweets,tid.flatten()]\n",
    "  \n",
    "  tdataset = GreekPredictDataset(xypredict)\n",
    "  tsampler=RandomSampler(tdataset)\n",
    "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "  print(device.type)\n",
    "  '''model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "  if device.type==\"cpu\":\n",
    "    model.to(device)\n",
    "    map_location='cpu'\n",
    "  else:\n",
    "    model.cuda()\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/DanishData/augdanish.pth.tar',map_location=map_location)\n",
    "  print(\"Hello\")\n",
    "  model.load_state_dict(checkpoint['state_dict'])'''\n",
    "  model.eval()\n",
    "  i=0\n",
    "  for batch in predictdataloader:\n",
    "      print(i)\n",
    "      i=i+1\n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"tids\":batch[2]}\n",
    "      \n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      tidl=(inputs[\"tids\"]).to('cpu').numpy()\n",
    "      finalTid.append(tidl)\n",
    "      calculateScore(logits)\n",
    "      \n",
    "  return predictedLabels,finalTidF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3Gp5gPddxj"
   },
   "outputs": [],
   "source": [
    "preprocessedTweets,tid=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jw_7IjQpiLHw"
   },
   "outputs": [],
   "source": [
    "predictedLabels,finalTid=predictingData(preprocessedTweets,tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-v3ajuk04jw-"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/DanishData/augdanish.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/DanishData/augdanish.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBxBKJFVaFjr"
   },
   "outputs": [],
   "source": [
    "yans=[yres[i].flatten().tolist() for i in range(len(yres))]\n",
    "ytid=[finalTid[i].flatten().tolist() for i in range(len(finalTid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdm6cxWpodZ6"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "yans=list(chain.from_iterable(yans))\n",
    "ytid=list(chain.from_iterable(ytid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8HSGUkNofbW"
   },
   "outputs": [],
   "source": [
    "len(ytid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CveSLjS4oRXx"
   },
   "outputs": [],
   "source": [
    "yans1=[\"NOT\" if yans[i]==0 else \"OFF\" for i in range(len(yans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtxToRGIoNtc"
   },
   "outputs": [],
   "source": [
    "print(yans1.count(\"OFF\"))\n",
    "print(yans1.count(\"NOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25c0lKP1oYAr"
   },
   "outputs": [],
   "source": [
    "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
    "#print(len(z))\n",
    "C = {'id': ytid,\n",
    "        'predicted': yans1,\n",
    "    }\n",
    "df = pd.DataFrame(C)\n",
    "print (df[df['id'] == 400] )\n",
    "\n",
    "export_csv = df.to_csv ('/content/drive/My Drive/DanishData/Answer.csv', index = None, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3_AaAvxliJm"
   },
   "source": [
    "from 80 ,10 ,10 split getting  # F1 score: 0.836 Accuracy score: 0.867"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AugmentedFirstWorkingF1TestingAndTrainDanishFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00411c590e2d40d6abe14497d6e9246e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6638a4c105d44e6898cc39018fbe0e4c",
       "IPY_MODEL_ab4da3fbeec84b23a7d204191e9f077b"
      ],
      "layout": "IPY_MODEL_23a6e3182e504edcbaaca49f599ed41a"
     }
    },
    "1194a37289a24b7dba376496287be4e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca711bd515db4b4ab2243dd2be1bb37d",
       "IPY_MODEL_883a63f02c114754b9e6476824f344ff"
      ],
      "layout": "IPY_MODEL_444f9cf820d840cfb8c204141a10ae9e"
     }
    },
    "23a6e3182e504edcbaaca49f599ed41a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29bafd2f260c405187ecbda0c8dbed27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9aad37766c0b4a08b5d3e1a6cdfd27b0",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef615d79414e4f208f7c5f5e7ec8f0b2",
      "value": 714314041
     }
    },
    "444f9cf820d840cfb8c204141a10ae9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4778600e3d45425d917b7fcefb413fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29bafd2f260c405187ecbda0c8dbed27",
       "IPY_MODEL_c31fb1d3edbd441ba045513bc5529908"
      ],
      "layout": "IPY_MODEL_a0f4f685c7e54a2694ccd8342899740d"
     }
    },
    "6638a4c105d44e6898cc39018fbe0e4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d54f1b884b314107b066cd3fd2349980",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fb9a96f16c34ac8a56d25e00073f167",
      "value": 995526
     }
    },
    "7fb9a96f16c34ac8a56d25e00073f167": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "81c4ad4dbdd342c0bc7f9cd5bbb7126c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "883a63f02c114754b9e6476824f344ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e2346647aa7463ca0e624b8d975cd67",
      "placeholder": "​",
      "style": "IPY_MODEL_b62eec3e85c24e7698e0533c57e95e5f",
      "value": " 625/625 [00:00&lt;00:00, 1.01kB/s]"
     }
    },
    "8e2346647aa7463ca0e624b8d975cd67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aad37766c0b4a08b5d3e1a6cdfd27b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d2fec9666d34df081e6877bfc380687": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0f4f685c7e54a2694ccd8342899740d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5844159318b43799bc49ed6311e1087": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab4da3fbeec84b23a7d204191e9f077b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d2fec9666d34df081e6877bfc380687",
      "placeholder": "​",
      "style": "IPY_MODEL_a5844159318b43799bc49ed6311e1087",
      "value": " 996k/996k [00:00&lt;00:00, 1.80MB/s]"
     }
    },
    "b62eec3e85c24e7698e0533c57e95e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c31fb1d3edbd441ba045513bc5529908": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fba02d25bbff4b539f78bb7038f2b218",
      "placeholder": "​",
      "style": "IPY_MODEL_81c4ad4dbdd342c0bc7f9cd5bbb7126c",
      "value": " 714M/714M [00:23&lt;00:00, 30.1MB/s]"
     }
    },
    "c5163060de664a2aa519d7faa6f17b3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca711bd515db4b4ab2243dd2be1bb37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5163060de664a2aa519d7faa6f17b3c",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edd5e4f623d44694beb7384a0b6aabef",
      "value": 625
     }
    },
    "d54f1b884b314107b066cd3fd2349980": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edd5e4f623d44694beb7384a0b6aabef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef615d79414e4f208f7c5f5e7ec8f0b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fba02d25bbff4b539f78bb7038f2b218": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
