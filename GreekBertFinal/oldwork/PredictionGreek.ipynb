{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "colab_type": "code",
    "id": "K8VFcl1gBfU-",
    "outputId": "bb396c32-fbc4-490f-c8f4-78f1e1e69b26"
   },
   "outputs": [],
   "source": [
    "#ALL INSTALLTIONS\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Data set and Data loader has  been adapted and inspired from \n",
    "#Michael Sugimura,Github Repository:https://github.com/sugi-chan/custom_bert_pipeline\n",
    "#BERT based fine tuning adapted and inspired from:Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning #Tutorial with PyTorch. Retrieved from http://www.mccormickml.com\n",
    "#for all references refer README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "T3MK2sszwvbe",
    "outputId": "8163f13e-478e-4406-b386-3a1baa058dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cEeA5Ys-R2r"
   },
   "outputs": [],
   "source": [
    "gpuname=\"\"\n",
    "device=\"\"\n",
    "y=\"\"\n",
    "preprocessedTweets=\"\"\n",
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaSv6PB4w1JW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def initGpus1():\n",
    "  gpuname=tf.test.gpu_device_name()\n",
    "  if gpuname=='/device:GPU:0':\n",
    "    print('Found GPU at :{}'.format(gpuname))\n",
    "  else:\n",
    "    gpuname=\"\"\n",
    "  if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    n_gpu=torch.cuda.device_count()\n",
    "    print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "  else:\n",
    "    print(\"No GPU available using only CPU instead\")\n",
    "    device=torch.device(\"cpu\")\n",
    "  return gpuname,device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "iALw8AQY7LkW",
    "outputId": "7d20a5a4-f48f-49e2-9ec3-312e959ea41d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhCZIFPC7Yhs"
   },
   "outputs": [],
   "source": [
    "!unzip -P yourpassword -qq '/content/drive/My Drive/GreekData/PredictFile.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RUoX4ag7a5W"
   },
   "outputs": [],
   "source": [
    "##Use blob\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['tweet','subtask_a']\n",
    "  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter=',',names=headers)\n",
    "  \n",
    "  data=greekdata[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  y=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  arrt=X[:,0]\n",
    "  #print(X)\n",
    "  #print(y)\n",
    "  preprocessedTweets=arrt\n",
    "  return preprocessedTweets,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfE9PV0Vu08q"
   },
   "outputs": [],
   "source": [
    "#preprocessedTweets,y=readData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "PuLzvJ4msRLX",
    "outputId": "60d20a13-de28-4899-9310-69fa15b22265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n##Use blob\\n#GET THE DATA FROM THE PANDAS FRAME\\ndef readData1():\\n  headers=[\\'tweet\\',\\'subtask_a\\']\\n  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter=\\'\\t\\',names=headers)\\n  data=greekdata[1:]\\n  #print(greekdata)\\n  dfnumpy=data.to_numpy();\\n  X=dfnumpy[:, 0].reshape(-1, 1)\\n\\n\\n  #REMOVE THE BELOW LINE\\n  greekdata1 = pd.read_csv(\"PredictFile.csv\", delimiter=\\',\\',names=headers)\\n\\n  data=greekdata[1:]\\n  dfnumpy=data.to_numpy();\\n  X=dfnumpy[:, 0].reshape(-1, 1)\\n  #print(X)\\n  \\n  data=greekdata1[1:]\\n  dfnumpy=data.to_numpy();\\n  y=dfnumpy[:, 1].reshape(-1, 1)\\n  \\n  arrt=X[:,0]\\n  #print(y)\\n  preprocessedTweets=arrt\\n\\n  return preprocessedTweets,y\\n  '"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##Use blob\n",
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "def readData1():\n",
    "  headers=['tweet','subtask_a']\n",
    "  greekdata = pd.read_csv(\"PredictFile.csv\", delimiter='\\t',names=headers)\n",
    "  data=greekdata[1:]\n",
    "  #print(greekdata)\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "\n",
    "\n",
    "  #REMOVE THE BELOW LINE\n",
    "  greekdata1 = pd.read_csv(\"PredictFile.csv\", delimiter=',',names=headers)\n",
    "\n",
    "  data=greekdata[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  X=dfnumpy[:, 0].reshape(-1, 1)\n",
    "  #print(X)\n",
    "  \n",
    "  data=greekdata1[1:]\n",
    "  dfnumpy=data.to_numpy();\n",
    "  y=dfnumpy[:, 1].reshape(-1, 1)\n",
    "  \n",
    "  arrt=X[:,0]\n",
    "  #print(y)\n",
    "  preprocessedTweets=arrt\n",
    "\n",
    "  return preprocessedTweets,y\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAPtgGcYVDjl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fF2D1hIsObn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_ZLONeR9I4Y"
   },
   "outputs": [],
   "source": [
    "def giveIds(sentence):\n",
    "  tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "  ids_of_sentence=[]\n",
    "  ids_of_sentence_words=[]\n",
    "  attention_masks=[]\n",
    "  maxlength=0\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "  print(maxlength)\n",
    "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
    "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
    "  return ids_of_sentence_words,attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZsgnMAssDmy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYZP78bKr4Sa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eqN01x9LqjLa",
    "outputId": "800ad691-e69b-43f4-c7d6-293c3f30ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "xpredict,xpredictmask=giveIds(preprocessedTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X6_3fz3pruOD",
    "outputId": "ffcb6ea5-c6ab-4d5b-c5b9-6197f734bfc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_of_sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xv0Z1IwUyNGl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  #print(\"predictionArgmax\",predictionArgmax)\n",
    "  #print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3Gp5gPddxj"
   },
   "outputs": [],
   "source": [
    "def predictingData(pTweets,ypred):\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  \n",
    "  xpredict,xpredictmask=giveIds(pTweets)\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ypredict=le.fit_transform(ypred.flatten())\n",
    "\n",
    "  x_predict_pytorch=torch.tensor(xpredict)\n",
    "  y_predict_pytorch=torch.tensor(ypredict)\n",
    "  x_predict_mask_pytorch=torch.tensor(xpredictmask)\n",
    "\n",
    "  bsize = 32\n",
    "  predictdata=TensorDataset(x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch)\n",
    "  predictsampler=RandomSampler(predictdata)\n",
    "  predictdataloader=DataLoader(predictdata,sampler=predictsampler,batch_size=bsize)\n",
    "  \n",
    "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "  model.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  \n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "\n",
    "  for batch in predictdataloader: \n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      trueLabels.append(label_ids)\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      \n",
    "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "  return predictedLabels,trueLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Da99UbY7xlx_"
   },
   "outputs": [],
   "source": [
    "#device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "cBxBKJFVaFjr",
    "outputId": "6ebf28cb-94a4-45b0-b21a-c91fb5e55c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n",
      "The device name is Tesla P100-PCIE-16GB\n",
      "166\n",
      "  F1 score: 0.839\n",
      "  Accuracy score: 0.883\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  initGpus1()  \n",
    "  preprocessedTweets,y=readData1()\n",
    "  predictedLabels,trueLabels=predictingData(preprocessedTweets,y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ey3iQErEVmuA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PredictionGreek.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
