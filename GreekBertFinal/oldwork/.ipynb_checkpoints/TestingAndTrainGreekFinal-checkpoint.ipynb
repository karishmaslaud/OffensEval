{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "l0-z91UlfiRk",
    "outputId": "a0a4e04c-6820-41f5-c33f-f0b32609fb82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all imports\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Data set and Data loader has  been adapted and inspired from \n",
    "#Michael Sugimura,Github Repository:https://github.com/sugi-chan/custom_bert_pipeline\n",
    "#BERT based fine tuning adapted and inspired from:Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning #Tutorial with PyTorch. Retrieved from http://www.mccormickml.com\n",
    "#for all references refer README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "amsZ4bSdhBEP",
    "outputId": "d3f1c9b1-e55b-4ab6-b47b-ad6acc0c3930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at :/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpuname=tf.test.gpu_device_name()\n",
    "if gpuname=='/device:GPU:0':\n",
    "  print('Found GPU at :{}'.format(gpuname))\n",
    "else:\n",
    "  raise(SystemError('GPU device not found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lL3ZtD-zg4k1",
    "outputId": "ec74c0c8-2cf0-4912-e9aa-026a5761b3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU DEVICES available \n",
      "The device name is Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device=torch.device(\"cuda\")\n",
    "  print(\"There are %d GPU DEVICES available \" %torch.cuda.device_count())\n",
    "  print(\"The device name is %s\"%torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  print(\"No GPU available using only CPU instead\")\n",
    "  device=torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "buldkQJQiKYI",
    "outputId": "7a090480-5b32-4052-80c2-fe714592ac08"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKdaEMufiiAu",
    "outputId": "f3d04f2f-f823-4f94-b361-7a131fa03153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_byFfpTf1D9"
   },
   "source": [
    "#Custom Data set and Data loader has been inspired from \n",
    "#https://github.com/sugi-chan/custom_bert_pipeline/blob/master/bert_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0iCZDHmlWSjY",
    "outputId": "2fe97eff-8060-47c0-e3c2-72b6c32b5646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace Greek/offenseval-greek-training-v1.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace Greek/readme-trainingset-greek.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
     ]
    }
   ],
   "source": [
    "!unzip -P yourpassword -qq '/content/drive/My Drive/GreekData/Greek.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vr20Wv8gpF9w",
    "outputId": "a3f15617-209e-426b-c090-74ba20d1972d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Cx_z-bmJsVg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bHoGZVoSCPU"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucAFIEswSPcQ"
   },
   "outputs": [],
   "source": [
    "#GET THE DATA FROM THE PANDAS FRAME\n",
    "headers=['id','tweet','subtask_a']\n",
    "greekdata = pd.read_csv(\"Greek/offenseval-greek-training-v1.tsv\", delimiter='\\t',names=headers)\n",
    "data=greekdata[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvqVo6tfV2xr"
   },
   "outputs": [],
   "source": [
    "dataOffensive1=data[data.subtask_a==\"OFF\"]\n",
    "dataNOTOffensive=data[data.subtask_a==\"NOT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpynLG3NYR5Y"
   },
   "outputs": [],
   "source": [
    "#dataOffensive1=dataOffensive1.append(dataOffensive1, ignore_index=True)\n",
    "dataOffensive=dataOffensive1.append(dataOffensive1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XHclFDnUSh9z",
    "outputId": "c622fd0a-6c26-4e39-bbfd-b890ec9ddb1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4972"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataOffensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ETu9KrsbSph_",
    "outputId": "f63a5735-3fee-42d1-bc28-9b3a81707d5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6257"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataNOTOffensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLPDEHelTmgo"
   },
   "outputs": [],
   "source": [
    "data=dataNOTOffensive.append(dataOffensive, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5dc110HdTtF1",
    "outputId": "fee58f9c-7562-4c78-8521-de293f80a4ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11229"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bnhbuYtZL0zO",
    "outputId": "a4bcf362-211e-4c8b-bc35-1ae310233270"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT', 'NOT', 'NOT', ..., 'OFF', 'OFF', 'OFF'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_numpy()[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXNuys5ZaNOQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "dfnumpy=data.to_numpy();\n",
    "x=dfnumpy[:, 1].reshape(-1, 1)\n",
    "y=dfnumpy[:, 2].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UoqOUnmNZO07",
    "outputId": "b21f765d-8195-4c6a-c446-c6f8f80c4b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U89nu4PBSSZD",
    "outputId": "2b515cc9-ee07-42da-9225-ef9e435efbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('el_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"el_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY5vGRQYdq5F"
   },
   "outputs": [],
   "source": [
    "#LEMMATIZATION\n",
    "import string\n",
    "import spacy\n",
    "#import el_core_news_sm \n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "import preprocessor as p2\n",
    "\n",
    "\n",
    "nlp =  spacy.load('el_core_news_md')\n",
    "#Preprocessing # to HASHTAG so that spacy can tokenize it properly\n",
    "p=re.compile(r\"(#)\",re.UNICODE)\n",
    "p1=re.compile(r\"\\.*\",re.UNICODE)\n",
    "##tokenization with NLTK and SPACY DIDNT WORK TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOEIfAgyr83C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gp1M-zbEcXXo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chD2GSH5dHb1"
   },
   "outputs": [],
   "source": [
    "arrt=x[:,0]\n",
    "#allTokens=preprocess1(arrt)\n",
    "allTokens=arrt\n",
    "#allTokenstrain, allTokenstest, y_train, y_test = train_test_split(allTokens,y, test_size=0.2, random_state=42)\n",
    "#allTokensPredict, _, y_predict, _ = train_test_split(allTokenstest,y_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZALP47hKO4HD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2X-eKHng4jUh"
   },
   "outputs": [],
   "source": [
    "preprocessedTweets=allTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZLNpEq1VVUH"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "preprocessedTweets, y = shuffle(preprocessedTweets, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Y7m4cgbJLwXW",
    "outputId": "48a45a31-341f-4f39-c7da-8f5ba28c2249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NOT'],\n",
       "       ['OFF'],\n",
       "       ['NOT'],\n",
       "       ...,\n",
       "       ['OFF'],\n",
       "       ['OFF'],\n",
       "       ['OFF']], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AzyloI-QNt2a",
    "outputId": "ad96b6a1-2c5d-459c-de59-640073ebac43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\\n  f.write(str(x))\""
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open('/content/drive/My Drive/preprocessedTweets.txt', 'w') as f:\n",
    "  f.write(str(x))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "3TImBZYl4wih",
    "outputId": "90333114-a0cd-4768-b13b-89d3b8eb3189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Τον χαιρετάω με χαιρετάει. Με ρωτάει τι κάνεις κι ανύποπτος του λέω τα πάντα σχετικά με τη ζωή μου. Τελειώνοντας εγώ τότε με ρωτάει, αλήθεια ποιος είσαι; Σέκος εγώ.'\n",
      " '@USER Ναι μωρη μαλακω παίρνει! Κοιτα ένα λογαριασμό της ΔΕΗ και θα καταλαβεις.'\n",
      " '@USER Είσαι ευαίσθητο πλάσμα αλλά δεν το αναγνωρίζουν τα ρεμάλια.'\n",
      " 'Αααα ναι, γαματος σεφ.... Ξεκαθαρα ΔΕΝ θα τον ηξεραν #masterchefgr #masterchefgr_xeftiles'\n",
      " \"Γιατι να μην ειμαι κι εγω σ'αυτο το κονσεπτ;! #gntmgr\"]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessedTweets[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufM4upXK2UOR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFSxRGBU-jXr"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer as bertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utvnzPv3Ar4O"
   },
   "outputs": [],
   "source": [
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ch6CWnxu5TG3",
    "outputId": "98ac5079-71cb-4244-b1c6-e74098ceedc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nids_of_sentence=[]\\nmaxlength=0\\nfor t in preprocessedTweets:\\n      #token ids\\n      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\\n      #for t in tokenized_sentence_id:\\n      #Checking max length\\n      if(maxlength<len(tokenized_sentence_id)):\\n          maxlength=len(tokenized_sentence_id)\\n      \\n      ids_of_sentence.append(tokenized_sentence_id)\\n\\nids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "ids_of_sentence=[]\n",
    "maxlength=0\n",
    "for t in preprocessedTweets:\n",
    "      #token ids\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      #for t in tokenized_sentence_id:\n",
    "      #Checking max length\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "      \n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "\n",
    "ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=64,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GnIbY9ING13E",
    "outputId": "cc292b8b-5a0d-41fd-eb3e-6668027528fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attention_masks = []\\nfor inds in ids_of_sentence_words:\\n    att_mask = [int(t_id > 0) for t_id in inds]  \\n    attention_masks.append(att_mask)'"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''attention_masks = []\n",
    "for inds in ids_of_sentence_words:\n",
    "    att_mask = [int(t_id > 0) for t_id in inds]  \n",
    "    attention_masks.append(att_mask)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsBprzLM6iuq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s47V63nd6u1g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "hVpdgDWB7-ja",
    "outputId": "59663944-cd71-41e0-be21-79895c418bae"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-122-5a83c8f8cb78>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    allLens.append(len1*1.0)/totalLen)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "\n",
    "def giveIds(sentence,y_):\n",
    "  ids_of_sentence=[]\n",
    "  ids_of_sentence_words=[]\n",
    "  attention_masks=[]\n",
    "  maxlength=0\n",
    "  averageLength=0\n",
    "  allLens=[]\n",
    "  totalLen=len(sentence)\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      len1=len(tokenized_sentence_id)\n",
    "      if(maxlength<len1):\n",
    "          maxlength=len1\n",
    "          allLens.append(len1*1.0)/totalLen)\n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "  averageLength=[for s in allLens] \n",
    "  print(maxlength)\n",
    "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
    "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
    "  #print(len(attention_masks))\n",
    "  #print(len(ids_of_sentence_words))\n",
    "  return ids_of_sentence_words,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f2S1fYRTXYi"
   },
   "outputs": [],
   "source": [
    "ids_of_sentence=[]\n",
    "ids_of_sentence_words=[]\n",
    "attention_masks=[]\n",
    "def giveIds(sentence,y_):\n",
    "  ids_of_sentence=[]\n",
    "  ids_of_sentence_words=[]\n",
    "  attention_masks=[]\n",
    "  maxlength=0\n",
    "  for t in sentence:\n",
    "      tokenized_sentence_id=tokenizer.encode(t,add_special_tokens=True)\n",
    "      if(maxlength<len(tokenized_sentence_id)):\n",
    "          maxlength=len(tokenized_sentence_id)\n",
    "      ids_of_sentence.append(tokenized_sentence_id)\n",
    "  print(maxlength)\n",
    "  ids_of_sentence_words=pad_sequences(ids_of_sentence,maxlen=maxlength,dtype=\"long\",value=0,truncating=\"post\",padding=\"post\")##can change max length\n",
    "  attention_masks = [[int(a > 0)   for a in b ]for b in ids_of_sentence_words] \n",
    "  #print(len(attention_masks))\n",
    "  #print(len(ids_of_sentence_words))\n",
    "  return ids_of_sentence_words,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fh02lGbz79_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIn1L3EaG_Ts"
   },
   "outputs": [],
   "source": [
    "#sentence_train, sentence_test, y_train, y_test= train_test_split(preprocessedTweets,y, test_size=0.1, random_state=42)\n",
    "#x_train_mask,x_test_mask,_,_=train_test_split(attention_masks,y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQDZFAOzcNYX"
   },
   "outputs": [],
   "source": [
    "##do this at the time of training only \n",
    "sentence_train, sentence_test1, y_train, y_test1 = train_test_split(preprocessedTweets,y, test_size=0.2, random_state=42) \n",
    "sentence_test,sentence_predict, y_test,y_predict = train_test_split(sentence_test1,y_test1, test_size=0.5, random_state=42)\n",
    "#x_predict_mask,_,_,_=train_test_split(x_test_mask,y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBt1IAUnLZYs"
   },
   "outputs": [],
   "source": [
    "#y_predict.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1Z4zlYAJRCb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xA_qRN1yU04y",
    "outputId": "a8884489-29f7-4603-fe16-a713e73a0531"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C = {'tweet': sentence_predict,\\n        'subtask_a': y_predict.flatten(),\\n    }\\ndf = pd.DataFrame(C, columns=['tweet', 'subtask_a'])\\nexport_csv = df.to_csv ('/content/drive/My Drive/GreekData/PredictFile.csv', index = None, header=True)\\nprint (df)\\n\""
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
    "#print(len(z))\n",
    "'''C = {'tweet': sentence_predict,\n",
    "        'subtask_a': y_predict.flatten(),\n",
    "    }\n",
    "df = pd.DataFrame(C, columns=['tweet', 'subtask_a'])\n",
    "export_csv = df.to_csv ('/content/drive/My Drive/GreekData/PredictFile.csv', index = None, header=True)\n",
    "print (df)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7CYsPFfkdWL9",
    "outputId": "f4d76167-abe9-443a-db14-8c831956998e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8983, 1)\n",
      "(1123, 1)\n",
      "(8983,)\n",
      "['NOT' 'OFF']\n",
      "['NOT' 'OFF']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_predict.shape)\n",
    "yTrain=le.fit_transform(y_train.flatten())\n",
    "print(yTrain.shape)\n",
    "print(le.classes_)\n",
    "yTest=le.fit_transform(y_test.flatten())\n",
    "print(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFcDGmeNVbKd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTrainDataset(Dataset):\n",
    "    def __init__(self,xytrain):\n",
    "        self.xytrain = xytrain\n",
    "        self.maxlength=256\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytrain[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_train_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_train_pytorch=torch.tensor(self.xytrain[1][index])\n",
    "        x_train_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_train_pytorch,x_train_mask_pytorch,y_train_pytorch\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MRzkZ70fqRJ"
   },
   "outputs": [],
   "source": [
    "#from torch.utils.data import Dataset\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekTestDataset(Dataset):\n",
    "    def __init__(self,xytest):\n",
    "        self.xytest = xytest\n",
    "        self.maxlength=256\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xytest[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_test_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_test_pytorch=torch.tensor(self.xytest[1][index])\n",
    "        x_test_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_test_pytorch,x_test_mask_pytorch,y_test_pytorch\n",
    "        #return [1,2,3]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xytest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt6HvS5-dpok"
   },
   "outputs": [],
   "source": [
    "xytrain=[sentence_train,yTrain]\n",
    "tdataset = GreekTrainDataset(xytrain)\n",
    "tsampler=RandomSampler(tdataset)\n",
    "tdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGJiYjC1fb1V"
   },
   "outputs": [],
   "source": [
    "xytest=[sentence_test,yTest]\n",
    "tedataset = GreekTestDataset(xytest)\n",
    "tesampler=RandomSampler(tedataset)\n",
    "tedataloader = DataLoader(tedataset, batch_size=32, num_workers=1, shuffle=False,sampler=tesampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2bOBLycdL0lc",
    "outputId": "a6faa47b-fa33-471b-dfc9-52f8f33a5033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification as bfsc,AdamW,BertConfig\n",
    "model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JyH9yvdIO208",
    "outputId": "4167c2c9-0352-48ce-8de7-a27dd6c8ad03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iF4guWRdOTS4"
   },
   "outputs": [],
   "source": [
    "params=list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKOeqrn-jopN"
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": 0.01,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RlThDORmMrf"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(optimizer_grouped_parameters,lr=2e-5,eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FRiX25tlMdG"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs=6\n",
    "total_steps=len(tdataloader)*epochs\n",
    "\n",
    "sch=get_linear_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps=0,num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6LNSaNZpKVT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculateF1Score(predictions,labels):\n",
    "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
    "  predictionArgmax=np.argmax(predictions,axis=1).flatten()\n",
    "  labelsFlattend=labels.flatten()\n",
    "  print(\"predictionArgmax\",predictionArgmax)\n",
    "  print(\"labelsFlattend\",labelsFlattend)\n",
    "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "brS_TJmHJs0I",
    "outputId": "ad9e9759-b629-4649-b759-2b0a0bdbd4a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch Number 1\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.40836691856384\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.51476311683655\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.73377513885498\n",
      "Batch Completed  200  of  281.    Elapsed time is  156.9239993095398\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.11154747009277\n",
      " The training loss incured is  0.537\n",
      "  Training one epoch time taken 220.30170249938965\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1]\n",
      "labelsFlattend [0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1]\n",
      "predictionArgmax [0 1 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1]\n",
      "predictionArgmax [0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 1]\n",
      "labelsFlattend [0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0]\n",
      "predictionArgmax [0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0]\n",
      "labelsFlattend [0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1]\n",
      "labelsFlattend [0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1]\n",
      "predictionArgmax [1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1]\n",
      "labelsFlattend [1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1]\n",
      "predictionArgmax [0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1]\n",
      "labelsFlattend [1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0]\n",
      "labelsFlattend [1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1]\n",
      "predictionArgmax [1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1]\n",
      "labelsFlattend [1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1]\n",
      "predictionArgmax [0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0]\n",
      "labelsFlattend [0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0]\n",
      "predictionArgmax [1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0]\n",
      "labelsFlattend [1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      "predictionArgmax [0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0]\n",
      "labelsFlattend [0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0]\n",
      "labelsFlattend [0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0]\n",
      "labelsFlattend [0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1]\n",
      "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0]\n",
      "labelsFlattend [1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1]\n",
      "predictionArgmax [1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0]\n",
      "labelsFlattend [1 0 0]\n",
      "  F1 score: 0.769\n",
      "  Accuracy score: 0.786\n",
      "  Validating one epoch time taken  8.930499076843262\n",
      "Start Epoch Number 2\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.373218059539795\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.56534099578857\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.79900455474854\n",
      "Batch Completed  200  of  281.    Elapsed time is  156.95997071266174\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.16845750808716\n",
      " The training loss incured is  0.382\n",
      "  Training one epoch time taken 220.32982325553894\n",
      " Validation starts here \n",
      "predictionArgmax [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0]\n",
      "labelsFlattend [1 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1]\n",
      "labelsFlattend [1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0]\n",
      "predictionArgmax [1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1]\n",
      "predictionArgmax [1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1]\n",
      "labelsFlattend [1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "labelsFlattend [0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0]\n",
      "labelsFlattend [0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1 1]\n",
      "labelsFlattend [0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1]\n",
      "predictionArgmax [0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0]\n",
      "labelsFlattend [0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
      "labelsFlattend [1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1]\n",
      "predictionArgmax [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1]\n",
      "labelsFlattend [1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0]\n",
      "predictionArgmax [0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0]\n",
      "labelsFlattend [0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0]\n",
      "predictionArgmax [0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1]\n",
      "labelsFlattend [0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1]\n",
      "predictionArgmax [0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0]\n",
      "labelsFlattend [1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1]\n",
      "predictionArgmax [1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1]\n",
      "predictionArgmax [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1]\n",
      "labelsFlattend [0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1]\n",
      "predictionArgmax [0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1]\n",
      "labelsFlattend [0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1]\n",
      "predictionArgmax [1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1]\n",
      "labelsFlattend [1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1]\n",
      "predictionArgmax [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0]\n",
      "predictionArgmax [1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0]\n",
      "predictionArgmax [1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0]\n",
      "labelsFlattend [1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0]\n",
      "predictionArgmax [1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0]\n",
      "predictionArgmax [0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0]\n",
      "labelsFlattend [0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0]\n",
      "labelsFlattend [1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 1]\n",
      "labelsFlattend [0 0 1]\n",
      "  F1 score: 0.814\n",
      "  Accuracy score: 0.822\n",
      "  Validating one epoch time taken  8.912525177001953\n",
      "Start Epoch Number 3\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.42240810394287\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.6465528011322\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.87231874465942\n",
      "Batch Completed  200  of  281.    Elapsed time is  157.12441515922546\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.31206798553467\n",
      " The training loss incured is  0.288\n",
      "  Training one epoch time taken 220.40471982955933\n",
      " Validation starts here \n",
      "predictionArgmax [1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0]\n",
      "labelsFlattend [1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0]\n",
      "predictionArgmax [0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0]\n",
      "labelsFlattend [1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1]\n",
      "labelsFlattend [1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0]\n",
      "labelsFlattend [1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      "predictionArgmax [1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0]\n",
      "predictionArgmax [0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1]\n",
      "labelsFlattend [0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1]\n",
      "predictionArgmax [1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [1 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1]\n",
      "labelsFlattend [1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0]\n",
      "predictionArgmax [1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0]\n",
      "labelsFlattend [1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0]\n",
      "labelsFlattend [1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0]\n",
      "labelsFlattend [0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1]\n",
      "labelsFlattend [0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1]\n",
      "predictionArgmax [0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1]\n",
      "labelsFlattend [0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1]\n",
      "labelsFlattend [1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0]\n",
      "labelsFlattend [1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0]\n",
      "labelsFlattend [0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 0]\n",
      "predictionArgmax [1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0]\n",
      "labelsFlattend [1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "predictionArgmax [1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0]\n",
      "labelsFlattend [1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0]\n",
      "predictionArgmax [1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1]\n",
      "labelsFlattend [1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0]\n",
      "predictionArgmax [1 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1]\n",
      "labelsFlattend [0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1]\n",
      "predictionArgmax [1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0]\n",
      "labelsFlattend [1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0]\n",
      "predictionArgmax [1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0]\n",
      "labelsFlattend [1 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0]\n",
      "predictionArgmax [0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1]\n",
      "labelsFlattend [0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0]\n",
      "labelsFlattend [1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 1 0]\n",
      "predictionArgmax [1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0]\n",
      "labelsFlattend [1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0]\n",
      "predictionArgmax [1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1]\n",
      "labelsFlattend [1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0]\n",
      "predictionArgmax [1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0]\n",
      "labelsFlattend [0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0]\n",
      "predictionArgmax [0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1]\n",
      "labelsFlattend [0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0]\n",
      "labelsFlattend [0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "predictionArgmax [0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1]\n",
      "labelsFlattend [0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1]\n",
      "predictionArgmax [1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0]\n",
      "labelsFlattend [1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0]\n",
      "predictionArgmax [0 1 0]\n",
      "labelsFlattend [0 1 0]\n",
      "  F1 score: 0.853\n",
      "  Accuracy score: 0.857\n",
      "  Validating one epoch time taken  8.934643745422363\n",
      "Start Epoch Number 4\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.40179371833801\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.60117197036743\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.79394245147705\n",
      "Batch Completed  200  of  281.    Elapsed time is  157.0081639289856\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.14495611190796\n",
      " The training loss incured is  0.214\n",
      "  Training one epoch time taken 220.32420825958252\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0]\n",
      "labelsFlattend [0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1]\n",
      "predictionArgmax [0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1]\n",
      "predictionArgmax [0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0]\n",
      "labelsFlattend [1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0]\n",
      "predictionArgmax [1 1 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1]\n",
      "labelsFlattend [1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1]\n",
      "predictionArgmax [0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0]\n",
      "labelsFlattend [0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0]\n",
      "predictionArgmax [1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0]\n",
      "labelsFlattend [1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0]\n",
      "predictionArgmax [1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1]\n",
      "labelsFlattend [1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1]\n",
      "predictionArgmax [1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0]\n",
      "labelsFlattend [1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0]\n",
      "predictionArgmax [1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0]\n",
      "labelsFlattend [1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0]\n",
      "predictionArgmax [1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0]\n",
      "predictionArgmax [1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0]\n",
      "labelsFlattend [1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1]\n",
      "labelsFlattend [0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1]\n",
      "predictionArgmax [1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1]\n",
      "labelsFlattend [1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1]\n",
      "predictionArgmax [1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0]\n",
      "labelsFlattend [1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "predictionArgmax [1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0]\n",
      "labelsFlattend [1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0]\n",
      "labelsFlattend [0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1]\n",
      "predictionArgmax [1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0]\n",
      "labelsFlattend [1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0]\n",
      "labelsFlattend [0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0]\n",
      "predictionArgmax [0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0]\n",
      "labelsFlattend [0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0]\n",
      "predictionArgmax [1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 1 1]\n",
      "labelsFlattend [1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1]\n",
      "predictionArgmax [1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      "labelsFlattend [0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0]\n",
      "predictionArgmax [1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0]\n",
      "labelsFlattend [1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1]\n",
      "labelsFlattend [0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1]\n",
      "labelsFlattend [0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1]\n",
      "labelsFlattend [0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1]\n",
      "predictionArgmax [0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0]\n",
      "labelsFlattend [1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0]\n",
      "predictionArgmax [1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1]\n",
      "labelsFlattend [0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1]\n",
      "predictionArgmax [1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0]\n",
      "labelsFlattend [1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0]\n",
      "labelsFlattend [1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0]\n",
      "predictionArgmax [0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1]\n",
      "labelsFlattend [0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1]\n",
      "predictionArgmax [1 1 1]\n",
      "labelsFlattend [1 1 1]\n",
      "  F1 score: 0.877\n",
      "  Accuracy score: 0.881\n",
      "  Validating one epoch time taken  8.939869165420532\n",
      "Start Epoch Number 5\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.361674785614014\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.5666434764862\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.71689939498901\n",
      "Batch Completed  200  of  281.    Elapsed time is  156.88914823532104\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.00418424606323\n",
      " The training loss incured is  0.155\n",
      "  Training one epoch time taken 220.16265869140625\n",
      " Validation starts here \n",
      "predictionArgmax [1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1]\n",
      "labelsFlattend [0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1]\n",
      "labelsFlattend [0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1]\n",
      "predictionArgmax [0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1]\n",
      "labelsFlattend [0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0]\n",
      "predictionArgmax [1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0]\n",
      "labelsFlattend [0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 0 1 0 0]\n",
      "predictionArgmax [1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1]\n",
      "labelsFlattend [1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1]\n",
      "predictionArgmax [0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1]\n",
      "labelsFlattend [1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0]\n",
      "predictionArgmax [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1]\n",
      "labelsFlattend [1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1]\n",
      "labelsFlattend [1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1]\n",
      "predictionArgmax [0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1]\n",
      "labelsFlattend [1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1]\n",
      "predictionArgmax [0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1]\n",
      "labelsFlattend [0 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1]\n",
      "labelsFlattend [0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0]\n",
      "labelsFlattend [0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0]\n",
      "predictionArgmax [1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1]\n",
      "labelsFlattend [1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1]\n",
      "predictionArgmax [0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1]\n",
      "labelsFlattend [0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1]\n",
      "labelsFlattend [0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1]\n",
      "predictionArgmax [1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0]\n",
      "labelsFlattend [1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0]\n",
      "predictionArgmax [0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0]\n",
      "labelsFlattend [0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0]\n",
      "predictionArgmax [1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1]\n",
      "labelsFlattend [1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0]\n",
      "predictionArgmax [1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0]\n",
      "labelsFlattend [1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "predictionArgmax [1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0]\n",
      "labelsFlattend [1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0]\n",
      "predictionArgmax [1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1]\n",
      "labelsFlattend [1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1]\n",
      "predictionArgmax [0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1]\n",
      "labelsFlattend [0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1]\n",
      "predictionArgmax [0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0]\n",
      "labelsFlattend [0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "predictionArgmax [0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0]\n",
      "predictionArgmax [0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "labelsFlattend [0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0]\n",
      "predictionArgmax [1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1]\n",
      "labelsFlattend [0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 1]\n",
      "predictionArgmax [1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0]\n",
      "labelsFlattend [1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0]\n",
      "predictionArgmax [0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0]\n",
      "labelsFlattend [0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0]\n",
      "predictionArgmax [1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0]\n",
      "labelsFlattend [1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0]\n",
      "predictionArgmax [0 1 0]\n",
      "labelsFlattend [0 1 0]\n",
      "  F1 score: 0.886\n",
      "  Accuracy score: 0.891\n",
      "  Validating one epoch time taken  8.929396867752075\n",
      "Start Epoch Number 6\n",
      "Start Training\n",
      "Batch Completed  50  of  281.    Elapsed time is  39.333192110061646\n",
      "Batch Completed  100  of  281.    Elapsed time is  78.47934460639954\n",
      "Batch Completed  150  of  281.    Elapsed time is  117.67035913467407\n",
      "Batch Completed  200  of  281.    Elapsed time is  156.87446403503418\n",
      "Batch Completed  250  of  281.    Elapsed time is  196.04568791389465\n",
      " The training loss incured is  0.117\n",
      "  Training one epoch time taken 220.26603174209595\n",
      " Validation starts here \n",
      "predictionArgmax [0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1]\n",
      "labelsFlattend [0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1]\n",
      "predictionArgmax [0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0]\n",
      "labelsFlattend [0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 0]\n",
      "labelsFlattend [0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0]\n",
      "predictionArgmax [1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 0]\n",
      "labelsFlattend [1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0]\n",
      "predictionArgmax [0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0]\n",
      "labelsFlattend [0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0]\n",
      "predictionArgmax [0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1]\n",
      "labelsFlattend [0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1]\n",
      "labelsFlattend [0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1]\n",
      "labelsFlattend [0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1]\n",
      "predictionArgmax [0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1]\n",
      "labelsFlattend [0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1]\n",
      "predictionArgmax [0 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 1]\n",
      "labelsFlattend [0 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1]\n",
      "labelsFlattend [1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1]\n",
      "predictionArgmax [1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0]\n",
      "labelsFlattend [1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1]\n",
      "labelsFlattend [0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1]\n",
      "predictionArgmax [1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0]\n",
      "labelsFlattend [1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "predictionArgmax [0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0]\n",
      "labelsFlattend [0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0]\n",
      "predictionArgmax [1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1]\n",
      "labelsFlattend [0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1]\n",
      "predictionArgmax [0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0]\n",
      "labelsFlattend [0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0]\n",
      "predictionArgmax [0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1]\n",
      "labelsFlattend [0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1]\n",
      "predictionArgmax [0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0]\n",
      "predictionArgmax [0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1]\n",
      "labelsFlattend [0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0]\n",
      "predictionArgmax [0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1]\n",
      "labelsFlattend [0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1]\n",
      "predictionArgmax [0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1]\n",
      "labelsFlattend [0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1]\n",
      "predictionArgmax [0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1]\n",
      "labelsFlattend [0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1]\n",
      "predictionArgmax [0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0]\n",
      "labelsFlattend [0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0]\n",
      "predictionArgmax [1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1]\n",
      "labelsFlattend [1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1]\n",
      "predictionArgmax [1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "labelsFlattend [1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1]\n",
      "labelsFlattend [0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "predictionArgmax [1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1]\n",
      "labelsFlattend [1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1]\n",
      "predictionArgmax [1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0]\n",
      "labelsFlattend [1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0]\n",
      "predictionArgmax [0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0]\n",
      "labelsFlattend [0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0]\n",
      "predictionArgmax [1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1]\n",
      "labelsFlattend [1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1]\n",
      "predictionArgmax [0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1]\n",
      "labelsFlattend [0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1]\n",
      "predictionArgmax [1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0]\n",
      "labelsFlattend [1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1]\n",
      "predictionArgmax [1 1 0]\n",
      "labelsFlattend [1 1 0]\n",
      "  F1 score: 0.887\n",
      "  Accuracy score: 0.891\n",
      "  Validating one epoch time taken  8.959425210952759\n",
      "ALL DONE!!!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "def set_seed(seed,ngpu):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if ngpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "      \n",
    "set_seed(42,torch.cuda.device_count())\n",
    "#remove later\n",
    "\n",
    "lossList=[]\n",
    "max_grad_norm=1.0\n",
    "for e in range(0, epochs):\n",
    "    print(\"Start Epoch Number\",(e + 1))\n",
    "    print(\"Start Training\")\n",
    "    \n",
    "    #Amount of time taken for training\n",
    "    t1 = time.time()\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    tsteps=0\n",
    "    for step, batch in enumerate(tdataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"Batch Completed  {:,}  of  {:,}.    Elapsed time is  {}\".format(step, len(tdataloader),time.time() - t1))\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        model.zero_grad()        \n",
    "        outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"], labels=inputs[\"labels\"])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        tsteps+=1\n",
    "        optimizer.step()\n",
    "        sch.step()\n",
    "\n",
    "    a_tr_loss = tr_loss /(tsteps)               \n",
    "    lossList.append(a_tr_loss)\n",
    "    \n",
    "    print(\" The training loss incured is  {0:.3f}\".format(a_tr_loss))\n",
    "    t2=time.time()\n",
    "    print(\"  Training one epoch time taken\",t2-t1)\n",
    "    print(\" Validation starts here \")\n",
    "   \n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_f1=0\n",
    "    eval_acc=0\n",
    "\n",
    "    for batch in tedataloader:       \n",
    "        batch = tuple(t.to(device) for t in batch)        \n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "        tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "        eval_f1 = eval_f1+tmpf1score\n",
    "        eval_acc=eval_acc+tmpaccscore\n",
    "        nb_eval_steps += 1\n",
    "        #print(\" TEMP F1 score: {0:.3f}\".format(tmpf1score))\n",
    "        #print(\"TEMP  Accuracy score: {0:.3f}\".format(tmpaccscore))\n",
    "\n",
    "\n",
    "    print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "    print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "    \n",
    "    t2=time.time()\n",
    "    print(\"  Validating one epoch time taken \",t2-t1)\n",
    "    \n",
    "print(\"ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F-oJKkuabfDM",
    "outputId": "55b7b795-6fec-4ebd-d62d-86a06c5081ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4rWdrUSxJIV"
   },
   "outputs": [],
   "source": [
    "##WITH AND WITHOUT PREPROCESSING F1 and accuracy score stuck at 0.755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "K8VFcl1gBfU-",
    "outputId": "7e5342ce-0faa-4799-f976-4a8f7739cfa1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-42b6107215b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlkhjkdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lkhjkdb' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWKfHXfplWQ_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#tokenizer=bertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=True)\n",
    "class GreekPredictDataset(Dataset):\n",
    "    def __init__(self,xypredict):\n",
    "        self.xypredict = xypredict\n",
    "        self.maxlength=128\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_review = tokenizer.tokenize(str(self.xypredict[0][index]))\n",
    "        if len(tokenized_review) > self.maxlength:\n",
    "            #print(tokenized_review)\n",
    "            tokenized_review = tokenized_review[:self.maxlength]\n",
    "        \n",
    "        \n",
    "        ids_of_sentence_word  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
    "        padding = [0] * (self.maxlength - len(ids_of_sentence_word))\n",
    "        ids_of_sentence_word += padding\n",
    "        assert len(ids_of_sentence_word) == self.maxlength\n",
    "        #print(ids_of_sentence_word)\n",
    "        attention_mask = [int(b > 0) for b in ids_of_sentence_word] \n",
    "        x_predict_pytorch = torch.tensor(ids_of_sentence_word)\n",
    "        y_predict_pytorch=torch.tensor(self.xypredict[1][index])\n",
    "        x_predict_mask_pytorch=torch.tensor(attention_mask)\n",
    "        \n",
    "        return x_predict_pytorch,x_predict_mask_pytorch,y_predict_pytorch\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.xypredict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3Gp5gPddxj"
   },
   "outputs": [],
   "source": [
    "def predictingData(pTweets,ypred):\n",
    "  #https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=1M296yz577fV\n",
    "  ids_of_sentence=[]\n",
    "  predictedLabels,trueLabels=[],[]\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ypredict=le.fit_transform(ypred.flatten())\n",
    "  map_location=\"\"\n",
    "  xypredict=[pTweets,ypredict]\n",
    "  tdataset = GreekPredictDataset(xypredict)\n",
    "  tsampler=RandomSampler(tdataset)\n",
    "  predictdataloader = DataLoader(tdataset, batch_size=32, num_workers=1, shuffle=False,sampler=tsampler)\n",
    "  print(device.type)\n",
    "  model=bfsc.from_pretrained('bert-base-multilingual-cased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "  if device.type==\"cpu\":\n",
    "    model.to(device)\n",
    "    map_location='cpu'\n",
    "  else:\n",
    "    model.cuda()\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "  params=list(model.named_parameters())\n",
    "  eval_f1=0\n",
    "  eval_acc=0\n",
    "  nb_eval_steps=0\n",
    "  checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar',map_location=map_location)\n",
    "  print(\"Hello\")\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "  i=0\n",
    "  for batch in predictdataloader:\n",
    "      #print(i)\n",
    "      i=i+1\n",
    "      batch = tuple(t.to(device) for t in batch)        \n",
    "      inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "      \n",
    "      with torch.no_grad():       \n",
    "          outputs = model(inputs[\"input_ids\"],token_type_ids=None,attention_mask=inputs[\"attention_mask\"])\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = (inputs[\"labels\"]).to('cpu').numpy()\n",
    "      predictedLabels.append(logits)\n",
    "      trueLabels.append(label_ids)\n",
    "      tmpf1score,tmpaccscore = calculateF1Score(logits, label_ids)\n",
    "      eval_f1 = eval_f1+tmpf1score\n",
    "      eval_acc=eval_acc+tmpaccscore\n",
    "      nb_eval_steps += 1\n",
    "      \n",
    "  print(\"  F1 score: {0:.3f}\".format(eval_f1/nb_eval_steps))\n",
    "  print(\"  Accuracy score: {0:.3f}\".format(eval_acc/nb_eval_steps))\n",
    "  return predictedLabels,trueLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-v3ajuk04jw-"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save({'state_dict': model.state_dict()}, '/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "checkpoint = torch.load('/content/drive/My Drive/GreekData/bertgreek.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JQ-v9vkBMEZo",
    "outputId": "2e037193-b7b7-40d4-f028-b99d35237220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Hello\n",
      "predictionArgmax [1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0]\n",
      "labelsFlattend [1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "predictionArgmax [0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0]\n",
      "predictionArgmax [0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0]\n",
      "labelsFlattend [0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0]\n",
      "predictionArgmax [1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1]\n",
      "labelsFlattend [1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1]\n",
      "predictionArgmax [0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0]\n",
      "labelsFlattend [0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0]\n",
      "predictionArgmax [0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1]\n",
      "labelsFlattend [0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0]\n",
      "labelsFlattend [0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1]\n",
      "labelsFlattend [1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1]\n",
      "predictionArgmax [0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1]\n",
      "labelsFlattend [0 0 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1]\n",
      "predictionArgmax [1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1]\n",
      "labelsFlattend [1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1]\n",
      "predictionArgmax [0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0]\n",
      "labelsFlattend [0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0]\n",
      "predictionArgmax [0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0]\n",
      "labelsFlattend [0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0]\n",
      "labelsFlattend [0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0]\n",
      "labelsFlattend [1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\n",
      "predictionArgmax [1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1]\n",
      "labelsFlattend [1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1]\n",
      "predictionArgmax [0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0]\n",
      "labelsFlattend [0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1]\n",
      "labelsFlattend [1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1]\n",
      "predictionArgmax [1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "labelsFlattend [1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      "predictionArgmax [1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1]\n",
      "labelsFlattend [1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1]\n",
      "predictionArgmax [1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1]\n",
      "labelsFlattend [1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      "labelsFlattend [1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1]\n",
      "predictionArgmax [1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "labelsFlattend [0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1]\n",
      "predictionArgmax [1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0]\n",
      "labelsFlattend [1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1]\n",
      "predictionArgmax [1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0]\n",
      "labelsFlattend [1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0]\n",
      "predictionArgmax [1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1]\n",
      "labelsFlattend [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1]\n",
      "predictionArgmax [0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0]\n",
      "labelsFlattend [0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0]\n",
      "predictionArgmax [0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0]\n",
      "labelsFlattend [0 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0]\n",
      "predictionArgmax [1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1]\n",
      "labelsFlattend [1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "predictionArgmax [0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1]\n",
      "labelsFlattend [0 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "predictionArgmax [0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1]\n",
      "labelsFlattend [0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0]\n",
      "predictionArgmax [1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0]\n",
      "labelsFlattend [1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0]\n",
      "predictionArgmax [0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1]\n",
      "labelsFlattend [1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1]\n",
      "predictionArgmax [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1]\n",
      "labelsFlattend [0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0]\n",
      "predictionArgmax [0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1]\n",
      "labelsFlattend [0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1]\n",
      "predictionArgmax [1 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1]\n",
      "labelsFlattend [1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1]\n",
      "predictionArgmax [1 0 0]\n",
      "labelsFlattend [1 0 0]\n",
      "  F1 score: 0.877\n",
      "  Accuracy score: 0.884\n"
     ]
    }
   ],
   "source": [
    "#modelInitialize tokenizer and sequence classification\n",
    "predictedLabels,trueLabels=predictingData(sentence_predict,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBxBKJFVaFjr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3_AaAvxliJm"
   },
   "source": [
    "from 80 ,10 ,10 split getting  # F1 score: 0.836 Accuracy score: 0.867"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERTCodalabestingAndTrainGreekFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
