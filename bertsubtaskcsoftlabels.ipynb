{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bertsubtaskcsoftlabels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b08da1fbff11411eb6a9db8efd66cb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0737322b65f94389b52e8983131ba792",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4f5c631d5704393819dc3ba12a222a3",
              "IPY_MODEL_9740ed8f29a04153b513b4dcb19d795d"
            ]
          }
        },
        "0737322b65f94389b52e8983131ba792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4f5c631d5704393819dc3ba12a222a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13735bf084f349539619374b4b033c9a",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 188973,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85966,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a06bd173d2443339033e103e2247411"
          }
        },
        "9740ed8f29a04153b513b4dcb19d795d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ad2c31c804e4c6fa9ffe2c9369060c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45% 85714/188973 [00:36&lt;00:42, 2418.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f227cb91f7a34e6490e05dd264843789"
          }
        },
        "13735bf084f349539619374b4b033c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a06bd173d2443339033e103e2247411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ad2c31c804e4c6fa9ffe2c9369060c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f227cb91f7a34e6490e05dd264843789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhCLCTtuAhul",
        "colab_type": "code",
        "outputId": "52646e39-e5ee-4213-dc65-c0a863a685e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypQ5E9bxIQtq",
        "colab_type": "text"
      },
      "source": [
        "#this model is  inspired from \n",
        "#https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRTh77-LIUhx",
        "colab_type": "text"
      },
      "source": [
        "#https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_OUS9PLIWrU",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/strongio/keras-bert/blob/d81d6cd21c7c191a766ae671ed040f4f8868b561/keras-bert.py#L155"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJZY-JygIS6s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlleXY4xAsET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##NOT FOR SYSTEMS\n",
        "!unzip -P ****** -qq '/content/drive/My Drive/EnglishDatac/task_c_distant.zip' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCdwDXghJGlI",
        "colab_type": "code",
        "outputId": "4fe18d42-5e63-41d2-a6c8-705cde76861b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh2YHOt7H770",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "e22034b5-8b2a-4e9b-fd0b-5ad273ac4997"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from bert.tokenization import FullTokenizer\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras import backend as K\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHbDCk1HAoWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2aa44c18-2d21-4086-a748-097e6f8002f8"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbYuUFf9H_do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Params for bert model and tokenization\n",
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "max_seq_length = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LJq8AGiLSTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convertToFloat(val):\n",
        "    if not val:\n",
        "        return 0    \n",
        "    try:\n",
        "        return np.float64(val)\n",
        "    except:        \n",
        "        return np.float64(0)\n",
        "\n",
        "\n",
        "headers=['id','text','average_ind','average_grp','average_oth','std_ind','std_grp','std_oth']\n",
        "taskc = pd.read_csv(\"task_c_distant_ann.tsv\", delimiter='\\t',names=headers,low_memory=False,converters={\"average_ind\":convertToFloat,\n",
        "                                                                                                    \"average_grp\":convertToFloat,\n",
        "                                                                                                    \"average_oth\":convertToFloat,\n",
        "                                                                                                    \"std_ind\":convertToFloat,\n",
        "                                                                                                    \"std_grp\":convertToFloat,\n",
        "                                                                                                    \"std_oth\":convertToFloat})\n",
        "taskc=taskc[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZlsG1eLks2",
        "colab_type": "code",
        "outputId": "f6f2a1ba-6545-4e87-b001-6d00be90283e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "taskc.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average_ind</th>\n",
              "      <th>average_grp</th>\n",
              "      <th>average_oth</th>\n",
              "      <th>std_ind</th>\n",
              "      <th>std_grp</th>\n",
              "      <th>std_oth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1159533712079503361</td>\n",
              "      <td>@USER Trump is a fucking idiot his dementia is...</td>\n",
              "      <td>0.833432</td>\n",
              "      <td>0.076110</td>\n",
              "      <td>0.107765</td>\n",
              "      <td>0.208334</td>\n",
              "      <td>0.098937</td>\n",
              "      <td>0.138649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1159533713044234241</td>\n",
              "      <td>@USER HELL YES! His grinned and thumbs up are ...</td>\n",
              "      <td>0.481062</td>\n",
              "      <td>0.367363</td>\n",
              "      <td>0.138841</td>\n",
              "      <td>0.345225</td>\n",
              "      <td>0.335924</td>\n",
              "      <td>0.083230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1159533718345830400</td>\n",
              "      <td>@USER Can't wait to see the shit show his deat...</td>\n",
              "      <td>0.438813</td>\n",
              "      <td>0.268574</td>\n",
              "      <td>0.377573</td>\n",
              "      <td>0.182609</td>\n",
              "      <td>0.186880</td>\n",
              "      <td>0.254621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1159533739871002625</td>\n",
              "      <td>@USER @USER @USER This guys is dumb check his ...</td>\n",
              "      <td>0.712995</td>\n",
              "      <td>0.123504</td>\n",
              "      <td>0.111130</td>\n",
              "      <td>0.248839</td>\n",
              "      <td>0.107572</td>\n",
              "      <td>0.067552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1159533742366633984</td>\n",
              "      <td>@USER @USER Fuck him better than his hoes</td>\n",
              "      <td>0.691414</td>\n",
              "      <td>0.146723</td>\n",
              "      <td>0.192282</td>\n",
              "      <td>0.204415</td>\n",
              "      <td>0.154818</td>\n",
              "      <td>0.104436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...   std_oth\n",
              "1  1159533712079503361  ...  0.138649\n",
              "2  1159533713044234241  ...  0.083230\n",
              "3  1159533718345830400  ...  0.254621\n",
              "4  1159533739871002625  ...  0.067552\n",
              "5  1159533742366633984  ...  0.104436\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_l5T9EJLyMg",
        "colab_type": "code",
        "outputId": "665e4939-c845-4c93-8526-d43614b4526e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "taskc.values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['1159533712079503361',\n",
              "        '@USER Trump is a fucking idiot his dementia is getting worse',\n",
              "        0.8334315660070198, ..., 0.20833409336419706,\n",
              "        0.09893746284301566, 0.1386493230104102],\n",
              "       ['1159533713044234241',\n",
              "        '@USER HELL YES! His grinned and thumbs up are disgusting!',\n",
              "        0.48106237178573397, ..., 0.3452248610539589,\n",
              "        0.33592350092689993, 0.08323036242339713],\n",
              "       ['1159533718345830400',\n",
              "        \"@USER Can't wait to see the shit show his death will bring.\",\n",
              "        0.4388127663192773, ..., 0.18260870386171185,\n",
              "        0.18688048564468512, 0.25462109958562573],\n",
              "       ...,\n",
              "       ['1187636295306268673',\n",
              "        'I meant tool but the point is women ain‚Äôt shit. üôÖüèª\\u200d‚ôÇÔ∏èü§∑üèª\\u200d‚ôÇÔ∏è',\n",
              "        0.36375786996300313, ..., 0.23943555651707127,\n",
              "        0.16535075005267147, 0.09506541000311416],\n",
              "       ['1187636299785744384', '@USER i sang too the fuck-',\n",
              "        0.5982300263631064, ..., 0.19187065632830977,\n",
              "        0.10707485138459394, 0.11520566509045577],\n",
              "       ['1187636316487520258',\n",
              "        'obviously ur allowed to not like the ship but using that excuse is so stale like fuck off.',\n",
              "        0.6849481559629798, ..., 0.19227685039701298,\n",
              "        0.14081314237397982, 0.16559246442850858]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfa9MbOBMBlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfnumpy=taskc.to_numpy();\n",
        "x=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y_train1=dfnumpy[:, 2].reshape(-1, 1)\n",
        "y_train2=dfnumpy[:, 3].reshape(-1, 1)\n",
        "y_train3=dfnumpy[:, 4].reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_idtKA4oNkU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=np.stack((y_train1.flatten(),y_train2.flatten(),y_train3.flatten()), axis=-1, out=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX2XZKTtOPNN",
        "colab_type": "code",
        "outputId": "cb2beeff-abb7-4264-97c6-4b2345c86dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "y_train2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07610979866070268],\n",
              "       [0.3673629474131143],\n",
              "       [0.2685740368872388],\n",
              "       ...,\n",
              "       [0.43151670865663655],\n",
              "       [0.16155983352929942],\n",
              "       [0.15227155079903518]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFsTfX5oOKve",
        "colab_type": "code",
        "outputId": "ed78d578-a48a-49b0-844f-be7a78c67754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "y[0:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8334315660070198, 0.07610979866070268, 0.10776452321727449],\n",
              "       [0.48106237178573397, 0.3673629474131143, 0.13884137991817902],\n",
              "       [0.4388127663192773, 0.2685740368872388, 0.3775726696311655],\n",
              "       [0.7129954339515537, 0.12350408671699416, 0.11113008071093726],\n",
              "       [0.6914140593727042, 0.14672323837904971, 0.19228166422122278]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-pgXoMdOQ9-",
        "colab_type": "code",
        "outputId": "a9efd0f5-3d3d-41e8-a929-10a80b1be02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQS_yVdMYUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords \n",
        "import re\n",
        "import string\n",
        "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
        "stopwords=set(stopwords.words('english'))\n",
        "def preprocessinglib(arrt):\n",
        "    ans =[]\n",
        "    for txt in arrt:\n",
        "        unique_words = dict.fromkeys(txt.split())\n",
        "        txt2=' '.join(unique_words)\n",
        "        tokens=tknzr.tokenize(txt2)\n",
        "        ctokens=[]\n",
        "        for t in tokens:\n",
        "          if  t not in stopwords and t not in string.punctuation :\n",
        "            ctokens.append(t)\n",
        "        #cs=ctokens[0:max_seq_length]\n",
        "        clean_s = ' '.join(ctokens)\n",
        "        ans.append(clean_s)\n",
        "               \n",
        "    return ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azbHYpXqOKOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=preprocessinglib(x[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3zIfiS_S9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "preprocessedTweets,y=shuffle(preprocessedTweets,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqqgNBoZVZ4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the dependencies\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM,SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2yqhPfvMZl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=preprocessedTweets\n",
        "y_train=y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgmZA1-rTQ6p",
        "colab_type": "code",
        "outputId": "d47bb467-3624-4a9f-819c-8e1b2fe6d4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32970500650729356, 0.17999333857533661, 0.5282886149584926],\n",
              "       [0.7917002313617327, 0.09223190703485422, 0.11158894406489282],\n",
              "       [0.17462440898700485, 0.665503975441615, 0.20898024553828357],\n",
              "       ...,\n",
              "       [0.5362114789259027, 0.21174702781058236, 0.3051222130387538],\n",
              "       [0.553953214916959, 0.14026104093205793, 0.3430198312192558],\n",
              "       [0.5924243074190462, 0.282917964711436, 0.20051719942393592]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPiDs7spYrvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#GET THE DATA FROM THE PANDAS FRAME\n",
        "headers=['id','tweet','subtask_a','subtask_b','subtask_c']\n",
        "englishdata = pd.read_csv(\"/content/drive/My Drive/EnglishDatac/olid-training-v1.0.tsv\", delimiter='\\t',names=headers,low_memory=False)\n",
        "englishdata=englishdata[['id','tweet','subtask_c']]\n",
        "englishdata=englishdata[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbrjgENsY0o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "englishdata = englishdata.dropna(subset=['subtask_c'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqyEoGaqZAzU",
        "colab_type": "code",
        "outputId": "62de2537-1f2f-4d43-c209-1d8618b98096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "englishdata.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>52415</td>\n",
              "      <td>@USER was literally just talking about this lo...</td>\n",
              "      <td>GRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesn‚Äôt need another CUCK! We alr...</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>28414</td>\n",
              "      <td>@USER you are a lying corrupt traitor!!! Nobod...</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              tweet subtask_c\n",
              "2   90194  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...       IND\n",
              "6   97670                  @USER Liberals are all Kookoo !!!       OTH\n",
              "8   52415  @USER was literally just talking about this lo...       GRP\n",
              "10  13384  @USER Canada doesn‚Äôt need another CUCK! We alr...       IND\n",
              "13  28414  @USER you are a lying corrupt traitor!!! Nobod...       IND"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XAi1jQ-ZjRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSeWOamBfR_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfnumpy=englishdata.to_numpy()\n",
        "x_test=dfnumpy[:, 1].reshape(-1, 1)\n",
        "y_test=dfnumpy[:, 2].reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNQoqRTDftGd",
        "colab_type": "code",
        "outputId": "c1ce49b6-fd88-480d-ab29-95be421e2e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['IND'],\n",
              "       ['OTH'],\n",
              "       ['GRP'],\n",
              "       ...,\n",
              "       ['GRP'],\n",
              "       ['IND'],\n",
              "       ['OTH']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy4yoE9-gVmS",
        "colab_type": "code",
        "outputId": "ff1992b9-a139-4383-f650-0cdfe2174943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(y_test.flatten())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH6_69JAdl0_",
        "colab_type": "code",
        "outputId": "07896ebb-8552-45d5-bf7a-9605dffc8c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_test.flatten())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nuiWCx-TOcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oyEZlsCT7Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module():\n",
        "    bert_module =  hub.Module(bert_path)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy0l9iGpUtqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
        "    \n",
        "   \n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9jPYpVnhJ9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbvR_pNvUwIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRv6hg2XUyOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_text_to_examples(texts, labels):\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3GZ8R6CVUXN",
        "colab_type": "code",
        "outputId": "d4c03878-b474-4caa-beca-56cf2cd3021e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "tokenizer = create_tokenizer_from_hub_module()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o3HGXIycmNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_fine_tune_layers=10,\n",
        "        pooling=\"first\",\n",
        "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        self.pooling = pooling\n",
        "        self.bert_path = bert_path\n",
        "        if self.pooling not in [\"first\", \"mean\"]:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(\n",
        "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
        "        )\n",
        "\n",
        "        # Remove unused layers\n",
        "        trainable_vars = self.bert.variables\n",
        "        if self.pooling == \"first\":\n",
        "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "            trainable_layers = [\"pooler/dense\"]\n",
        "\n",
        "        elif self.pooling == \"mean\":\n",
        "            trainable_vars = [\n",
        "                var\n",
        "                for var in trainable_vars\n",
        "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
        "            ]\n",
        "            trainable_layers = []\n",
        "        else:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        # Select how many layers to fine tune\n",
        "        for i in range(self.n_fine_tune_layers):\n",
        "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
        "\n",
        "        # Update trainable vars to contain only the specified layers\n",
        "        trainable_vars = [\n",
        "            var\n",
        "            for var in trainable_vars\n",
        "            if any([l in var.name for l in trainable_layers])\n",
        "        ]\n",
        "\n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "\n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:\n",
        "                self._non_trainable_weights.append(var)\n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        if self.pooling == \"first\":\n",
        "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"pooled_output\"\n",
        "            ]\n",
        "        elif self.pooling == \"mean\":\n",
        "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"sequence_output\"\n",
        "            ]\n",
        "\n",
        "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
        "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
        "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
        "            input_mask = tf.cast(input_mask, tf.float32)\n",
        "            pooled = masked_reduce_mean(result, input_mask)\n",
        "        else:\n",
        "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
        "\n",
        "        return pooled\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDgfMb9dcm8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "def build_model(max_seq_length): \n",
        "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
        "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
        "    pred = tf.keras.layers.Dense(3, activation='softmax')(dense)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev6alrDsfSJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfIM7pWfiNV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets1=preprocessinglib(x_test[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBC5wt7KidS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def giveLabel2(y1):\n",
        "  i=0\n",
        "  largest_index=0\n",
        "  #label1=['IND','GRP','OTH']\n",
        "  ylabels=[]\n",
        "  for r in y1:\n",
        "    if (r==\"IND\"): \n",
        "        largest_index = 0 \n",
        "    elif (r==\"GRP\"):\n",
        "        largest_index = 1 \n",
        "    else: \n",
        "        largest_index = 2 \n",
        "    \n",
        "    ylabels.append(largest_index)\n",
        "    i=i+1;\n",
        "  return ylabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cbsYP89oimCd",
        "colab": {}
      },
      "source": [
        "yz=giveLabel2(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20b40fdc-d34b-4da5-b09d-d659e976fbd2",
        "id": "HoCPAL3eimCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "set(yz)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g-StfBGnimC8",
        "colab": {}
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(yz)\n",
        "encoded_Y = encoder.transform(yz)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ZIl1DY7imDB",
        "colab": {}
      },
      "source": [
        "ytestlabels=dummy_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBzncF70nJet",
        "colab_type": "code",
        "outputId": "302b23df-96b9-4e96-8093-3232cd7c9d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32970500650729356, 0.17999333857533661, 0.5282886149584926],\n",
              "       [0.7917002313617327, 0.09223190703485422, 0.11158894406489282],\n",
              "       [0.17462440898700485, 0.665503975441615, 0.20898024553828357],\n",
              "       ...,\n",
              "       [0.5362114789259027, 0.21174702781058236, 0.3051222130387538],\n",
              "       [0.553953214916959, 0.14026104093205793, 0.3430198312192558],\n",
              "       [0.5924243074190462, 0.282917964711436, 0.20051719942393592]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNGWj0j-m-Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSmKvvMGVeeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples = convert_text_to_examples(x_train, y_train)\n",
        "test_examples = convert_text_to_examples(preprocessedTweets1, ytestlabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJVSHSQnqRz",
        "colab_type": "code",
        "outputId": "3a5f9478-ef28-49df-89b0-c6aab877da4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_examples)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO_niaaoT_8d",
        "colab_type": "code",
        "outputId": "dacf5118-03e9-4e15-cf68-431e45e37b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b08da1fbff11411eb6a9db8efd66cb08",
            "0737322b65f94389b52e8983131ba792",
            "c4f5c631d5704393819dc3ba12a222a3",
            "9740ed8f29a04153b513b4dcb19d795d",
            "13735bf084f349539619374b4b033c9a",
            "5a06bd173d2443339033e103e2247411",
            "8ad2c31c804e4c6fa9ffe2c9369060c4",
            "f227cb91f7a34e6490e05dd264843789"
          ]
        }
      },
      "source": [
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
        ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b08da1fbff11411eb6a9db8efd66cb08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=188973, style=ProgressS‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeiQYPc4n1Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-IloWIAi7H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
        ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6chIkuTmzHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dktXv_oVdFug",
        "colab_type": "code",
        "outputId": "bee38caf-ced9-40c1-911c-338d88bea6bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "\n",
        "model = build_model(max_seq_length)\n",
        "\n",
        "# Instantiate variables\n",
        "initialize_vars(sess)\n",
        "\n",
        "model.fit(\n",
        "    [train_input_ids, train_input_masks, train_segment_ids], \n",
        "    train_labels,\n",
        "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
        "    epochs=1,\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer_9 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 256)          196864      bert_layer_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 3)            771         dense_18[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 110,302,525\n",
            "Trainable params: 22,051,843\n",
            "Non-trainable params: 88,250,682\n",
            "__________________________________________________________________________________________________\n",
            "Train on 188973 samples, validate on 3876 samples\n",
            "  1536/188973 [..............................] - ETA: 66:53:36 - loss: 1.2002 - acc: 0.6641"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP2GvkLjiU84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnDnO3srfElI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def f1_calc(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=np.argmax(predictions,axis=1).to('cpu').numpy().flatten()\n",
        "  labelsFlattend=np.argmax(predictions,axis=1).to('cpu').numpy().flatten()\n",
        "  print(predictions)\n",
        "  print(\"Predictions Argmax\",predictionArgmax)\n",
        "  print(\"labels Flattened\",labelsFlattend)   \n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pnpWHzpf5av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kmqo_U_hu2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#f1 inspired from \n",
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPmR_vZuZHrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=x_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yObShLEjikHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyWlozOEivho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets1=preprocessinglib(x_test[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tloiaAJEf4Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_1 = tokenizer.texts_to_sequences(preprocessedTweets1)\n",
        "X_test = pad_sequences(X_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtgkOJEs-oNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def giveLabel2(y1):\n",
        "  i=0\n",
        "  largest_index=0\n",
        "  #label1=['IND','GRP','OTH']\n",
        "  ylabels=[]\n",
        "  for r in y1:\n",
        "    if (r==\"IND\"): \n",
        "        largest_index = 0 \n",
        "    elif (r==\"GRP\"):\n",
        "        largest_index = 1 \n",
        "    else: \n",
        "        largest_index = 2 \n",
        "    \n",
        "    ylabels.append(largest_index)\n",
        "    i=i+1;\n",
        "  return ylabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4t9tiul-09y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yz=giveLabel2(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ2avTzU-_6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set(yz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLoYQpvi94Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(yz)\n",
        "encoded_Y = encoder.transform(yz)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hprtjamF-_Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om4bW22TCBAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgKS0NlS-Ab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEaCkDKwCGc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"SubtaskCEnglishData.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2HSwB5BEgD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1uiK6awCXUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"SubtaskCEnglishData.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTOB5JVZV-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score= model.evaluate(X_test,dummy_y)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(score[0],score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LAGOO1RYDoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yvalid=model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCr8JEs_GXbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdghWOjxF98G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculateF1Score(predictions,labels):\n",
        "  #rowwise return the index of the max element ie 0 or 1 depending on the maximum value returned\n",
        "  predictionArgmax=predictions.flatten()\n",
        "  labelsFlattend=labels.flatten()\n",
        "  #print(\"Predictions Argmax\",predictionArgmax)\n",
        "  #print(\"labels Flattened\",labelsFlattend)   \n",
        "  return f1_score(labelsFlattend, predictionArgmax, average='macro'),accuracy_score(labelsFlattend, predictionArgmax)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDzj449-GqJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58RB8sbBFhNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f11,acc=calculateF1Score(yvalid,encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh9Iph4mGD-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BAkNvIFrdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEfQpnBOLXXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ygiven=[]\n",
        "ypredicted=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a0FKPfsNobT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou207z2INRfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/EnglishDatac/test_c_baseline.csv.zip' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHUf_RjRNpVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -P ****** -qq '/content/drive/My Drive/EnglishDatac/public_data_task_C.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUY9Oq4tiVLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readData1():\n",
        "  headers=['id','ypredicted']\n",
        "  greekdataBaseline = pd.read_csv(\"test_c_baseline.csv\", delimiter=',',names=headers)\n",
        "  #,converters={\"id\":convertToInt}       \n",
        "  #greekdataBaseline.id = greekdataBaseline.id.astype(int)\n",
        "  #greekdataBaseline=greekdataBaseline[1:]\n",
        "  print(greekdataBaseline.head())\n",
        "  print(greekdataBaseline.shape)\n",
        "\n",
        "  headers=['id','tweet']\n",
        "  greekDataTest = pd.read_csv(\"test_c_tweets.tsv\", delimiter='\\t',names=headers)\n",
        "                                #converters={\"id\":convertToInt})\n",
        "  #greekDataTest=greekDataTest[1:]\n",
        "  print(greekDataTest.head())\n",
        "  #print(greekDataTest.dtypes)\n",
        "  print(greekDataTest.shape)\n",
        "  result = pd.merge(greekDataTest, greekdataBaseline, on='id', how='inner')\n",
        "  print(result.head())\n",
        "  print(result.dtypes)\n",
        "  print(result.shape)\n",
        "\n",
        "  #result=\n",
        "  #result.sort_values(by=['id'], inplace=True)\n",
        "  #print(result.head())\n",
        "  dfnumpy=result.to_numpy();\n",
        "  X=dfnumpy[:, 1].reshape(-1, 1)\n",
        "  y=dfnumpy[:, 2].reshape(-1, 1)\n",
        "  tid=dfnumpy[:, 0].reshape(-1, 1)\n",
        "  preprocessedTweets=X[:,0]\n",
        "  return preprocessedTweets,y,tid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwg1ano7LZ0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets,ypredict1,tid=readData1()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdcRliJmGaqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(preprocessedTweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmMxxn_YShdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessedTweets=preprocessinglib(preprocessedTweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKKEJU_cG1wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xpredict = tokenizer.texts_to_sequences(preprocessedTweets)\n",
        "Xpredict = pad_sequences(Xpredict, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', Xpredict.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WoaOf7VYOHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ynew = model.predict_classes(Xpredict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR-ajoMOStSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IfeaDCUdRJ-j",
        "colab": {}
      },
      "source": [
        "yz=giveLabel2(ypredict1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmaT7QgeRJ_C",
        "colab": {}
      },
      "source": [
        "set(yz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IFU7qozGRJ_L",
        "colab": {}
      },
      "source": [
        "encoded_Ypredict = encoder.transform(yz)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W75Xr6iHTTuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f11,acc=calculateF1Score(ynew,encoded_Ypredict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef629NijTzsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Azbt_nUFlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHffhfImvU5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(ynew.flatten().tolist().count(0))\n",
        "print(ynew.flatten().tolist().count(1))\n",
        "print(ynew.flatten().tolist().count(2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaYWIdBv7p3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans=ynew.flatten().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6UHJRQv2hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yans3=[]\n",
        "#yans3.append(\"IND\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py58xFYnv489",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(yans)):\n",
        "  if yans[i]==0:\n",
        "    yans3.append(\"IND\")\n",
        "  elif yans[i]==1:\n",
        "    yans3.append(\"GRP\")\n",
        "  else:\n",
        "    yans3.append(\"OTH\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbnZPNfpwHtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tid.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkgq93UVUQ27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z={'tweet':sentence_predict[],'subtask_a':y_predict}\n",
        "#print(len(z))\n",
        "C = {'id': tid.flatten(),\n",
        "        'predicted': yans3\n",
        "    }\n",
        "df = pd.DataFrame(C)\n",
        "#print (df[df['id'] == 2707] )\n",
        "\n",
        "export_csv = df.to_csv ('/content/drive/My Drive/EnglishDatac/EnglishSubtaskCAnswerFinalOneHot.csv', index = None, header=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K68yAoYCwCeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}